2022-02-16T14:13:39,710 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T14:13:39,710 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T14:13:39,866 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T14:13:39,866 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T14:13:40,690 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220209215905239-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T14:13:40,690 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220209215905239-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T14:13:40,721 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220209215905239-startup.cfg",
  "modelCount": 1,
  "created": 1644411545240,
  "models": {
    "sentencemoji": {
      "1.1": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T14:13:40,721 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220209215905239-startup.cfg",
  "modelCount": 1,
  "created": 1644411545240,
  "models": {
    "sentencemoji": {
      "1.1": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T14:13:40,743 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220209215905239-startup.cfg
2022-02-16T14:13:40,743 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220209215905239-startup.cfg
2022-02-16T14:13:40,749 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220209215905239-startup.cfg validated successfully
2022-02-16T14:13:40,749 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220209215905239-startup.cfg validated successfully
2022-02-16T14:14:22,424 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T14:14:22,424 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T14:14:22,425 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:14:22,425 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:14:22,430 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:14:22,430 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:14:22,431 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T14:14:22,431 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T14:14:22,433 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T14:14:22,433 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T14:14:22,464 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:14:22,464 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:14:22,464 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:14:22,464 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:14:22,464 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:14:22,465 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:14:22,464 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:14:22,468 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:14:22,464 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:14:22,474 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T14:14:22,464 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:14:22,464 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:14:22,464 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:14:22,478 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:14:22,465 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:14:22,474 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T14:14:22,478 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:14:22,468 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:14:25,208 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2022-02-16T14:14:25,208 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2022-02-16T14:15:37,025 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T14:15:37,025 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T14:15:37,133 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T14:15:37,133 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T14:15:37,912 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216141425334-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T14:15:37,912 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216141425334-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T14:15:37,939 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216141425334-shutdown.cfg",
  "modelCount": 1,
  "created": 1644988465335,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T14:15:37,939 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216141425334-shutdown.cfg",
  "modelCount": 1,
  "created": 1644988465335,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T14:15:37,960 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216141425334-shutdown.cfg
2022-02-16T14:15:37,960 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216141425334-shutdown.cfg
2022-02-16T14:15:37,966 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216141425334-shutdown.cfg validated successfully
2022-02-16T14:15:37,966 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216141425334-shutdown.cfg validated successfully
2022-02-16T14:16:20,092 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T14:16:20,092 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T14:16:22,143 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:16:22,143 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:16:22,160 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:16:22,160 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T14:16:22,164 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T14:16:22,164 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T14:16:22,165 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T14:16:22,165 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T14:16:22,200 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:22,201 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:22,200 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:22,204 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T14:16:22,203 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:22,201 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:22,211 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:22,203 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:22,211 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:22,204 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T14:16:22,211 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:22,211 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:22,231 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:22,239 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:22,240 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:22,231 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:22,239 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:22,240 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:22,841 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T14:16:22,841 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T14:16:22,842 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T14:16:22,842 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T14:16:22,848 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T14:16:22,848 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T14:16:22,849 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T14:16:22,849 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T14:16:22,852 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T14:16:22,852 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T14:16:24,021 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T14:16:24,021 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T14:16:26,265 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,287 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:13.283626556396484|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:219.56109619140625|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,295 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.3|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,296 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:4476.35546875|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11701.65234375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:26,300 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:72.3|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988586
2022-02-16T14:16:30,182 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,190 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]5372
2022-02-16T14:16:30,195 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,194 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,195 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,202 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,212 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:30,212 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:30,241 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:30,249 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590249
2022-02-16T14:16:30,249 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590249
2022-02-16T14:16:30,327 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,520 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,524 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]20900
2022-02-16T14:16:30,528 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,528 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,528 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,536 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:30,536 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,536 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:30,550 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590550
2022-02-16T14:16:30,550 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590550
2022-02-16T14:16:30,550 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:30,587 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,703 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,705 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]14688
2022-02-16T14:16:30,711 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,711 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,719 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:30,718 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,719 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:30,727 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590727
2022-02-16T14:16:30,727 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590727
2022-02-16T14:16:30,727 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:30,751 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,754 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32528
2022-02-16T14:16:30,756 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,756 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:30,758 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:30,756 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,758 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:30,760 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,763 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,769 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590769
2022-02-16T14:16:30,769 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:30,769 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988590769
2022-02-16T14:16:30,808 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,222 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,224 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]31604
2022-02-16T14:16:31,225 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,225 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,225 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,225 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,226 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:31,226 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:31,232 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:31,233 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591233
2022-02-16T14:16:31,233 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591233
2022-02-16T14:16:31,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,359 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,361 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]29732
2022-02-16T14:16:31,366 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,366 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,366 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,380 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:31,374 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,380 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:31,404 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591404
2022-02-16T14:16:31,404 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591404
2022-02-16T14:16:31,404 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:31,439 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,617 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,619 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19916
2022-02-16T14:16:31,624 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,623 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,624 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,633 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:31,631 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,633 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:31,639 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591639
2022-02-16T14:16:31,639 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591639
2022-02-16T14:16:31,639 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:31,683 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,789 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,791 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]53036
2022-02-16T14:16:31,795 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,795 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,795 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T14:16:31,804 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:31,802 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,804 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:31,812 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591811
2022-02-16T14:16:31,812 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988591811
2022-02-16T14:16:31,812 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:31,843 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:33,785 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:33,790 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:33,786 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:33,790 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:33,800 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:33,792 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:33,800 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:33,802 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:33,806 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:33,807 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:33,809 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:33,811 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:33,813 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:33,827 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:33,828 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:33,830 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:16:33,832 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:16:33,804 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:33,834 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T14:16:33,804 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:33,840 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:33,836 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T14:16:33,840 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:33,843 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:33,841 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T14:16:33,843 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:33,859 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 123, in handle
2022-02-16T14:16:33,890 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T14:16:33,892 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 112, in handle
2022-02-16T14:16:33,897 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T14:16:33,899 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:33,898 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 37, in initialize
2022-02-16T14:16:33,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T14:16:33,912 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-16T14:16:33,921 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:33,899 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:33,923 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:33,921 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:33,913 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     pretrained_model_name_or_path, return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs
2022-02-16T14:16:33,939 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 582, in from_pretrained
2022-02-16T14:16:33,923 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:33,952 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T14:16:33,944 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-02-16T14:16:33,953 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:33,952 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T14:16:33,953 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:34,182 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,183 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,184 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,183 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,197 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,188 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,197 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,204 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,214 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,215 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,214 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,224 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,238 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,237 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,246 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,238 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,254 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,252 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,254 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,258 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,260 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:34,260 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:34,262 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:34,260 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:34,262 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:34,265 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T14:16:34,264 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:16:34,267 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:34,267 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,266 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,265 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T14:16:34,282 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:34,267 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,267 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:34,286 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,277 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,282 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:34,286 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,298 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,296 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,298 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,308 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,304 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,308 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,315 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,313 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,315 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,326 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,329 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:34,329 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,329 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:34,336 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:34,331 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,336 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:34,338 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T14:16:34,336 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,340 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:34,338 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T14:16:34,340 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:34,344 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:34,344 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:34,412 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,413 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,413 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,413 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,430 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,427 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,430 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,434 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,432 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,434 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,439 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,436 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,439 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,459 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,451 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,459 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,461 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,466 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:34,465 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,466 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:34,469 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:34,467 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,469 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:34,480 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T14:16:34,484 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:34,484 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,471 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,486 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:34,484 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,489 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,484 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:34,480 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T14:16:34,483 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,489 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,500 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,486 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:34,500 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,519 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,500 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,519 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,523 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,521 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,523 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,524 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,528 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:34,538 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:34,528 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,538 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:34,528 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:34,552 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:34,541 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,552 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:34,559 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T14:16:34,557 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,561 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:34,559 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T14:16:34,561 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:34,664 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,665 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,665 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,665 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,679 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,672 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,679 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,683 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,681 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,683 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,692 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,686 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,692 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,715 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,710 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,715 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,722 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:34,717 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,722 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:34,730 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:34,723 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,730 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:34,740 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T14:16:34,733 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,742 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:34,740 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T14:16:34,742 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:34,758 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:34,758 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:34,869 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,870 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,870 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,869 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,870 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,885 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,870 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:34,888 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,870 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,885 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,892 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,877 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,890 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,888 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:34,910 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,901 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,892 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,915 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,910 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:34,918 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,912 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,918 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,924 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,919 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,915 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:34,939 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,924 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,939 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:34,945 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:34,947 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:34,922 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,941 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,945 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:34,949 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:34,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,947 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,947 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:34,954 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:34,958 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:34,964 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:34,965 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:34,952 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,965 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:34,964 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:34,958 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:34,954 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:34,994 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T14:16:34,952 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,969 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:34,949 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:34,998 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:34,998 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T14:16:34,996 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,999 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:34,994 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T14:16:34,998 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T14:16:34,998 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:34,999 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:35,276 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:35,276 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:35,355 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:35,355 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:35,501 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:35,501 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:35,582 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:35,582 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:35,753 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:35,753 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:36,015 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:36,015 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:36,015 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:36,015 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:40,772 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:40,773 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]26936
2022-02-16T14:16:40,777 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:40,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:40,777 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:40,787 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:40,785 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:40,787 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:40,794 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:40,794 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988600794
2022-02-16T14:16:40,794 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988600794
2022-02-16T14:16:40,852 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,035 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,042 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]15352
2022-02-16T14:16:42,043 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,043 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,043 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,052 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:42,050 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,052 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:42,060 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602060
2022-02-16T14:16:42,060 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602060
2022-02-16T14:16:42,060 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:42,123 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,226 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,228 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]40788
2022-02-16T14:16:42,233 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,233 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,233 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,243 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:42,241 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,243 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:42,250 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602250
2022-02-16T14:16:42,250 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602250
2022-02-16T14:16:42,251 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:42,278 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,280 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]3380
2022-02-16T14:16:42,299 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,299 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:42,299 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,309 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:42,309 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:42,319 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602319
2022-02-16T14:16:42,319 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988602319
2022-02-16T14:16:42,319 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:42,376 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,159 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,161 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]26428
2022-02-16T14:16:43,166 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,165 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,166 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,175 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:43,173 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,175 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:43,189 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603189
2022-02-16T14:16:43,189 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:43,189 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603189
2022-02-16T14:16:43,214 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,238 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,239 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]57660
2022-02-16T14:16:43,241 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,241 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,241 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,254 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:43,246 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,254 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:43,277 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603277
2022-02-16T14:16:43,277 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603277
2022-02-16T14:16:43,278 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:43,302 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,553 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,554 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]34200
2022-02-16T14:16:43,559 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,559 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,559 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,567 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,576 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:43,576 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:43,610 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603610
2022-02-16T14:16:43,610 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603610
2022-02-16T14:16:43,610 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:43,648 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,686 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,690 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29072
2022-02-16T14:16:43,693 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,693 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,693 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:43,711 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:43,703 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,711 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:43,734 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603734
2022-02-16T14:16:43,734 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:43,734 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988603734
2022-02-16T14:16:43,776 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:44,520 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:44,521 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:44,521 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:44,521 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:44,535 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:44,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:44,535 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:44,539 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:44,537 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:44,539 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:44,554 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:44,546 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:44,554 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:44,569 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:44,556 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:44,569 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:44,577 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:44,571 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:44,577 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:44,584 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:44,583 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:44,584 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:44,593 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T14:16:44,599 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:44,586 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:44,602 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:44,599 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:44,593 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T14:16:44,602 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:45,491 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,492 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,492 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,492 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,496 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,497 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,495 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,495 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,496 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,514 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,497 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,522 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,505 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,514 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,512 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,538 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,529 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,522 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,549 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,538 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,553 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,538 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,549 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,557 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,546 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,555 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,553 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,575 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,560 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,557 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,575 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,581 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:45,582 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:45,572 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,577 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,581 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:45,585 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:45,583 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,585 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:45,589 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T14:16:45,585 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,582 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:45,587 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,609 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:45,609 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:45,591 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,589 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T14:16:45,614 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:45,615 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:45,609 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:45,609 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:45,621 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T14:16:45,615 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:45,611 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,631 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:45,614 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:45,640 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:45,631 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:45,621 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T14:16:45,640 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:45,754 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,755 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,755 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,755 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:45,770 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,762 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,770 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:45,774 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,771 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,774 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:45,779 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,776 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,779 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:45,791 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,788 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,791 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:45,797 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,801 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:45,801 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:45,803 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:45,801 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,803 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:45,806 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T14:16:45,805 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,808 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:45,806 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T14:16:45,808 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:45,823 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:45,823 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:46,143 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,144 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,144 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,144 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,157 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,149 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,157 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,161 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,161 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,166 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,162 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,166 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,170 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,167 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,170 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,188 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:46,180 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,188 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:46,201 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:46,193 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,215 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:46,201 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:46,215 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:46,224 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T14:16:46,210 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,226 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:46,226 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:46,224 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T14:16:46,386 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,387 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,387 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,387 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,400 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,392 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,400 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,402 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,420 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,411 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,420 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,430 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,428 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,430 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,442 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:46,442 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,442 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:46,446 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:46,443 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,446 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:46,450 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T14:16:46,449 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:46,459 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:46,450 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T14:16:46,459 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:46,493 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:46,493 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:46,594 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:46,594 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:46,612 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,613 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,613 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,613 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,617 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,615 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,617 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,622 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,620 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,630 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,641 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:46,622 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,646 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,641 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:46,639 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,646 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,662 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,654 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,662 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,680 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:46,672 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,680 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:46,706 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:46,687 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,706 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:46,732 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T14:16:46,732 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:46,736 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,732 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T14:16:46,736 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:46,739 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,735 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,733 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:46,750 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:46,750 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:46,747 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,739 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:46,732 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:46,781 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,774 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,781 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:46,792 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,789 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,792 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:46,794 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,794 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,794 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:46,796 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,808 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:46,808 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,808 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:46,811 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:46,809 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,811 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:46,814 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T14:16:46,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,816 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:46,814 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T14:16:46,818 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:46,816 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:46,818 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:46,827 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:46,827 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:47,241 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:47,241 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:47,460 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:47,460 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:47,761 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:47,761 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:47,842 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:47,842 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:51,783 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:51,788 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]38124
2022-02-16T14:16:51,789 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:51,789 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:51,789 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:51,799 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:51,796 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:51,799 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:16:51,805 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988611805
2022-02-16T14:16:51,805 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988611805
2022-02-16T14:16:51,806 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:51,813 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:52,995 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:52,999 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:53,001 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]26048
2022-02-16T14:16:53,009 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,009 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,009 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,013 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:53,011 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,013 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]18052
2022-02-16T14:16:53,016 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,013 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:16:53,024 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613024
2022-02-16T14:16:53,016 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,026 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:53,016 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,024 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613024
2022-02-16T14:16:53,021 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:53,033 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,026 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:16:53,046 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:53,078 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613078
2022-02-16T14:16:53,078 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613078
2022-02-16T14:16:53,079 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:53,082 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:53,281 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:53,283 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32012
2022-02-16T14:16:53,288 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,288 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,288 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:53,298 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:53,296 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,298 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:16:53,316 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613316
2022-02-16T14:16:53,316 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988613316
2022-02-16T14:16:53,316 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:53,327 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,074 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,076 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]39268
2022-02-16T14:16:54,081 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,080 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,081 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,090 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:54,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,090 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:16:54,095 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614095
2022-02-16T14:16:54,095 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614095
2022-02-16T14:16:54,096 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:54,102 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,354 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,356 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]24516
2022-02-16T14:16:54,360 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,360 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,368 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,360 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,374 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:54,374 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:16:54,389 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614389
2022-02-16T14:16:54,389 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:54,389 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614389
2022-02-16T14:16:54,396 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,399 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,405 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]16072
2022-02-16T14:16:54,412 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,412 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,412 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,421 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:54,419 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,421 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:16:54,427 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614427
2022-02-16T14:16:54,427 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988614427
2022-02-16T14:16:54,427 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:54,437 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,986 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,987 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]21272
2022-02-16T14:16:54,991 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:54,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,991 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:16:55,001 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:54,999 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:55,001 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:16:55,017 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988615017
2022-02-16T14:16:55,017 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988615017
2022-02-16T14:16:55,017 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:55,021 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:55,487 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:55,486 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:55,487 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:55,494 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:55,487 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:55,494 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:55,504 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:55,501 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:55,515 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:55,504 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:55,535 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:55,535 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:55,535 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:55,554 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:55,542 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:55,554 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:55,560 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:55,570 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:55,570 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:55,570 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:55,574 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:55,572 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:55,574 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:55,579 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-02-16T14:16:55,578 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:55,581 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:55,579 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-02-16T14:16:55,581 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:16:55,626 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:55,626 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:16:56,128 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,128 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,128 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,135 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,129 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,135 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,144 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,143 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,144 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,149 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,146 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,153 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,149 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,159 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,153 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,161 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,152 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,151 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,170 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,172 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,161 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,159 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,189 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,192 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:56,174 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,169 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,192 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:56,208 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:56,189 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,217 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,197 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,197 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:56,217 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,223 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,208 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:56,225 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-02-16T14:16:56,222 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:56,227 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:56,219 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,223 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,262 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:56,225 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-02-16T14:16:56,229 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,227 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:16:56,279 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:56,304 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:56,262 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:56,266 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,312 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:56,304 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:16:56,279 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:16:56,312 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,312 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:56,331 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-02-16T14:16:56,329 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,334 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:56,331 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-02-16T14:16:56,334 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:16:56,627 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,626 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,627 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:56,633 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,627 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,633 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:56,643 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,641 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,643 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:56,646 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,645 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,646 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:56,650 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,648 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,650 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:56,661 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,669 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:56,668 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,669 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:56,672 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:56,670 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,672 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:56,675 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-02-16T14:16:56,672 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:56,677 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:56,675 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-02-16T14:16:56,677 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:16:56,683 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:56,683 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:16:57,045 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,044 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,045 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,052 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,046 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,052 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,062 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,060 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,062 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,065 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,064 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,065 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,070 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,067 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,070 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,083 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,087 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:57,086 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,087 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:57,090 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:57,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,090 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:57,092 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-02-16T14:16:57,091 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,093 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:57,092 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-02-16T14:16:57,093 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:16:57,097 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:57,097 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:16:57,230 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,229 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,230 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,235 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,230 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,235 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,248 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,243 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,248 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,258 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,256 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,258 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,268 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,259 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,268 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,279 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:57,278 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,279 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:57,281 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:57,279 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,281 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:57,283 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-02-16T14:16:57,283 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,285 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:57,283 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-02-16T14:16:57,285 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:16:57,289 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:57,289 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:16:57,314 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,313 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,314 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,316 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,316 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,320 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,318 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,320 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,329 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,322 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,329 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,338 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,331 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,338 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,345 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:57,345 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,345 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:57,349 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:57,347 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,364 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:57,349 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:57,365 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-02-16T14:16:57,364 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:16:57,351 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,373 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:57,365 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-02-16T14:16:57,373 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:16:57,486 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,486 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,486 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:16:57,493 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,487 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,493 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:16:57,503 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,501 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,503 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:16:57,509 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,505 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,509 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:16:57,522 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,520 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,522 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:16:57,529 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,533 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:57,532 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,533 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:57,537 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:57,534 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,537 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:57,541 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-02-16T14:16:57,542 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:57,539 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,551 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:57,542 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:16:57,551 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:16:57,541 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-02-16T14:16:57,591 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:57,591 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:16:58,235 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:58,235 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:16:58,345 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:58,345 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:16:58,704 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:58,704 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:16:59,115 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:59,115 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:16:59,304 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:59,304 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:16:59,377 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:59,377 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:16:59,548 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:16:59,548 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:03,572 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:03,574 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]21500
2022-02-16T14:17:03,579 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:03,579 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:03,579 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:03,588 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:03,586 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:03,588 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:03,594 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988623594
2022-02-16T14:17:03,594 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988623594
2022-02-16T14:17:03,594 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:03,597 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,379 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,380 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]56900
2022-02-16T14:17:04,389 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,389 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,389 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,393 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:04,391 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,393 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:04,409 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624409
2022-02-16T14:17:04,409 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624409
2022-02-16T14:17:04,410 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:04,423 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,619 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,621 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]23820
2022-02-16T14:17:04,626 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,625 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,629 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,626 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,637 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:04,633 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,636 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]42004
2022-02-16T14:17:04,641 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,637 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:04,651 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624651
2022-02-16T14:17:04,641 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:04,656 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:04,641 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,658 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,651 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624651
2022-02-16T14:17:04,650 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:04,656 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:04,684 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624684
2022-02-16T14:17:04,675 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,684 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:04,684 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988624684
2022-02-16T14:17:04,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:05,849 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:05,851 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]18040
2022-02-16T14:17:05,856 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:05,856 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:05,856 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:05,866 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:05,864 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:05,866 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:05,872 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988625872
2022-02-16T14:17:05,872 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988625872
2022-02-16T14:17:05,872 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:05,875 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,120 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,121 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]24632
2022-02-16T14:17:06,125 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,125 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,125 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,135 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:06,133 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,135 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:06,140 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626140
2022-02-16T14:17:06,140 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626140
2022-02-16T14:17:06,140 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:06,150 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,240 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]51028
2022-02-16T14:17:06,246 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,245 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,246 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,254 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:06,253 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,254 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:06,259 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626259
2022-02-16T14:17:06,259 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:06,259 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626259
2022-02-16T14:17:06,263 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,688 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,689 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]31220
2022-02-16T14:17:06,700 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,700 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,707 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,700 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:06,719 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:06,719 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:06,729 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626729
2022-02-16T14:17:06,729 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:06,729 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988626729
2022-02-16T14:17:06,740 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:07,098 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,097 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,098 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,105 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,098 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,105 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,115 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,112 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,115 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,120 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,117 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,120 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,122 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,121 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,122 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,127 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:07,123 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,127 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:07,140 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:07,137 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,140 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:07,144 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-02-16T14:17:07,142 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:07,145 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:07,144 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-02-16T14:17:07,145 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:07,171 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:07,171 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:07,509 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,508 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,509 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,515 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,509 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,515 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,525 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,523 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,525 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,529 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,527 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,529 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,531 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,530 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,531 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,547 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:07,533 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,547 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:07,552 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:07,550 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,552 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:07,556 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-02-16T14:17:07,554 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:07,558 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:07,556 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-02-16T14:17:07,558 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:07,602 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:07,602 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:07,926 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,926 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,926 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:07,933 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,927 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,933 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:07,942 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,940 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,942 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:07,947 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,944 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,947 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:07,951 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,949 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,951 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:07,957 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:07,952 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,957 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:07,969 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:07,967 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,969 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:07,973 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-02-16T14:17:07,971 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:07,975 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:07,973 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-02-16T14:17:07,975 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:08,031 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,031 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,037 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,041 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:08,031 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,041 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:08,037 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,048 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,048 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,064 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,061 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,064 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,073 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,071 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,073 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,080 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,083 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:08,083 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:08,085 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:08,083 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,085 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:08,089 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-02-16T14:17:08,087 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,091 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:08,089 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-02-16T14:17:08,091 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:08,100 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:08,100 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:08,649 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,654 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,650 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,654 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,662 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,660 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,662 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,664 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,664 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,664 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,668 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,666 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,668 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,682 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,670 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,682 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,694 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:08,696 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,684 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,696 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,707 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,695 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,721 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:08,694 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:08,727 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:08,707 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,728 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,700 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,721 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:08,715 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,729 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:08,727 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:08,746 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-02-16T14:17:08,728 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,754 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,737 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:08,756 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:08,734 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,754 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,746 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-02-16T14:17:08,762 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,758 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,756 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:08,780 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,762 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,796 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,798 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:08,798 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:08,801 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:08,798 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,801 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:08,805 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-02-16T14:17:08,803 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,807 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:08,805 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-02-16T14:17:08,807 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:08,823 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:08,823 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:08,931 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,930 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,931 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:08,937 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,932 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,937 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:08,946 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,944 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,946 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:08,950 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,948 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,950 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:08,955 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,952 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,955 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:08,967 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,976 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:08,975 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,976 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:08,980 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:08,978 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,980 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:08,984 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-02-16T14:17:08,982 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:08,994 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:08,996 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:08,984 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-02-16T14:17:08,996 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:08,994 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:09,031 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:09,032 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:09,032 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:09,039 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:09,032 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:09,039 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:09,048 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:09,041 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:09,048 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:09,065 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:09,062 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:09,065 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:09,077 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:09,075 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:09,077 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:09,088 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:09,083 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:09,088 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:09,091 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:09,088 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:09,091 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:09,096 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-02-16T14:17:09,093 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:09,098 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:09,105 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:09,096 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-02-16T14:17:09,105 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:09,098 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:10,150 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:10,150 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:10,561 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:10,561 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:10,989 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:10,989 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:11,100 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:11,100 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:11,759 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:11,759 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:11,824 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:11,824 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:12,007 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:12,007 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:12,119 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:12,119 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:16,083 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:16,084 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]16696
2022-02-16T14:17:16,089 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:16,089 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:16,089 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:16,102 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:16,097 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:16,102 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:16,126 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:16,127 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988636127
2022-02-16T14:17:16,127 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988636127
2022-02-16T14:17:16,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:16,733 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:16,735 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]51912
2022-02-16T14:17:16,740 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:16,740 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:16,740 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:16,750 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:16,748 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:16,750 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:16,754 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988636754
2022-02-16T14:17:16,754 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988636754
2022-02-16T14:17:16,754 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:16,757 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:17,103 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:17,110 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]33356
2022-02-16T14:17:17,111 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:17,110 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:17,111 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:17,117 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:17,116 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:17,117 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:17,123 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988637123
2022-02-16T14:17:17,123 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988637123
2022-02-16T14:17:17,123 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:17,136 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:17,238 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:17,239 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]14956
2022-02-16T14:17:17,243 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:17,243 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:17,243 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:17,253 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:17,251 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:17,253 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:17,258 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988637258
2022-02-16T14:17:17,258 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:17,258 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988637258
2022-02-16T14:17:17,262 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,300 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,301 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]15996
2022-02-16T14:17:18,316 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,316 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,318 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:18,316 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,318 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:18,325 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638325
2022-02-16T14:17:18,325 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:18,325 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638325
2022-02-16T14:17:18,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,605 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,607 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]55844
2022-02-16T14:17:18,613 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,612 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,613 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,623 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:18,620 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,623 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:18,629 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638629
2022-02-16T14:17:18,629 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638629
2022-02-16T14:17:18,629 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:18,632 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,676 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,677 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]48524
2022-02-16T14:17:18,682 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,682 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,682 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,692 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:18,690 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,692 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:18,700 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638700
2022-02-16T14:17:18,700 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638700
2022-02-16T14:17:18,700 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:18,718 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,897 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,899 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]38064
2022-02-16T14:17:18,903 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,903 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,903 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:18,913 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:18,911 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,913 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:18,920 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638920
2022-02-16T14:17:18,920 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988638920
2022-02-16T14:17:18,920 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:18,934 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:19,114 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:19,114 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:19,114 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:19,121 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:19,115 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:19,121 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:19,130 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:19,128 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:19,130 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:19,136 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:19,133 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:19,136 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:19,153 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:19,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:19,153 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:19,155 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:19,159 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:19,159 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:19,161 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:19,159 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:19,161 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:19,168 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-02-16T14:17:19,162 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:19,173 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:19,173 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:19,168 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-02-16T14:17:19,206 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:19,206 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:19,976 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:19,977 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:19,977 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:19,983 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:19,977 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:19,983 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:19,993 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:19,991 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:19,993 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:19,998 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:19,995 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:19,998 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:20,012 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,009 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,012 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,018 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,022 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:20,022 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,022 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:20,027 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:20,025 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,029 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:20,027 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:20,042 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-02-16T14:17:20,041 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:20,044 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:20,042 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-02-16T14:17:20,044 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:20,115 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:20,115 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:20,265 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:20,266 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:20,266 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:20,272 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:20,266 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:20,272 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:20,282 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:20,280 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:20,282 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:20,288 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:20,284 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:20,288 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:20,292 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,290 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,292 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,304 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,309 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:20,308 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,309 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:20,313 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:20,311 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,313 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:20,316 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-02-16T14:17:20,314 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:20,318 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:20,316 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-02-16T14:17:20,321 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:20,318 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:20,321 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:20,545 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:20,546 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:20,546 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:20,546 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:20,560 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:20,552 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:20,560 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:20,565 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:20,562 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:20,565 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:20,571 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:20,567 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,571 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:20,584 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,573 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,584 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:20,590 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,593 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:20,593 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:20,596 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:20,593 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,596 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:20,601 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-02-16T14:17:20,598 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:20,601 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:20,601 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-02-16T14:17:20,601 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:20,647 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:20,647 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:21,178 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,183 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,179 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,189 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,183 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,192 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,189 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,194 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,188 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,184 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,194 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,206 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,192 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,209 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,204 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,196 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,209 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,222 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,206 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,230 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,213 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,209 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,230 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,248 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,222 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,250 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,246 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,244 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,250 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,248 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,258 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:21,259 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:21,253 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,252 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,259 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:21,278 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:21,258 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:21,280 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:21,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,296 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:21,278 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:21,313 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-02-16T14:17:21,281 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,296 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:21,341 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:21,284 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,342 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:21,280 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:21,342 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,343 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-02-16T14:17:21,341 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:21,341 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,336 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:21,348 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:21,313 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-02-16T14:17:21,346 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,343 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-02-16T14:17:21,342 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,372 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,342 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:21,352 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,348 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:21,372 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,380 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,380 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,392 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,382 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,392 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,405 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,408 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:21,408 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:21,410 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:21,408 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,410 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:21,414 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-02-16T14:17:21,417 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:21,412 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,428 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:21,417 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:21,414 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-02-16T14:17:21,428 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:21,517 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,517 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,517 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:21,523 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,518 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,523 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:21,534 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,531 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,534 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:21,539 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,536 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,539 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:21,550 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,549 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,550 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:21,557 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,560 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:21,560 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,560 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:21,563 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:21,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,563 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:21,566 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-02-16T14:17:21,569 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:21,564 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,573 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:21,569 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:21,566 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-02-16T14:17:21,573 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:24,182 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:24,182 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:24,839 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,841 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:13.28622055053711|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,845 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:219.55850219726562|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,847 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:94.3|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,855 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:4394.52734375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,857 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11783.50390625|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:24,859 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:72.8|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644988644
2022-02-16T14:17:25,056 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:25,056 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:25,325 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:25,325 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:25,622 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:25,793 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=55844)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 55844

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('55844',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('55844', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=51912)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 51912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('51912',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('51912', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=16696)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 16696

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('16696',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('16696', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=14956)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 14956

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('14956',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('14956', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=15996)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 15996

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('15996',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('15996', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=48524)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 48524

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('48524',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('48524', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=33356)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 33356

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('33356',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('33356', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp949'>
OSError: [Errno 22] Invalid argument

2022-02-16T14:17:26,350 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:26,350 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:26,417 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:26,579 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:25,622 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:29,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:28,964 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:28,283 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:26,579 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:26,417 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:26,350 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:26,350 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:30,729 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]35316
2022-02-16T14:17:30,726 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]24420
2022-02-16T14:17:30,897 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:30,897 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:30,726 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]50192
2022-02-16T14:17:30,897 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:30,897 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:25,793 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=55844)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 55844

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('55844',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('55844', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=51912)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 51912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('51912',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('51912', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=16696)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 16696

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('16696',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('16696', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=14956)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 14956

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('14956',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('14956', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=15996)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 15996

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('15996',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('15996', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=48524)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 48524

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('48524',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('48524', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=33356)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 33356

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('33356',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('33356', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp949'>
OSError: [Errno 22] Invalid argument

2022-02-16T14:17:30,897 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,898 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:30,897 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,896 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,897 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:30,905 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:30,902 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,900 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,898 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:30,911 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650911
2022-02-16T14:17:30,897 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:30,912 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:30,911 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:30,905 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:30,928 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650928
2022-02-16T14:17:30,904 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,912 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:30,911 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650911
2022-02-16T14:17:30,940 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:30,948 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650947
2022-02-16T14:17:30,948 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:30,928 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650928
2022-02-16T14:17:30,948 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988650947
2022-02-16T14:17:30,952 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:30,945 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:30,956 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:33,500 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,499 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,500 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,509 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,501 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,509 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,509 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,510 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,510 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,510 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,523 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,516 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,523 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,526 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,529 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,523 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,529 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,543 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,528 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,526 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,547 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:33,543 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,533 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,551 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,544 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,547 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:33,551 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,555 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:33,555 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,551 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:33,552 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,555 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:33,557 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,560 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-02-16T14:17:33,557 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:33,555 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,560 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:33,560 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,560 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,569 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:33,560 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,560 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:33,560 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-02-16T14:17:33,569 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:33,563 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,582 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:33,582 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,582 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:33,587 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:33,585 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:33,587 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:33,590 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-02-16T14:17:33,590 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:33,591 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:33,590 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-02-16T14:17:33,591 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:33,615 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,615 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,615 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:33,618 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,616 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,618 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:33,620 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,622 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,622 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,676 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:33,622 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:33,688 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,676 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:33,625 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,688 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:33,701 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,701 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:33,706 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:33,701 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,706 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:33,710 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:33,710 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,710 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:33,719 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-02-16T14:17:33,719 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:33,720 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:33,719 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-02-16T14:17:33,720 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:33,721 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:33,721 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:36,054 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]43848
2022-02-16T14:17:36,075 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,075 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,075 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,080 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:36,077 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,080 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:36,085 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656085
2022-02-16T14:17:36,085 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:36,085 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656085
2022-02-16T14:17:36,088 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,258 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,259 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]15712
2022-02-16T14:17:36,264 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,264 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,264 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,264 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,272 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:36,272 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:36,276 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656276
2022-02-16T14:17:36,276 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656276
2022-02-16T14:17:36,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:36,279 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,363 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,364 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]31200
2022-02-16T14:17:36,368 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,368 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,368 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,376 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,380 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:36,380 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:36,392 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656392
2022-02-16T14:17:36,392 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656392
2022-02-16T14:17:36,392 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:36,398 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,465 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,467 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]55000
2022-02-16T14:17:36,471 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,471 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,471 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:36,480 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:36,479 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,480 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:36,485 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656485
2022-02-16T14:17:36,485 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:36,485 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988656485
2022-02-16T14:17:36,489 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:37,174 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:37,176 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19328
2022-02-16T14:17:37,180 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:37,180 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:37,180 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:37,190 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:37,188 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:37,190 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:37,196 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988657196
2022-02-16T14:17:37,196 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988657196
2022-02-16T14:17:37,196 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:37,199 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:38,316 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,316 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,316 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,322 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,317 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,322 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,332 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,330 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,332 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,347 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,339 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,347 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,360 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,350 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,360 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,366 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,373 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,375 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:38,375 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,375 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:38,379 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:38,377 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:38,379 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:38,394 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-02-16T14:17:38,394 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:38,493 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,494 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,494 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,494 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,507 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,499 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,507 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,510 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,508 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,510 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,515 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,512 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,515 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,518 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,516 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,518 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,535 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,528 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,535 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:38,533 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,535 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:38,539 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:38,535 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,535 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,542 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,539 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:38,544 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-02-16T14:17:38,537 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,541 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:38,548 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:38,544 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-02-16T14:17:38,555 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:38,546 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,542 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,562 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,555 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:38,548 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:38,562 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,570 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,570 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,574 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,572 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,574 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,579 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:38,576 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,579 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:38,596 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:38,580 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,602 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:38,596 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:38,602 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:38,606 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-02-16T14:17:38,601 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,608 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:38,606 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-02-16T14:17:38,608 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:38,727 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,726 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,727 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:38,734 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,727 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,734 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:38,744 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,742 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,744 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:38,750 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,746 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,750 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:38,754 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,752 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,754 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:38,772 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:38,756 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,772 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:38,777 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:38,775 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,777 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:38,781 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-02-16T14:17:38,783 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:38,779 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,783 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:38,781 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-02-16T14:17:38,783 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:38,783 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:39,130 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:39,129 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:39,130 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:39,137 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:39,131 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:39,137 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:39,146 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:39,144 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:39,146 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:39,152 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:39,148 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:39,152 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:39,166 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:39,159 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:39,166 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:39,167 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:39,171 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:39,171 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:39,171 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:39,176 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:39,173 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:39,176 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:39,180 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:39,180 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-02-16T14:17:39,177 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:39,192 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:39,180 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:39,180 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-02-16T14:17:39,192 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:41,579 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:41,579 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:17:41,595 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:41,595 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:17:41,738 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:41,738 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:17:45,285 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,286 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]15348
2022-02-16T14:17:45,297 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,296 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,297 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,300 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:45,298 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,300 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:17:45,306 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665306
2022-02-16T14:17:45,306 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665306
2022-02-16T14:17:45,306 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:45,309 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:45,338 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,340 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]45496
2022-02-16T14:17:45,344 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,344 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,344 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,354 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:45,352 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,354 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:17:45,362 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665362
2022-02-16T14:17:45,362 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665362
2022-02-16T14:17:45,363 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:45,368 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:45,697 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,699 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]45980
2022-02-16T14:17:45,704 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,704 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,704 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:45,721 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:45,713 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,721 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:17:45,734 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665734
2022-02-16T14:17:45,734 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:45,734 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988665734
2022-02-16T14:17:45,742 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:46,405 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:46,405 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:17:46,560 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:46,560 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:17:46,621 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:46,621 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:17:46,798 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:46,798 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:17:47,198 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:47,198 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:17:47,207 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:47,206 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:47,207 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:47,216 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:47,209 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:47,216 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:47,231 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:47,221 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:47,231 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:47,240 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:47,236 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:47,240 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:47,248 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:47,246 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:47,248 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:47,250 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:47,266 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:47,266 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:47,268 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:47,266 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:47,268 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:47,273 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-02-16T14:17:47,270 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:47,274 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:47,273 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-02-16T14:17:47,274 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:17:47,285 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:47,285 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:17:47,620 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:47,619 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:47,620 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:47,633 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:47,620 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:47,633 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:47,637 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:47,635 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:47,637 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:47,647 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:47,639 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:47,647 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:47,655 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:47,653 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:47,655 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:47,657 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:47,669 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:47,669 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:47,669 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:47,674 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:47,672 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:47,674 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:47,677 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-02-16T14:17:47,675 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:47,679 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:47,677 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-02-16T14:17:47,679 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:17:47,752 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:47,752 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:17:48,303 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:48,302 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:48,303 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:48,309 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:48,303 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:48,309 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:48,321 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:48,316 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:48,321 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:48,338 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:48,331 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:48,338 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:48,346 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:48,344 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:48,346 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:48,360 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:48,348 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:48,360 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:48,368 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:48,366 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:48,368 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:48,369 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-02-16T14:17:48,370 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:48,369 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:48,371 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:48,370 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:17:48,369 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-02-16T14:17:48,371 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:17:52,175 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,179 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]16636
2022-02-16T14:17:52,184 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,184 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,184 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,194 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:52,192 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,194 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:17:52,201 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672201
2022-02-16T14:17:52,201 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:52,201 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672201
2022-02-16T14:17:52,221 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,292 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,308 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]23708
2022-02-16T14:17:52,313 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,313 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,313 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,323 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:52,321 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,323 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:17:52,342 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672342
2022-02-16T14:17:52,342 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672342
2022-02-16T14:17:52,343 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:52,354 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,573 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,576 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]2312
2022-02-16T14:17:52,581 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,580 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,581 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,590 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:52,588 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,590 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:17:52,596 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:52,597 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672597
2022-02-16T14:17:52,597 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672597
2022-02-16T14:17:52,600 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,646 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,667 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]21828
2022-02-16T14:17:52,671 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,671 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,671 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:52,683 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:52,680 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,683 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:17:52,689 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672689
2022-02-16T14:17:52,689 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988672689
2022-02-16T14:17:52,689 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:52,692 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:53,838 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:53,848 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]17948
2022-02-16T14:17:53,857 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:53,857 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:53,857 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:17:53,876 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:53,861 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:53,876 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:17:53,893 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988673893
2022-02-16T14:17:53,893 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988673893
2022-02-16T14:17:53,893 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:53,906 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:54,984 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:54,983 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:54,984 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:54,996 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:54,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:54,996 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,005 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,003 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,005 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,010 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,007 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,010 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,014 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,012 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,014 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,029 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:55,015 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,029 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:55,034 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:55,032 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,034 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:55,046 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-02-16T14:17:55,036 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,048 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:55,048 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:17:55,050 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:55,046 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-02-16T14:17:55,050 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:17:55,177 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,176 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,177 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,196 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,190 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,196 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,208 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,203 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,208 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,226 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,216 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,226 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,242 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,240 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,244 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,242 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,250 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:55,246 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,261 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:55,250 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:55,263 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:55,261 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:17:55,254 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,275 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,273 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,275 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,285 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,274 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,282 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:55,263 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:55,289 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-02-16T14:17:55,286 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,285 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,292 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,288 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:55,295 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:55,290 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,289 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-02-16T14:17:55,297 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,292 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,303 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,295 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:17:55,303 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,307 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,302 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,309 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,307 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,318 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:55,321 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,312 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,321 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:55,340 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,341 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:55,320 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,341 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:55,342 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,333 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,359 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,318 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:17:55,361 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:55,352 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,340 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:55,363 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,363 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,363 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:55,361 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:55,370 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-02-16T14:17:55,365 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,363 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:55,376 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,370 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-02-16T14:17:55,372 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,376 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:55,367 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:55,398 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:55,398 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,395 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,398 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:55,404 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:55,398 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:17:55,400 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,404 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:55,419 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:55,412 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,419 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:55,428 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-02-16T14:17:55,422 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:55,444 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:55,428 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-02-16T14:17:55,444 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:17:55,539 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:55,539 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:17:56,296 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:56,295 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:56,296 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:17:56,311 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:56,297 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:56,311 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:17:56,314 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:56,312 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:56,314 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:17:56,330 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:56,320 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:56,341 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:56,344 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:56,330 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:17:56,348 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:56,346 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:56,350 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:56,348 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:17:56,352 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:56,356 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:56,356 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:56,357 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:56,356 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:56,365 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:56,358 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:56,369 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:17:56,365 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:17:56,357 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:56,394 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-02-16T14:17:56,387 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:17:56,413 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:17:56,394 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-02-16T14:17:56,413 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:00,288 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:18:00,288 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:18:00,695 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:18:00,695 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:18:01,387 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:18:01,387 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:18:04,823 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:04,829 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]13328
2022-02-16T14:18:04,833 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:04,833 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:04,833 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:04,843 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:18:04,841 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:04,843 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:18:04,848 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988684848
2022-02-16T14:18:04,848 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988684848
2022-02-16T14:18:04,849 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:18:04,855 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:05,262 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:05,264 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]35136
2022-02-16T14:18:05,269 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:05,269 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:05,269 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:05,279 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:18:05,277 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:05,279 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:18:05,284 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988685283
2022-02-16T14:18:05,284 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988685283
2022-02-16T14:18:05,284 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:18:05,290 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:06,060 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:06,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]38240
2022-02-16T14:18:06,066 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:06,066 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:06,066 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:06,075 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:18:06,074 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:06,075 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:18:06,084 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988686084
2022-02-16T14:18:06,084 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:18:06,084 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988686084
2022-02-16T14:18:06,096 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:06,723 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:06,722 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:06,723 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:06,731 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:06,723 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:06,731 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:06,739 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:06,739 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:06,739 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:06,746 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:06,741 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:06,746 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:06,761 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:06,758 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:06,761 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:06,767 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:06,772 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:06,771 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:06,772 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:06,775 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:06,773 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:06,775 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:06,780 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-02-16T14:18:06,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:06,785 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:06,780 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-02-16T14:18:06,785 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:06,806 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:06,806 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:07,194 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:07,193 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:07,194 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:07,211 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:07,199 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:07,211 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:07,225 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:07,220 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:07,225 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:07,233 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:07,227 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:07,233 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:07,242 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:07,235 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:07,242 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:07,256 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:07,260 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:07,260 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:07,260 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:07,264 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:07,262 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:07,264 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:07,268 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-02-16T14:18:07,266 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:07,270 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:07,268 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-02-16T14:18:07,275 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:07,270 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:07,275 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:07,890 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:07,890 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:07,890 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:07,901 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:07,891 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:07,901 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:07,910 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:07,909 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:07,910 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:07,916 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:07,912 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:07,916 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:07,919 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:07,917 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:07,919 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:07,921 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:07,925 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:07,924 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:07,925 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:07,929 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:07,927 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:07,941 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:07,929 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:07,950 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-02-16T14:18:07,941 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:07,931 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:07,953 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:07,950 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-02-16T14:18:07,953 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:08,060 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:18:08,060 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:18:08,297 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:18:08,297 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:18:08,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:18:08,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:18:08,441 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:18:08,441 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:18:09,418 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:18:09,418 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:18:13,074 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,076 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27408
2022-02-16T14:18:13,080 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,080 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,080 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,095 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:18:13,091 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,095 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:18:13,101 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693101
2022-02-16T14:18:13,101 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693101
2022-02-16T14:18:13,101 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:18:13,113 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,195 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,200 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]49452
2022-02-16T14:18:13,201 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,201 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,201 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,218 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:18:13,209 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,218 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:18:13,233 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693233
2022-02-16T14:18:13,233 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693233
2022-02-16T14:18:13,233 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:18:13,241 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,303 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,304 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]45672
2022-02-16T14:18:13,308 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,308 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,308 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,325 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:18:13,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,325 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:18:13,336 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693336
2022-02-16T14:18:13,336 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:18:13,336 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693336
2022-02-16T14:18:13,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,343 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,344 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]13764
2022-02-16T14:18:13,346 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,346 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:13,359 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:18:13,359 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:18:13,362 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,367 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693367
2022-02-16T14:18:13,367 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:18:13,367 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988693367
2022-02-16T14:18:13,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:15,023 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:15,024 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]3000
2022-02-16T14:18:15,029 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:15,029 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:15,029 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:15,039 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:18:15,037 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:15,039 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:18:15,045 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988695045
2022-02-16T14:18:15,045 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:18:15,045 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988695045
2022-02-16T14:18:15,049 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:15,359 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,359 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,359 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,368 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,362 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,368 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,378 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,376 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,379 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,378 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,424 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,381 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,424 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,428 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,425 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,428 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,434 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,445 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:15,445 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,445 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:15,467 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:15,450 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:15,467 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:15,484 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-02-16T14:18:15,478 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:18:15,487 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:15,484 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-02-16T14:18:15,487 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:15,566 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:15,566 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:15,625 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,625 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,625 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,639 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,633 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,639 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,648 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,646 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,648 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,655 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,650 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,655 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,660 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,657 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,660 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,672 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,680 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:15,681 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,680 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,681 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,685 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,680 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,680 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:15,690 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:15,685 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,693 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,687 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,682 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,690 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:15,710 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-02-16T14:18:15,703 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,693 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,723 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,710 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-02-16T14:18:15,710 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:15,741 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:15,723 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,747 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,718 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,741 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:15,747 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,749 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,758 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:15,757 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,774 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:15,758 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:15,780 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:15,774 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:15,773 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,780 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:15,788 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-02-16T14:18:15,795 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,784 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,798 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:15,795 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:15,805 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,793 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,788 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-02-16T14:18:15,827 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:15,805 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:15,844 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,798 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:15,827 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:15,808 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,844 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:15,871 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,864 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,871 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:15,881 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,873 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,881 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:15,893 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,897 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:15,897 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,897 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:15,901 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:15,899 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,901 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:15,904 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-02-16T14:18:15,902 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,905 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:15,904 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-02-16T14:18:15,905 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:15,921 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:15,921 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:17,014 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:17,012 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:17,014 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:17,020 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:17,015 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:17,020 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:17,032 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:17,030 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:17,032 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:17,044 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:17,036 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:17,044 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:17,047 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:17,046 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:17,047 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:17,064 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:17,067 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:17,067 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:17,067 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:17,070 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:17,068 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:17,070 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:17,073 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-02-16T14:18:17,074 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:17,072 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:17,081 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:17,074 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:17,073 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-02-16T14:18:17,081 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:27,799 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:18:27,799 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:18:28,278 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:18:28,278 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:18:28,966 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:18:28,966 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:18:32,106 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:32,107 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]7492
2022-02-16T14:18:32,112 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:32,112 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:32,112 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:32,123 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:18:32,120 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:32,123 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:18:32,129 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988712129
2022-02-16T14:18:32,129 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988712129
2022-02-16T14:18:32,129 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:18:32,132 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:32,594 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:32,597 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]41624
2022-02-16T14:18:32,602 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:32,602 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:32,602 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:32,614 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:18:32,612 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:32,614 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:18:32,630 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988712630
2022-02-16T14:18:32,630 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:18:32,630 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988712630
2022-02-16T14:18:32,637 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:33,115 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:33,116 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]37288
2022-02-16T14:18:33,121 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:33,121 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:33,121 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:33,132 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:18:33,129 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:33,132 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:18:33,142 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988713142
2022-02-16T14:18:33,142 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988713142
2022-02-16T14:18:33,142 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:18:33,151 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:34,032 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:34,032 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:34,032 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:34,054 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:34,048 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:34,054 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:34,063 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:34,061 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:34,063 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:34,068 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:34,065 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:34,068 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:34,073 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:34,069 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:34,073 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:34,074 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:34,084 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:34,084 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:34,084 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:34,088 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:34,086 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:34,088 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:34,105 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-02-16T14:18:34,101 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:34,107 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:34,107 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:18:34,105 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-02-16T14:18:34,137 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:34,137 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:18:34,654 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:34,653 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:34,654 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:34,668 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:34,662 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:34,668 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:34,681 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:34,679 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:34,681 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:34,684 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:34,683 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:34,684 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:34,696 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:34,686 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:34,696 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:34,709 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:34,699 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:34,709 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:34,723 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:34,715 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:34,738 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:34,723 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:34,747 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-02-16T14:18:34,738 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:18:34,736 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:34,752 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:34,747 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-02-16T14:18:34,752 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:18:35,183 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:35,182 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:35,183 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:35,188 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:35,183 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:35,188 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:35,197 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:35,196 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:35,197 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:35,202 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:35,199 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:35,202 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:35,218 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:35,218 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:35,218 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:35,224 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:35,232 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:35,235 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:35,233 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:35,235 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:35,259 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:35,254 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:35,259 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:35,262 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-02-16T14:18:35,261 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:18:35,263 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:35,262 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-02-16T14:18:35,266 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:35,263 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:18:35,266 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:18:36,500 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:18:36,500 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:18:36,724 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:18:36,724 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:18:36,802 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:18:36,802 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:18:36,923 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:18:36,923 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:18:38,088 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:18:38,088 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:18:41,495 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,496 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,498 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]23468
2022-02-16T14:18:41,510 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,502 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]28696
2022-02-16T14:18:41,514 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,510 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,520 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:18:41,510 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,514 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,524 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:18:41,514 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,522 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,520 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:18:41,536 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721536
2022-02-16T14:18:41,525 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,524 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:18:41,545 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721545
2022-02-16T14:18:41,536 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:18:41,536 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721536
2022-02-16T14:18:41,545 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721545
2022-02-16T14:18:41,545 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:18:41,557 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,565 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,786 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,802 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]33684
2022-02-16T14:18:41,818 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,818 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,818 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:41,822 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:18:41,820 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,822 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:18:41,829 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721829
2022-02-16T14:18:41,829 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988721829
2022-02-16T14:18:41,829 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:18:41,832 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,980 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:42,000 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]43296
2022-02-16T14:18:42,008 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:42,005 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:42,013 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:42,008 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:42,020 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:18:42,020 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:18:42,029 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988722029
2022-02-16T14:18:42,029 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988722029
2022-02-16T14:18:42,029 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:18:42,036 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:42,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:42,942 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]17228
2022-02-16T14:18:42,955 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:42,954 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:42,955 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:18:42,959 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:18:42,957 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:42,959 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:18:42,965 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988722965
2022-02-16T14:18:42,965 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988722965
2022-02-16T14:18:42,965 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:18:42,968 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:43,757 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:43,757 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:43,757 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:43,766 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:43,760 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:43,766 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:43,776 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:43,774 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:43,776 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:43,781 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:43,778 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:43,799 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:43,781 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:43,799 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:43,799 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:43,801 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:43,798 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:43,793 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:43,801 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:43,807 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:43,799 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:43,806 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:43,812 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:43,804 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:43,807 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:43,826 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:43,812 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:43,828 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:43,811 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:43,826 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:43,832 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:43,823 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:43,830 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:43,828 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:43,838 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-02-16T14:18:43,834 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:43,832 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:43,838 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-02-16T14:18:43,844 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:43,836 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:43,847 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:43,839 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:43,844 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:43,852 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:43,847 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:18:43,850 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:43,872 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:43,852 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:43,874 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-02-16T14:18:43,872 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:18:43,871 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:43,878 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:43,874 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-02-16T14:18:43,878 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:18:43,934 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:43,934 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:18:44,108 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:44,107 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:44,108 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:44,123 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:44,113 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:44,123 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:44,127 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:44,125 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:44,127 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:44,131 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:44,130 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:44,131 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:44,135 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:44,134 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:44,135 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:44,138 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:44,142 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:44,141 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:44,142 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:44,157 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:44,155 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:44,161 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:44,157 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:44,162 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-02-16T14:18:44,161 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:18:44,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:44,179 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:44,162 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-02-16T14:18:44,179 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:18:44,285 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:44,284 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:44,285 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:44,291 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:44,285 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:44,291 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:44,300 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:44,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:44,300 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:44,305 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:44,302 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:44,305 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:44,306 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:44,306 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:44,306 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:44,312 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:44,308 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:44,324 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:44,312 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:44,325 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:44,324 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:18:44,322 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:44,325 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:44,337 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-02-16T14:18:44,334 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:44,339 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:44,337 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-02-16T14:18:44,339 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:18:45,064 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:45,063 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:45,064 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:18:45,078 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:45,071 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:45,078 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:18:45,089 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:45,087 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:45,089 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:18:45,094 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:45,092 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:45,094 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:18:45,107 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:45,097 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:45,107 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:18:45,118 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:45,109 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:45,118 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:45,121 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:45,118 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:45,121 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:45,126 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-02-16T14:18:45,123 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:45,129 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:45,126 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-02-16T14:18:45,129 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:18:45,145 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:18:45,145 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:19:08,110 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:19:08,110 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:19:08,762 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:19:08,762 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:19:09,284 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:19:09,284 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:19:13,412 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:13,416 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41828
2022-02-16T14:19:13,421 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:13,421 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:13,421 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:13,422 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:19:13,422 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:13,422 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:19:13,432 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988753432
2022-02-16T14:19:13,432 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988753432
2022-02-16T14:19:13,432 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:19:13,435 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:13,851 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:13,853 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]19884
2022-02-16T14:19:13,858 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:13,858 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:13,866 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:13,858 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:13,870 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:19:13,870 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:19:13,874 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988753874
2022-02-16T14:19:13,874 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988753874
2022-02-16T14:19:13,874 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:19:13,876 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:14,763 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:14,770 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]39232
2022-02-16T14:19:14,777 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:14,777 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:14,777 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:14,796 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:19:14,788 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:14,796 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:19:14,809 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988754809
2022-02-16T14:19:14,809 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988754809
2022-02-16T14:19:14,809 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:19:14,841 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:15,725 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:15,725 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:15,725 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:15,738 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:15,730 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:15,738 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:15,748 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:15,745 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:15,748 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:15,765 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:15,750 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:15,765 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:15,773 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:15,771 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:15,773 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:15,779 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:19:15,775 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:15,779 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:19:15,781 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:19:15,779 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:15,781 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:19:15,803 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2022-02-16T14:19:15,803 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:19:15,796 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:15,804 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:19:15,803 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:19:15,803 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2022-02-16T14:19:15,804 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:19:16,112 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:16,111 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:16,112 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:16,137 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:16,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:16,137 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:16,148 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:16,145 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:16,150 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:16,148 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:16,186 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:16,170 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:16,186 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:16,203 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:16,194 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:16,203 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:16,222 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:19:16,211 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:16,222 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:19:16,237 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:19:16,230 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:16,237 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:19:16,259 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-02-16T14:19:16,245 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:16,266 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:19:16,271 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:19:16,259 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-02-16T14:19:16,271 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:19:16,266 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:19:17,020 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:17,018 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:17,020 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:17,027 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:17,020 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:17,027 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:17,036 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:17,034 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:17,036 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:17,042 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:17,038 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:17,042 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:17,047 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:17,044 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:17,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:17,047 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:17,064 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:17,073 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:19:17,073 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:17,073 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:19:17,076 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:19:17,075 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:17,076 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:19:17,082 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 55 seconds.
2022-02-16T14:19:17,081 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:17,098 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:19:17,082 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 55 seconds.
2022-02-16T14:19:17,098 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:19:17,144 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:19:17,144 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:19:17,854 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:19:17,854 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:19:17,887 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:19:17,887 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:19:18,167 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:19:18,167 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:19:18,354 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:19:18,354 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:19:19,145 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:19:19,145 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:19:24,429 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,431 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]52600
2022-02-16T14:19:24,436 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,436 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,436 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,446 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:19:24,444 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,446 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:19:24,452 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764452
2022-02-16T14:19:24,452 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764452
2022-02-16T14:19:24,452 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:19:24,455 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,559 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,563 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]50876
2022-02-16T14:19:24,568 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,567 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,568 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,575 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,580 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:19:24,580 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:19:24,589 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764589
2022-02-16T14:19:24,589 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:19:24,589 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764589
2022-02-16T14:19:24,615 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,638 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,656 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]52244
2022-02-16T14:19:24,670 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,670 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,670 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,684 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:19:24,673 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,684 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:19:24,689 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764689
2022-02-16T14:19:24,687 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,689 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764689
2022-02-16T14:19:24,689 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]21348
2022-02-16T14:19:24,693 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,689 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:19:24,693 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:24,720 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:19:24,693 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,712 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,729 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,720 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:19:24,746 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764746
2022-02-16T14:19:24,746 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:19:24,746 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988764746
2022-02-16T14:19:24,750 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:27,056 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,055 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,056 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,076 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,070 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,076 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,085 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,083 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,085 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,096 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,096 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,107 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,101 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,107 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,115 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,124 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:19:27,123 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,124 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:19:27,129 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:19:27,125 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,129 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:19:27,132 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2022-02-16T14:19:27,130 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,134 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:19:27,132 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2022-02-16T14:19:27,134 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:19:27,162 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:19:27,162 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:19:27,286 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,285 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,286 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,303 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,297 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,303 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,312 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,310 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,312 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,316 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,314 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,316 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,320 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,317 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,320 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,321 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,327 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:19:27,325 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,327 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:19:27,336 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:19:27,329 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,349 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,336 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:19:27,353 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-02-16T14:19:27,353 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:27,355 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:19:27,353 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-02-16T14:19:27,355 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:19:27,402 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:19:27,402 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:19:27,456 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,455 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,456 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,460 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,457 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,460 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,464 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,462 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,464 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,469 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,466 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,469 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,486 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,480 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,486 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,488 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,494 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:19:27,492 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,494 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:19:27,498 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:19:27,495 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,498 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:19:27,512 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-02-16T14:19:27,513 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:19:27,505 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,514 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:19:27,513 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:19:27,512 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-02-16T14:19:27,514 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:19:27,623 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,622 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,623 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:27,632 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,624 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,632 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:27,642 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,640 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,642 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:27,645 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,644 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,645 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:27,650 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,647 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,650 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:27,652 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,656 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:19:27,655 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,656 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:19:27,672 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:19:27,658 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,672 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:19:27,677 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-02-16T14:19:27,675 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,679 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:19:27,677 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-02-16T14:19:27,679 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:19:27,764 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:27,766 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29660
2022-02-16T14:19:27,771 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:27,771 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:27,771 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:19:27,784 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:19:27,779 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:27,784 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:19:27,801 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988767801
2022-02-16T14:19:27,801 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988767801
2022-02-16T14:19:27,814 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:19:27,801 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:19:27,814 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:19:27,821 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:29,912 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:29,911 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:29,912 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:19:29,923 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:29,916 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:29,923 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:19:29,934 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:29,932 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:29,934 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:19:29,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:29,935 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:29,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:19:29,949 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:29,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:29,949 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:19:29,956 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:29,959 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:29,961 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:29,965 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:19:29,964 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:29,978 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:19:29,965 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:19:29,986 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:19:29,978 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:19:29,973 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:29,995 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:19:29,998 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:19:30,000 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:19:30,006 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T14:19:29,986 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:19:30,015 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 55 seconds.
2022-02-16T14:19:30,008 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T14:19:30,017 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:19:30,015 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 55 seconds.
2022-02-16T14:19:30,017 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:20:10,814 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:20:10,814 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T14:20:11,281 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:20:11,281 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T14:20:12,103 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:20:12,103 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T14:20:15,103 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:15,103 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]36652
2022-02-16T14:20:15,115 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:15,115 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:15,115 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:15,119 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:20:15,117 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:15,119 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T14:20:15,129 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988815129
2022-02-16T14:20:15,129 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988815129
2022-02-16T14:20:15,130 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:20:15,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:15,486 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:15,487 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]22132
2022-02-16T14:20:15,492 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:15,492 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:15,492 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:15,502 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:20:15,499 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:15,502 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T14:20:15,509 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988815509
2022-02-16T14:20:15,509 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988815509
2022-02-16T14:20:15,509 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:20:15,514 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:16,502 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:16,505 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]39104
2022-02-16T14:20:16,518 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:16,518 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:16,518 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:16,523 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:20:16,521 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:16,523 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T14:20:16,530 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988816530
2022-02-16T14:20:16,530 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988816530
2022-02-16T14:20:16,530 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:20:16,548 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:17,319 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:17,318 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:17,319 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:17,333 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:17,324 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:17,333 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:17,345 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:17,341 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:17,345 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:17,379 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:17,347 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:17,387 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:17,390 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:17,379 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:17,400 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:17,398 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:17,400 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:17,402 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:17,406 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:20:17,406 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:17,406 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T14:20:17,423 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:20:17,410 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:20:17,423 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T14:20:17,433 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2022-02-16T14:20:17,431 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:20:17,435 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:20:17,437 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:20:17,433 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2022-02-16T14:20:17,437 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T14:20:17,435 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T14:20:17,714 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:17,713 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:17,714 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:17,721 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:17,715 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:17,721 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:17,730 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:17,728 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:17,730 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:17,735 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:17,732 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:17,745 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:17,755 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:17,735 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:17,760 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:17,757 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:17,760 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:17,761 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:17,764 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:20:17,764 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:17,772 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:20:17,764 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T14:20:17,785 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:20:17,772 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T14:20:17,769 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:20:17,797 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:20:17,785 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T14:20:17,805 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-02-16T14:20:17,803 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:20:17,813 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:20:17,805 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-02-16T14:20:17,813 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T14:20:18,815 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:18,814 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:18,815 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:18,826 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:18,821 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:18,826 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:18,836 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:18,834 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:18,836 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:18,860 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:18,839 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:18,860 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:18,875 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:18,868 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:18,875 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:18,878 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:18,884 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:20:18,884 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T14:20:18,887 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:20:18,884 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:18,894 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:20:18,887 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T14:20:18,900 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 89 seconds.
2022-02-16T14:20:18,894 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T14:20:18,890 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:18,910 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:20:18,900 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 89 seconds.
2022-02-16T14:20:18,910 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T14:20:22,151 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:20:22,151 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T14:20:22,366 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:20:22,366 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T14:20:22,523 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:20:22,523 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T14:20:22,728 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:20:22,728 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T14:20:25,033 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:20:25,033 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T14:20:29,512 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,515 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]33272
2022-02-16T14:20:29,524 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,523 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,524 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,534 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:20:29,533 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,534 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T14:20:29,541 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829540
2022-02-16T14:20:29,541 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:20:29,541 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829540
2022-02-16T14:20:29,544 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,547 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]54724
2022-02-16T14:20:29,565 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,564 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,565 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,571 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:20:29,568 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,571 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T14:20:29,582 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829582
2022-02-16T14:20:29,582 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829582
2022-02-16T14:20:29,582 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:20:29,595 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,879 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,881 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]11404
2022-02-16T14:20:29,884 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,884 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,884 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,898 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:20:29,895 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,898 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T14:20:29,903 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829903
2022-02-16T14:20:29,903 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:20:29,903 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988829903
2022-02-16T14:20:29,906 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,975 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,984 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]14172
2022-02-16T14:20:29,987 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,986 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,987 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:29,995 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:20:29,992 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,995 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T14:20:30,006 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988830006
2022-02-16T14:20:30,006 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:20:30,006 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988830006
2022-02-16T14:20:30,010 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:31,821 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:31,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]43764
2022-02-16T14:20:31,833 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:31,833 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:31,833 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T14:20:31,842 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:20:31,840 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:31,842 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T14:20:31,849 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988831849
2022-02-16T14:20:31,849 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644988831849
2022-02-16T14:20:31,849 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:20:31,852 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:31,987 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,000 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:31,987 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,000 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,011 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,000 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:31,987 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,020 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,011 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,023 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,004 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,020 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,036 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,017 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,034 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,023 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,049 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,043 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,036 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,054 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,049 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,057 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,054 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,076 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,050 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,073 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,057 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,078 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,083 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:20:32,076 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,079 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,088 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:20:32,083 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T14:20:32,100 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:20:32,083 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,087 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,100 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T14:20:32,106 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2022-02-16T14:20:32,102 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,088 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T14:20:32,108 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:20:32,108 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:20:32,106 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2022-02-16T14:20:32,104 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:32,108 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T14:20:32,114 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2022-02-16T14:20:32,108 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T14:20:32,112 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:32,118 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:20:32,114 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2022-02-16T14:20:32,118 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T14:20:32,169 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:20:32,169 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:20:32,169 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T14:20:32,169 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T14:20:32,221 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,220 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,221 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,234 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,224 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,234 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,246 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,246 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,257 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,248 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,257 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,268 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,266 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,268 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,284 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:20:32,275 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,295 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:20:32,284 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T14:20:32,298 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:20:32,295 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T14:20:32,291 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,298 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T14:20:32,309 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2022-02-16T14:20:32,307 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:32,310 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:20:32,309 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2022-02-16T14:20:32,310 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T14:20:32,494 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,493 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,494 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:32,502 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,497 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,502 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:32,511 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,510 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,511 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:32,516 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,513 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,516 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:32,519 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,517 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,519 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:32,527 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:20:32,521 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,527 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T14:20:32,541 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:20:32,537 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,541 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T14:20:32,544 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2022-02-16T14:20:32,542 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:32,546 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:20:32,544 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2022-02-16T14:20:32,546 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T14:20:32,581 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:20:32,581 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T14:20:33,643 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:33,642 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:33,643 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T14:20:33,649 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:33,643 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:33,649 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T14:20:33,660 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:33,657 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:33,660 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T14:20:33,671 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:33,663 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:33,671 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T14:20:33,683 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:33,677 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:33,683 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T14:20:33,685 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:33,697 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:20:33,696 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:33,697 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T14:20:33,700 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:20:33,698 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:33,700 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T14:20:33,704 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 89 seconds.
2022-02-16T14:20:33,705 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:20:33,702 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:33,710 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T14:20:33,705 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T14:20:33,704 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 89 seconds.
2022-02-16T14:20:33,710 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:21:04,314 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T15:21:04,314 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T15:21:04,425 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T15:21:04,425 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T15:21:05,195 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216141622853-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T15:21:05,195 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216141622853-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T15:21:05,222 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216141622853-startup.cfg",
  "modelCount": 1,
  "created": 1644988582854,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T15:21:05,222 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216141622853-startup.cfg",
  "modelCount": 1,
  "created": 1644988582854,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T15:21:05,243 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216141622853-startup.cfg
2022-02-16T15:21:05,243 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216141622853-startup.cfg
2022-02-16T15:21:05,250 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216141622853-startup.cfg validated successfully
2022-02-16T15:21:05,250 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216141622853-startup.cfg validated successfully
2022-02-16T15:21:58,163 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T15:21:58,163 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T15:21:58,168 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:21:58,168 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:21:58,174 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:21:58,174 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:21:58,176 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T15:21:58,176 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T15:21:58,179 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T15:21:58,179 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T15:21:58,211 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:21:58,211 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:21:58,211 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:21:58,211 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:21:58,211 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:21:58,215 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T15:21:58,217 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:21:58,211 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:21:58,211 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:21:58,211 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:21:58,217 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:21:58,215 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T15:21:58,233 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:21:58,234 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:21:58,233 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:21:58,234 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:21:58,258 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:21:58,258 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:21:59,307 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T15:21:59,307 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T15:21:59,316 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T15:21:59,316 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T15:21:59,329 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T15:21:59,329 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T15:21:59,331 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T15:21:59,331 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T15:21:59,334 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T15:21:59,334 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T15:22:00,596 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T15:22:00,596 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T15:22:05,758 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,760 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.811569213867188|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,768 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.03315353393555|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,770 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.5|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,771 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2238.7578125|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,773 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13939.2734375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:05,775 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:86.2|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992525
2022-02-16T15:22:08,996 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:08,998 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]43104
2022-02-16T15:22:08,999 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:09,000 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:09,000 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:09,000 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:09,010 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:09,010 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:09,036 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:09,042 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992529042
2022-02-16T15:22:09,042 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992529042
2022-02-16T15:22:09,115 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,272 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,280 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40196
2022-02-16T15:22:10,282 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,282 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,282 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,286 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:10,284 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,286 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:10,299 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530299
2022-02-16T15:22:10,299 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530299
2022-02-16T15:22:10,299 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:10,335 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,457 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,459 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]572
2022-02-16T15:22:10,463 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,463 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,463 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,467 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:10,465 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,467 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:10,477 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530477
2022-02-16T15:22:10,476 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:10,477 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530477
2022-02-16T15:22:10,518 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,730 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,733 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26972
2022-02-16T15:22:10,737 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,737 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,737 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,741 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:10,738 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,741 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:10,749 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530749
2022-02-16T15:22:10,749 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530749
2022-02-16T15:22:10,749 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:10,779 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,830 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]32868
2022-02-16T15:22:10,835 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,834 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,835 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,837 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:10,836 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,837 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:10,844 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530844
2022-02-16T15:22:10,844 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530844
2022-02-16T15:22:10,844 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:10,872 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,928 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]45768
2022-02-16T15:22:10,937 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,937 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,937 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:10,940 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:10,938 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,940 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:10,952 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530952
2022-02-16T15:22:10,952 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992530952
2022-02-16T15:22:10,952 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:10,983 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:11,090 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:11,092 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36052
2022-02-16T15:22:11,096 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:11,096 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:11,096 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:11,098 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:11,097 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:11,098 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:11,105 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992531105
2022-02-16T15:22:11,105 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992531105
2022-02-16T15:22:11,105 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:11,139 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:11,609 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:11,614 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:11,611 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:11,614 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:11,616 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:11,620 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:11,621 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:11,622 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:11,621 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:11,623 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:11,626 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:11,627 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:11,629 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:11,632 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:11,639 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:11,641 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:11,643 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:11,645 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:11,647 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:22:11,648 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:22:11,650 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 123, in handle
2022-02-16T15:22:11,652 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T15:22:11,654 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 112, in handle
2022-02-16T15:22:11,655 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T15:22:11,657 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 37, in initialize
2022-02-16T15:22:11,625 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:11,660 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T15:22:11,662 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:11,625 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:11,676 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]22448
2022-02-16T15:22:11,670 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-16T15:22:11,681 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:11,681 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     pretrained_model_name_or_path, return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs
2022-02-16T15:22:11,681 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:11,681 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:22:11,685 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:11,683 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 582, in from_pretrained
2022-02-16T15:22:11,685 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:11,685 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:11,698 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:11,687 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-02-16T15:22:11,698 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:11,716 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:11,718 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992531718
2022-02-16T15:22:11,713 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\configuration_utils.py", line 576, in get_config_dict
2022-02-16T15:22:11,718 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992531718
2022-02-16T15:22:11,718 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:11,741 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     user_agent=user_agent,
2022-02-16T15:22:11,716 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:11,749 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\file_utils.py", line 1794, in cached_path
2022-02-16T15:22:11,751 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     raise ValueError(f"unable to parse {url_or_filename} as a URL or as a local path")
2022-02-16T15:22:11,754 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - ValueError: unable to parse C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\config.json as a URL or as a local path
2022-02-16T15:22:11,757 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:11,757 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:11,759 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:11,759 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:11,762 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T15:22:11,762 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T15:22:11,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:11,792 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:11,792 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:11,792 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:11,792 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:12,796 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:12,796 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:13,732 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,731 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,732 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,738 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,733 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,738 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,741 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,740 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,741 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,746 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,743 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,746 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,760 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,758 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,760 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,762 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,767 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:13,766 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,767 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:13,769 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:13,768 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:13,769 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:13,773 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T15:22:13,771 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:13,774 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:13,773 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T15:22:13,774 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:13,792 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:13,792 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:13,920 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,921 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,926 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,921 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,925 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,921 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,931 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,927 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,931 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,926 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:13,935 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,935 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,934 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,929 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,935 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:13,940 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,935 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,943 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,938 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,937 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,943 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,948 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,940 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:13,967 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,946 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,968 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,945 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,967 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:13,973 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,948 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,971 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,976 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:13,969 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:13,973 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:13,982 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:13,976 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,976 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:13,994 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:13,978 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:13,992 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,982 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:13,999 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:13,994 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:13,998 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,001 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T15:22:14,001 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:13,999 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:14,003 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T15:22:13,999 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,004 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:14,001 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:14,001 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T15:22:14,004 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:14,003 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T15:22:14,028 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:14,028 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:14,054 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:14,054 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:14,210 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,211 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,211 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,211 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,218 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,216 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,218 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,222 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,220 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,222 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,227 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,224 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,227 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,239 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,229 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,239 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,241 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,245 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:14,244 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,245 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:14,247 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:14,246 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,247 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:14,250 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T15:22:14,250 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,252 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:14,250 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T15:22:14,252 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:14,315 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,316 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,326 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:14,316 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,326 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:14,316 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,343 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,337 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,343 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,347 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,347 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,351 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,349 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,351 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,364 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,353 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,364 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,365 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,368 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:14,368 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,368 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:14,372 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:14,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,372 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:14,375 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T15:22:14,374 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,377 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:14,375 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T15:22:14,377 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:14,401 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:14,401 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:14,404 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,403 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,404 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,409 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,405 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,409 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,412 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,411 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,412 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,417 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,414 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,417 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,430 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,428 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,430 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,431 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,435 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,437 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:14,436 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,437 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:14,440 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:14,438 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,440 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:14,443 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T15:22:14,443 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,444 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:14,443 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T15:22:14,444 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:14,457 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:14,457 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:14,530 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,531 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,531 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,531 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:14,539 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,537 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,539 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:14,542 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,540 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,542 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:14,547 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,544 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,547 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:14,550 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,549 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,550 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:14,552 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,571 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:14,569 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,571 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:14,573 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:14,571 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,573 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:14,577 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T15:22:14,577 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,579 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:14,577 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T15:22:14,579 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:14,589 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:14,589 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:14,784 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:14,784 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:15,016 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:15,016 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:15,016 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:15,016 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:15,281 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:15,281 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:15,392 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:15,392 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:15,461 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:15,461 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:15,587 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:15,587 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:19,943 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:19,945 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]28460
2022-02-16T15:22:19,950 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:19,950 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:19,950 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:19,954 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:19,952 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:19,954 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:19,962 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992539962
2022-02-16T15:22:19,962 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:19,962 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992539962
2022-02-16T15:22:20,020 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:21,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:21,317 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]12332
2022-02-16T15:22:21,320 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:21,320 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:21,321 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:21,320 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:21,324 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:21,324 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:21,343 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992541343
2022-02-16T15:22:21,343 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:21,343 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992541343
2022-02-16T15:22:21,391 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,363 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,364 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]18332
2022-02-16T15:22:22,369 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,369 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,369 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,373 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:22,371 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,373 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:22,380 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542380
2022-02-16T15:22:22,380 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542380
2022-02-16T15:22:22,380 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:22,415 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,485 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,489 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]28888
2022-02-16T15:22:22,490 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,490 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,490 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,493 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,500 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:22,500 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:22,505 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,512 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27096
2022-02-16T15:22:22,514 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,514 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,515 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542515
2022-02-16T15:22:22,515 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,514 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,518 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:22,515 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542515
2022-02-16T15:22:22,515 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:22,518 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:22,567 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,574 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542574
2022-02-16T15:22:22,573 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:22,574 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542574
2022-02-16T15:22:22,593 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,688 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,690 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]57896
2022-02-16T15:22:22,694 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,694 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,694 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,697 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:22,696 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,697 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:22,703 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542703
2022-02-16T15:22:22,703 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542703
2022-02-16T15:22:22,703 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:22,721 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,961 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,963 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]33692
2022-02-16T15:22:22,967 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,967 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,967 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:22,971 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:22,969 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,971 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:22,978 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542978
2022-02-16T15:22:22,978 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992542978
2022-02-16T15:22:22,978 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:23,028 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:23,644 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:23,643 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:23,644 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:23,650 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:23,644 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:23,650 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:23,653 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:23,652 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:23,653 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:23,658 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:23,656 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:23,658 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:23,671 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:23,665 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:23,671 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:23,683 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:23,687 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:23,687 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:23,687 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:23,690 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:23,689 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:23,690 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:23,694 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T15:22:23,692 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:23,696 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:23,694 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-02-16T15:22:23,696 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:23,706 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:23,706 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:23,926 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:23,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]25288
2022-02-16T15:22:23,936 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:23,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:23,936 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:23,940 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:23,938 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:23,940 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:23,946 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992543946
2022-02-16T15:22:23,946 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992543946
2022-02-16T15:22:23,946 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:23,984 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:24,713 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:24,713 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:24,907 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:24,908 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:24,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:24,908 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:24,912 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:24,916 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:24,916 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:24,918 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:24,916 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:24,920 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:24,918 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:24,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:24,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:24,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:24,941 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:24,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:24,952 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:24,942 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:24,952 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:24,955 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:24,953 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:24,955 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:24,958 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:24,956 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:24,958 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:24,959 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:24,973 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T15:22:24,973 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:24,995 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:24,973 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-02-16T15:22:24,995 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:24,973 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:25,836 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:25,837 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:25,837 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:25,837 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:25,845 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:25,843 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:25,845 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:25,849 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:25,847 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:25,849 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:25,854 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:25,851 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:25,854 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:25,870 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:25,856 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:25,872 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:25,874 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:25,870 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:25,876 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:25,879 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:25,879 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:25,881 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:25,880 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:25,881 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:25,884 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T15:22:25,883 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:25,886 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:25,884 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-02-16T15:22:25,888 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:25,886 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:25,888 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:25,986 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:25,986 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:26,042 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,043 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,043 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,043 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,050 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,048 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,051 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,050 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,053 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,057 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,057 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,057 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,061 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,059 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,061 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,064 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,062 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,064 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,070 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:26,066 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,070 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:26,080 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:26,081 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:26,080 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,081 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:26,080 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:26,085 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T15:22:26,082 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:26,087 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:26,085 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-02-16T15:22:26,087 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:26,113 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,113 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,114 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,113 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,118 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,116 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,118 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,121 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,119 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,121 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,125 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,123 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,125 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,128 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,127 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,128 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,143 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:26,142 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,143 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:26,146 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:26,144 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,146 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:26,148 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T15:22:26,148 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,150 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:26,148 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-02-16T15:22:26,150 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:26,156 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:26,156 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:26,218 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,219 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,220 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,219 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,230 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,226 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,230 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,234 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,231 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,234 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,239 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,236 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,239 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,250 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,248 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,250 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,252 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,255 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:26,255 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:26,257 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:26,255 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,257 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:26,259 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T15:22:26,258 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,261 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:26,259 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-02-16T15:22:26,261 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:26,269 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,275 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:26,267 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,275 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:26,269 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,295 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,290 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,295 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,299 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,296 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,299 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,309 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,306 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,309 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,313 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,311 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,313 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,333 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,342 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:26,342 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:26,344 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:26,342 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,344 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:26,353 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T15:22:26,346 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,355 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:26,353 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-02-16T15:22:26,355 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:26,370 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:26,370 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:26,809 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,810 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,811 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,810 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:26,819 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,817 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,819 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:26,821 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,824 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,825 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,824 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:26,830 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,826 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,830 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,832 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,830 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:26,836 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,834 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,836 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:26,839 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,853 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:26,853 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:26,853 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:26,858 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:26,856 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:26,858 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:26,861 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T15:22:26,859 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:26,863 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:26,861 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-02-16T15:22:26,863 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:26,871 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:26,888 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:26,871 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:26,888 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:27,096 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:27,096 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:27,156 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:27,156 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:27,288 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:27,288 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:27,373 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:27,373 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:27,892 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:27,892 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:29,985 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:29,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]25416
2022-02-16T15:22:29,990 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:29,990 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:29,990 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:29,993 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:29,991 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:29,993 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:29,999 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992549999
2022-02-16T15:22:29,999 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992549999
2022-02-16T15:22:29,999 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:30,014 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:32,268 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:32,273 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]34392
2022-02-16T15:22:32,274 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:32,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:32,274 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:32,279 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:32,276 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:32,279 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:32,302 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992552302
2022-02-16T15:22:32,302 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:32,302 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992552302
2022-02-16T15:22:32,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,181 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:33,180 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:33,181 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:33,186 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:33,184 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,181 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:33,188 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40772
2022-02-16T15:22:33,192 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,186 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:33,190 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:33,193 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:33,192 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,195 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:33,192 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,193 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:33,199 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:33,195 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:33,193 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:33,196 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,204 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553204
2022-02-16T15:22:33,203 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:33,199 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:33,217 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:33,204 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553204
2022-02-16T15:22:33,204 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:33,215 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:33,220 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,217 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:33,222 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:33,226 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:33,225 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:33,226 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:33,229 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:33,227 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:33,229 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:33,233 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-02-16T15:22:33,232 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:33,244 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:33,233 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-02-16T15:22:33,244 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:33,289 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:33,289 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:33,665 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,667 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36660
2022-02-16T15:22:33,672 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,672 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,672 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,676 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:33,673 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,676 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:33,681 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553681
2022-02-16T15:22:33,681 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553681
2022-02-16T15:22:33,682 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:33,684 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,695 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,697 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]26420
2022-02-16T15:22:33,698 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,698 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,698 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,702 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:33,700 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,702 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:33,712 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:33,713 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553713
2022-02-16T15:22:33,713 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553713
2022-02-16T15:22:33,720 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,855 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,860 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]15072
2022-02-16T15:22:33,862 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,862 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,862 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:33,865 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:33,865 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,865 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:33,871 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553871
2022-02-16T15:22:33,871 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992553871
2022-02-16T15:22:33,872 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:33,875 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:34,053 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:34,055 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]40084
2022-02-16T15:22:34,059 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:34,059 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:34,059 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:34,062 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:34,060 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:34,062 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:34,073 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992554073
2022-02-16T15:22:34,073 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:34,073 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992554073
2022-02-16T15:22:34,078 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:34,371 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:34,372 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34360
2022-02-16T15:22:34,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:34,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:34,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:34,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:34,382 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:34,382 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:34,386 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992554386
2022-02-16T15:22:34,386 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992554386
2022-02-16T15:22:34,386 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:34,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:35,250 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:35,250 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:35,495 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:35,494 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:35,495 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:35,501 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:35,495 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:35,501 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:35,503 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:35,519 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:35,520 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:35,522 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:35,524 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:35,529 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:35,531 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:35,519 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:35,537 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:35,533 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:35,537 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:35,550 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:35,540 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:35,550 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:35,552 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:35,556 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:35,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:35,556 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:35,560 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:35,558 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:35,560 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:35,564 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-02-16T15:22:35,562 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:35,565 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:35,564 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-02-16T15:22:35,565 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:35,654 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:35,654 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:36,324 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,323 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,324 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,330 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,324 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,330 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,332 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,331 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,332 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,337 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,334 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,337 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,352 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,346 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,352 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,354 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,357 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:36,357 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,357 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:36,360 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:36,359 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,360 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:36,363 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-02-16T15:22:36,361 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:36,365 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:36,363 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-02-16T15:22:36,365 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:36,376 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:36,376 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:36,442 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,441 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,442 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,446 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,442 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,446 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,449 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,446 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,449 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,455 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,451 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,455 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,457 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,456 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,457 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,463 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:36,459 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,463 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:36,473 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:36,472 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,473 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:36,477 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-02-16T15:22:36,475 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,479 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:36,477 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-02-16T15:22:36,479 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:36,571 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:36,571 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:36,680 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,679 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,680 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,686 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,680 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,686 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,691 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,688 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,691 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,697 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,694 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,697 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,701 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,699 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,701 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,703 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,707 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:36,707 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,707 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:36,724 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:36,722 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,724 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:36,728 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-02-16T15:22:36,726 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:36,730 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:36,728 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-02-16T15:22:36,730 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:36,739 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:36,739 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:36,818 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,817 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,818 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:36,825 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,818 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,825 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:36,829 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,827 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,829 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:36,834 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,831 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,834 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:36,847 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,836 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,847 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:36,849 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,853 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:36,853 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,853 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:36,856 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:36,855 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,856 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:36,859 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-02-16T15:22:36,858 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:36,861 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:36,859 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-02-16T15:22:36,861 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:36,908 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:36,908 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:37,029 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:37,029 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:37,029 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:37,037 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:37,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:37,037 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:37,040 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:37,038 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:37,040 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:37,045 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:37,042 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:37,045 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:37,047 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:37,046 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:37,047 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:37,052 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:37,049 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:37,052 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:37,062 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:37,060 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:37,064 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:37,062 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:37,069 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-02-16T15:22:37,064 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:37,064 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:37,072 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:37,069 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-02-16T15:22:37,072 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:37,426 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:37,432 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:37,427 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:37,432 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:37,435 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:37,433 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:37,435 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:37,438 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:37,436 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:37,438 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:37,444 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:37,440 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:37,444 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:37,458 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:37,456 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:37,458 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:37,460 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:37,464 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:37,464 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:37,464 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:37,468 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:37,466 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:37,468 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:37,472 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-02-16T15:22:37,471 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:37,474 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:37,474 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:37,472 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-02-16T15:22:37,474 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:37,474 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:37,570 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:37,570 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:38,372 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:38,372 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:38,499 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:38,499 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:38,746 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:38,746 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:38,877 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:38,877 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:39,104 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:39,104 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:39,495 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:39,495 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:40,291 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:40,293 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]12600
2022-02-16T15:22:40,297 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:40,296 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:40,297 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:40,300 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:40,298 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:40,300 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:40,306 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992560306
2022-02-16T15:22:40,306 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:40,306 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992560306
2022-02-16T15:22:40,311 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:43,384 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:43,384 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:43,384 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:43,391 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:43,385 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:43,391 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:43,395 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:43,393 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:43,395 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:43,401 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:43,397 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:43,401 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:43,404 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:43,402 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:43,404 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:43,406 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:43,410 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:43,410 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:43,410 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:43,424 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:43,422 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:43,424 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:43,428 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-02-16T15:22:43,426 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:43,429 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:43,428 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-02-16T15:22:43,429 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:43,442 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:43,442 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:43,614 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:43,616 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29064
2022-02-16T15:22:43,620 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:43,620 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:43,622 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:43,620 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:43,636 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:43,636 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:43,650 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992563650
2022-02-16T15:22:43,650 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992563650
2022-02-16T15:22:43,650 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:43,653 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,430 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,431 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]34768
2022-02-16T15:22:44,435 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,435 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,435 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,439 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:44,436 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,439 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:44,444 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564444
2022-02-16T15:22:44,444 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564444
2022-02-16T15:22:44,444 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:44,446 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,725 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,727 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]12728
2022-02-16T15:22:44,732 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,732 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,732 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,736 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:44,734 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,736 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:44,743 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564743
2022-02-16T15:22:44,743 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564743
2022-02-16T15:22:44,748 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:44,748 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,806 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,807 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]27060
2022-02-16T15:22:44,811 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,811 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,814 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:44,813 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,814 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:44,820 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564820
2022-02-16T15:22:44,820 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564820
2022-02-16T15:22:44,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:44,823 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,901 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,905 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]19648
2022-02-16T15:22:44,907 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,907 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,907 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:44,911 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:44,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,911 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:44,917 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564917
2022-02-16T15:22:44,917 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992564917
2022-02-16T15:22:44,918 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:44,921 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:45,180 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:45,184 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]41620
2022-02-16T15:22:45,187 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:45,187 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:45,187 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:45,190 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:45,189 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:45,190 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:45,196 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992565196
2022-02-16T15:22:45,196 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992565196
2022-02-16T15:22:45,196 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:45,199 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:46,441 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:46,441 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:46,791 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:46,790 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:46,791 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:46,797 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:46,791 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:46,799 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:46,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:46,797 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:46,833 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:46,833 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:46,833 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:46,858 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:46,835 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:46,861 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:46,863 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:46,865 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:46,868 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:46,870 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:46,858 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:46,874 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:46,872 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:46,874 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:46,876 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:46,907 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:46,906 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:46,907 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:46,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:46,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:22:46,938 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:46,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:22:46,963 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:46,963 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-02-16T15:22:46,963 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:22:46,963 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-02-16T15:22:47,023 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:47,023 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:22:47,139 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:47,140 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]16508
2022-02-16T15:22:47,145 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:47,145 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:47,145 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:47,149 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:47,147 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:47,149 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:47,155 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992567155
2022-02-16T15:22:47,155 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992567155
2022-02-16T15:22:47,155 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:47,158 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:47,215 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,214 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,215 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,227 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,215 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,227 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,231 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,229 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,231 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,236 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,233 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,236 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,240 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,238 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,240 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,242 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,257 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:47,256 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,257 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:47,260 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:47,258 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,260 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:47,264 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-02-16T15:22:47,262 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,265 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:47,264 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-02-16T15:22:47,265 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:22:47,293 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:47,293 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:22:47,693 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,692 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,693 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,698 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,693 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,698 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,701 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,699 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,701 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,705 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,703 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,705 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,716 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,714 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,716 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,718 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,721 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:47,721 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,721 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:47,725 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:47,723 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,725 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:47,729 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-02-16T15:22:47,727 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,730 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:47,729 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-02-16T15:22:47,730 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:22:47,743 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:47,743 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:22:47,812 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,812 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,818 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,812 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,818 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,822 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,822 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,828 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,824 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,828 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,831 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,831 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,841 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,844 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:47,844 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,844 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:47,848 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:47,846 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,848 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:47,851 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-02-16T15:22:47,849 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,852 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:47,851 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-02-16T15:22:47,852 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:22:47,855 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:47,855 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:22:47,907 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,912 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,912 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:47,915 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,913 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,915 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:47,919 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,917 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,919 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:47,925 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,922 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,925 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:47,938 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,936 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,939 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,938 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:47,941 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,945 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:47,945 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,945 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:47,949 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:47,948 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:47,949 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:47,951 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-02-16T15:22:47,951 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:47,954 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:47,951 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-02-16T15:22:47,968 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:47,954 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:22:47,968 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:22:48,153 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:48,152 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:48,153 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:48,165 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:48,153 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:48,165 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:48,179 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:48,173 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:48,179 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:48,186 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:48,181 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:48,186 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:48,198 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:48,188 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:48,198 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:48,200 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:48,204 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:48,204 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:48,204 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:48,207 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:48,206 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:48,207 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:48,211 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-02-16T15:22:48,210 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:48,213 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:48,211 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-02-16T15:22:48,213 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:22:48,231 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:48,231 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:22:48,997 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:48,998 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:48,998 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:48,998 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:49,006 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:49,004 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:49,006 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:49,010 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:49,008 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:49,010 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:49,015 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:49,012 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:49,015 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:49,019 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:49,017 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:49,019 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:49,031 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:49,035 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:49,035 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:49,035 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:49,039 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:49,037 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:49,039 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:49,043 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-02-16T15:22:49,042 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:49,045 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:49,043 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-02-16T15:22:49,050 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:49,045 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:22:49,050 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:22:49,981 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:49,981 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:22:50,279 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:50,279 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:22:50,412 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:50,413 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]30452
2022-02-16T15:22:50,416 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:50,418 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:50,420 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:50,420 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:50,422 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:50,422 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:22:50,427 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992570426
2022-02-16T15:22:50,426 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:50,427 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992570426
2022-02-16T15:22:50,431 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:50,740 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:50,740 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:22:50,906 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:50,906 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:22:50,966 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:50,966 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:22:51,238 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:51,238 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:22:52,075 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:52,075 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:22:54,580 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:54,579 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:54,580 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:22:54,586 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:54,581 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:54,586 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:22:54,590 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:54,587 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:54,590 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:22:54,595 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:54,592 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:54,595 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:22:54,599 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:54,597 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:54,599 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:22:54,609 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:54,614 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:54,613 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:54,614 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:54,617 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:54,615 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:54,617 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:54,621 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-02-16T15:22:54,619 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:54,623 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:54,621 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-02-16T15:22:54,623 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:22:54,789 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:54,789 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:22:57,231 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,232 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19000
2022-02-16T15:22:57,236 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,238 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,238 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,238 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,243 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:57,243 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:22:57,250 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577250
2022-02-16T15:22:57,249 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:57,250 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577250
2022-02-16T15:22:57,255 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,274 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,275 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40024
2022-02-16T15:22:57,277 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,277 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,277 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,285 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:57,279 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,285 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:22:57,289 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577289
2022-02-16T15:22:57,289 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577289
2022-02-16T15:22:57,289 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:57,295 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,312 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,327 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26228
2022-02-16T15:22:57,344 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,344 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,344 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,350 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:57,348 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,350 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:22:57,354 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577354
2022-02-16T15:22:57,354 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577354
2022-02-16T15:22:57,355 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:57,356 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,531 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41180
2022-02-16T15:22:57,533 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,533 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,533 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,536 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:57,534 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,536 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:22:57,541 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577541
2022-02-16T15:22:57,541 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577541
2022-02-16T15:22:57,541 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:57,543 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,663 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,665 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]40100
2022-02-16T15:22:57,673 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,673 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,673 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,678 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,703 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:57,703 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:22:57,707 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:57,707 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577707
2022-02-16T15:22:57,707 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577707
2022-02-16T15:22:57,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,890 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,891 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]25596
2022-02-16T15:22:57,903 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,903 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,903 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:57,907 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:57,905 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,907 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:22:57,913 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577913
2022-02-16T15:22:57,913 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992577913
2022-02-16T15:22:57,913 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:57,919 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:58,371 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:58,372 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]56988
2022-02-16T15:22:58,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:58,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:58,376 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:22:58,380 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:58,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:58,380 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:22:58,385 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992578385
2022-02-16T15:22:58,385 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992578385
2022-02-16T15:22:58,385 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:58,388 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:59,642 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:22:59,642 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:23:00,282 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,281 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,282 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,287 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,282 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,287 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,291 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,289 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,291 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,296 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,293 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,296 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,299 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,297 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,299 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,301 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,305 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:00,304 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,305 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:00,318 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:00,306 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,318 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:00,322 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-02-16T15:23:00,320 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,323 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:00,322 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-02-16T15:23:00,323 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:00,370 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:00,370 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:00,394 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,393 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,394 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,398 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,396 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,398 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,403 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,400 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,403 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,408 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,405 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,408 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,412 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,410 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,412 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,417 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:00,413 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,417 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:00,430 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:00,428 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,430 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:00,436 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-02-16T15:23:00,433 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,438 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:00,436 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-02-16T15:23:00,438 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:00,443 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:00,443 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:00,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,557 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,557 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,563 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,557 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,563 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,568 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,565 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,568 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,574 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,570 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,574 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,577 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,575 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,577 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,579 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,583 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:00,582 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,584 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,583 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:00,599 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:00,597 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,599 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:00,604 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-02-16T15:23:00,604 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:00,606 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:00,604 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-02-16T15:23:00,606 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:00,640 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:00,640 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:00,783 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,782 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,783 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,789 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,783 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,789 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,791 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,794 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,789 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,796 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,796 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,796 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,798 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,800 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,796 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,810 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,803 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:00,810 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,813 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,811 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:00,813 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,813 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:00,816 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:00,815 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:00,816 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:00,818 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:00,816 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:23:00,818 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:00,820 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-02-16T15:23:00,819 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:23:00,821 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:00,820 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-02-16T15:23:00,821 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:00,877 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:00,877 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:00,942 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,942 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,942 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,948 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,943 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,948 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,951 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,949 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,951 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,955 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,953 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,955 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,965 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,963 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,985 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,965 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:00,985 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:00,990 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,991 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:00,984 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,967 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,990 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:00,995 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:00,991 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:00,997 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:00,992 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,997 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:01,001 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-02-16T15:23:01,016 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:00,995 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:01,019 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:00,999 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,999 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:01,026 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:01,019 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:01,028 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:01,016 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:01,001 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-02-16T15:23:01,028 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:01,026 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:01,048 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:01,025 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:01,048 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:01,049 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:01,049 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:01,049 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:01,055 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-02-16T15:23:01,053 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:01,057 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:01,055 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-02-16T15:23:01,057 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:01,068 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:01,068 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:01,220 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:01,221 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:01,221 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:01,226 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:01,221 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:01,226 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:01,231 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:01,229 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:01,231 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:01,237 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:01,233 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:01,237 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:01,239 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:01,238 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:01,239 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:01,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:01,245 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:01,245 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:01,245 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:01,259 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:01,257 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:01,259 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:01,263 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-02-16T15:23:01,261 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:01,266 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:01,263 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-02-16T15:23:01,266 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:01,302 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:01,302 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:02,323 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,325 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.811477661132812|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,330 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.03324508666992|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,333 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.5|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,335 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:3076.546875|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,337 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:13101.48828125|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:02,339 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:81.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644992582
2022-02-16T15:23:03,184 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=26228)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 26228

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('26228',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('26228', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=30452)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 30452

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('30452',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('30452', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=40024)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 40024

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('40024',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('40024', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=19000)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 19000

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('19000',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('19000', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=25596)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 25596

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('25596',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('25596', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=56988)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 56988

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('56988',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('56988', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=41180)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 41180

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('41180',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('41180', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp949'>
OSError: [Errno 22] Invalid argument

2022-02-16T15:23:03,184 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=26228)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 26228

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('26228',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('26228', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=30452)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 30452

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('30452',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('30452', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=40024)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 40024

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('40024',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('40024', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=19000)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 19000

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('19000',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('19000', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=25596)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 25596

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('25596',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('25596', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=56988)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 56988

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('56988',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('56988', 0)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 679, in wrapper
    return fun(self, *args, **kwargs)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 933, in create_time
    user, system, created = cext.proc_times(self.pid)
ProcessLookupError: [Errno 3] assume no such process (originated from GetExitCodeProcess != STILL_ACTIVE)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 354, in _init
    self.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 710, in create_time
    self._create_time = self._proc.create_time()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\_pswindows.py", line 681, in wrapper
    raise convert_oserror(err, pid=self.pid, name=self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=41180)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 326, in __init__
    self._init(pid)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\psutil\__init__.py", line 367, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 41180

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('41180',)
--- Logging error ---
Traceback (most recent call last):
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1038, in emit
    self.flush()
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\logging\__init__.py", line 1018, in flush
    self.stream.flush()
OSError: [Errno 22] Invalid argument
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\metrics\process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('41180', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='cp949'>
OSError: [Errno 22] Invalid argument

2022-02-16T15:23:04,654 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:04,655 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]35352
2022-02-16T15:23:04,658 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:04,658 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:04,660 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:04,658 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:04,664 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:04,664 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:04,668 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992584668
2022-02-16T15:23:04,668 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992584668
2022-02-16T15:23:04,669 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:04,672 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:05,334 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:05,334 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:05,450 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:05,450 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:05,634 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:05,634 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:05,841 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:05,841 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:06,020 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:06,020 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:06,069 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:06,069 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:06,268 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:06,268 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:06,964 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:06,963 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:06,964 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:06,969 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:06,964 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:06,971 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:06,969 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:06,975 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:06,973 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:06,977 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:06,978 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:06,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:06,982 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:06,983 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:06,975 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:06,987 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:06,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:06,987 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:07,001 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:06,989 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:07,001 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:07,003 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:07,008 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:07,007 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:07,008 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:07,011 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:07,009 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:23:07,011 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:07,015 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-02-16T15:23:07,012 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:23:07,016 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:07,015 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-02-16T15:23:07,016 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:07,054 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:07,054 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:11,449 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,322 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,268 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,101 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,096 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:11,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:11,679 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:13,455 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]29572
2022-02-16T15:23:13,460 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,453 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27240
2022-02-16T15:23:13,461 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,452 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21672
2022-02-16T15:23:13,463 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,447 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]40016
2022-02-16T15:23:13,465 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,433 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]41300
2022-02-16T15:23:13,466 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,463 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,468 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:13,463 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,461 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,479 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:13,460 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,481 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:13,459 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,458 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]47660
2022-02-16T15:23:13,486 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,456 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]34088
2022-02-16T15:23:13,493 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,483 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,481 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:13,479 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:13,499 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593499
2022-02-16T15:23:13,499 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593499
2022-02-16T15:23:13,461 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,502 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593502
2022-02-16T15:23:13,477 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,468 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:13,466 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,511 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593511
2022-02-16T15:23:13,465 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,512 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:13,465 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,511 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:13,511 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593511
2022-02-16T15:23:13,510 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,466 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,527 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:13,502 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593502
2022-02-16T15:23:13,501 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,499 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:13,493 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,493 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,540 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:13,486 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:13,541 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:13,486 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,540 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:13,553 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593553
2022-02-16T15:23:13,540 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,530 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,530 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:13,527 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:13,520 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593562
2022-02-16T15:23:13,514 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,512 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:13,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593562
2022-02-16T15:23:13,566 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593566
2022-02-16T15:23:13,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:13,558 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:13,553 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593553
2022-02-16T15:23:13,542 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,541 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:13,577 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593576
2022-02-16T15:23:13,568 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,566 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:13,566 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593566
2022-02-16T15:23:13,577 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:13,577 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992593576
2022-02-16T15:23:13,593 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,574 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,599 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:15,030 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:23:15,030 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:23:16,238 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,237 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,238 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,243 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,238 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,243 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,247 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,245 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,247 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,252 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,249 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,252 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,255 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,254 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,255 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,257 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,269 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:16,268 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,269 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:16,272 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:16,270 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,272 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:16,275 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-02-16T15:23:16,273 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,276 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:16,275 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-02-16T15:23:16,276 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:16,301 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,300 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,301 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,303 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,304 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:16,301 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,304 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:16,303 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,305 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,313 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,313 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,313 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,316 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,315 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,316 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,319 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,317 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,319 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,322 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,333 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:16,332 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,333 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:16,336 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:16,334 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,336 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:16,339 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-02-16T15:23:16,339 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:16,341 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:16,339 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-02-16T15:23:16,341 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:16,393 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:16,393 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:16,398 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,397 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,398 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,402 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,400 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,402 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,408 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,405 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,408 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,412 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,409 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,412 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,415 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,412 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,415 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,431 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,430 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,433 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:16,417 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,431 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,437 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,434 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,433 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:16,441 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:16,437 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,443 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,436 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,441 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:16,447 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-02-16T15:23:16,439 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,445 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,459 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:16,443 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,464 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,448 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,447 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-02-16T15:23:16,464 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,472 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,459 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:16,468 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,472 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,475 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,478 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:16,479 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:16,478 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,479 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:16,478 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:16,498 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:16,480 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,498 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:16,500 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-02-16T15:23:16,499 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,501 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:16,500 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-02-16T15:23:16,505 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:16,501 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:16,505 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:16,558 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,559 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,559 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,564 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,559 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,564 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,567 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,566 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,567 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,573 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,569 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,580 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,593 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,573 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,600 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,598 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,600 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,602 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,606 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:16,606 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:16,608 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:16,606 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,608 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:16,612 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-02-16T15:23:16,611 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:16,613 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:16,612 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-02-16T15:23:16,613 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:16,627 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,631 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,633 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:16,626 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,633 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:16,631 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,638 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,630 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,627 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:16,642 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,638 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,644 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,634 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,642 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:16,648 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,640 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,646 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,644 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,655 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,650 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,648 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:16,670 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,655 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,677 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,651 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,670 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:16,693 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,667 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,685 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,677 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,694 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,700 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:16,693 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:16,696 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,704 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:16,700 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:16,706 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:16,700 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,704 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:16,709 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:16,704 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,708 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,706 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:16,715 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-02-16T15:23:16,711 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,709 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:16,729 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-02-16T15:23:16,715 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-02-16T15:23:16,713 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,733 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:16,729 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-02-16T15:23:16,727 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,737 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:16,733 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:16,737 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:16,745 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:16,745 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:16,789 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:16,789 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:18,833 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:18,834 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]41548
2022-02-16T15:23:18,838 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:18,838 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:18,838 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:18,842 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:18,840 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:18,842 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:18,848 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992598848
2022-02-16T15:23:18,848 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992598848
2022-02-16T15:23:18,849 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:18,852 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:20,104 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:20,104 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:20,104 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:20,110 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:20,105 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:20,110 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:20,113 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:20,111 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:20,113 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:20,117 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:20,114 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:20,117 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:20,127 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:20,119 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:20,127 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:20,128 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:20,133 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:20,132 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:20,133 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:20,135 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:20,134 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:20,135 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:20,138 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-02-16T15:23:20,140 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:20,137 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:20,144 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:20,140 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:20,138 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-02-16T15:23:20,144 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:24,283 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:24,283 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:24,347 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:24,347 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:24,462 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:24,462 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:24,542 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:24,542 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:24,630 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:24,630 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:24,733 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:24,733 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:24,742 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:24,742 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:30,500 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,517 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40732
2022-02-16T15:23:30,522 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,522 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,522 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,524 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,526 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:30,526 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:30,531 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610531
2022-02-16T15:23:30,531 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:30,531 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610531
2022-02-16T15:23:30,535 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:30,628 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,633 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,635 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]19260
2022-02-16T15:23:30,640 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,639 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]45436
2022-02-16T15:23:30,641 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,640 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,643 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:30,640 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,641 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:30,647 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:30,641 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,644 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,643 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:30,648 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,647 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:30,658 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610658
2022-02-16T15:23:30,658 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610658
2022-02-16T15:23:30,658 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:30,658 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:30,658 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610658
2022-02-16T15:23:30,658 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992610658
2022-02-16T15:23:30,664 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:30,664 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,142 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]18692
2022-02-16T15:23:31,152 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,152 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,152 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,156 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:31,154 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,156 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:31,165 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:31,167 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611167
2022-02-16T15:23:31,167 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611167
2022-02-16T15:23:31,175 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,583 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,591 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34508
2022-02-16T15:23:31,622 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,621 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,622 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,628 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:31,625 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,628 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:31,640 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611640
2022-02-16T15:23:31,640 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611640
2022-02-16T15:23:31,640 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:31,649 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,782 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,802 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]20424
2022-02-16T15:23:31,810 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,809 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,810 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:31,814 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:31,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,814 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:31,820 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611820
2022-02-16T15:23:31,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:31,820 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992611820
2022-02-16T15:23:31,823 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:32,110 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:32,121 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]43736
2022-02-16T15:23:32,125 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:32,125 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:32,125 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:32,129 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:32,127 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:32,129 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:32,141 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992612141
2022-02-16T15:23:32,141 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992612141
2022-02-16T15:23:32,141 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:32,148 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:33,176 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:23:33,176 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:23:33,713 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:33,713 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:33,713 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:33,733 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:33,726 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:33,733 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:33,738 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:33,736 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:33,738 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:33,746 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:33,740 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:33,746 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:33,748 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:33,746 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:33,748 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:33,759 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:33,764 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:33,764 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:33,764 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:33,771 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:33,768 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:33,771 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:33,779 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-02-16T15:23:33,774 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:33,781 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:33,779 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-02-16T15:23:33,781 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:33,797 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:33,797 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:34,272 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,270 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,272 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,282 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,276 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,282 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,286 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,284 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,286 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,292 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,288 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,292 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,296 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,294 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,296 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,302 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:34,298 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,302 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:34,314 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:34,312 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,314 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:34,318 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-02-16T15:23:34,316 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:34,320 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:34,318 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-02-16T15:23:34,320 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:34,407 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:34,407 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:34,416 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,415 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,416 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,432 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,448 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,425 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,448 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,464 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,448 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,432 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,470 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,464 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,473 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,457 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,470 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,486 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,467 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,483 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,473 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,492 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,488 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,486 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,497 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,491 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,492 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,494 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,502 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,500 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,497 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,502 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,520 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:34,502 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,524 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:34,515 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,520 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,524 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:34,530 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:34,525 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:34,520 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:34,532 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:34,530 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:34,535 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-02-16T15:23:34,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,546 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:34,546 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:34,532 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:34,535 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-02-16T15:23:34,532 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:34,554 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-02-16T15:23:34,553 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:34,556 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:34,554 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-02-16T15:23:34,556 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:23:34,573 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:34,573 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:34,697 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:34,697 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:23:34,909 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,909 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,908 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,909 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,918 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,909 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,927 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,909 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,932 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,918 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,938 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,938 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:34,945 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,995 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:34,945 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:34,911 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:35,012 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:34,995 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:35,022 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:34,994 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,935 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,927 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:35,031 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:35,023 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:35,022 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:35,044 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:35,044 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:35,047 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:35,013 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:35,050 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,052 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,053 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:35,055 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:35,012 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:35,047 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:35,059 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:35,060 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:35,033 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:35,031 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:35,067 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:35,027 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,061 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,134 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:35,060 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:35,155 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:35,059 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:35,157 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:35,056 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:35,155 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:35,162 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-02-16T15:23:35,134 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:35,086 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,084 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,167 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:35,067 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:35,169 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:35,165 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:35,162 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-02-16T15:23:35,160 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:35,157 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:35,205 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:35,171 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:35,169 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:35,210 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:35,211 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:35,167 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:35,206 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:35,205 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:35,224 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-02-16T15:23:35,176 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:35,220 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:35,232 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:35,211 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:35,235 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:35,210 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:23:35,232 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:23:35,231 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:35,247 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:35,224 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-02-16T15:23:35,235 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:35,255 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:35,255 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-02-16T15:23:35,251 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:35,272 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:35,255 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:23:35,255 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-02-16T15:23:35,272 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:23:39,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:39,981 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]57036
2022-02-16T15:23:39,986 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:39,986 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:39,987 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:39,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:39,987 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:23:39,988 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:39,992 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992619992
2022-02-16T15:23:39,992 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992619992
2022-02-16T15:23:39,992 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:39,996 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:42,355 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:42,354 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:42,355 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:42,380 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:42,370 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:42,380 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:42,384 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:42,382 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:42,384 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:42,390 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:42,386 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:42,390 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:42,402 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:42,400 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:42,402 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:42,405 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:42,409 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:42,409 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:42,412 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:42,409 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:42,412 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:42,418 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-02-16T15:23:42,417 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:42,420 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:42,418 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-02-16T15:23:42,420 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:23:42,471 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:42,471 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:23:46,793 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:46,793 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:23:47,325 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:47,325 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:23:47,544 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:47,544 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:23:47,570 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:47,570 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:23:48,178 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:48,178 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:23:48,254 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:48,260 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:48,254 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:23:48,260 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:23:53,028 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:53,038 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]49552
2022-02-16T15:23:53,042 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:53,042 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:53,042 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:53,045 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:53,044 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:53,045 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:23:53,051 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992633051
2022-02-16T15:23:53,051 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992633051
2022-02-16T15:23:53,051 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:53,056 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:53,721 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:53,738 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26800
2022-02-16T15:23:53,753 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:53,753 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:53,753 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:53,765 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:53,763 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:53,765 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:23:53,775 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992633775
2022-02-16T15:23:53,775 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992633775
2022-02-16T15:23:53,775 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:53,780 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:56,589 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:56,591 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41272
2022-02-16T15:23:56,596 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:56,596 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:56,596 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:56,601 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:56,598 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:56,601 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:23:56,606 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992636606
2022-02-16T15:23:56,606 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992636606
2022-02-16T15:23:56,607 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:56,609 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,137 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,143 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]16780
2022-02-16T15:23:57,149 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,149 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,149 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,152 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:57,150 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,152 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:23:57,158 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637158
2022-02-16T15:23:57,158 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:57,158 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637158
2022-02-16T15:23:57,162 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,276 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,282 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]41372
2022-02-16T15:23:57,284 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,284 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,284 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,296 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:57,289 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,296 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:23:57,302 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637302
2022-02-16T15:23:57,302 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637302
2022-02-16T15:23:57,302 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:57,307 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,418 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,422 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]35408
2022-02-16T15:23:57,427 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,427 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,427 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,430 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:57,428 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,430 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:23:57,436 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637436
2022-02-16T15:23:57,436 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637436
2022-02-16T15:23:57,436 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:57,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,884 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,886 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]14376
2022-02-16T15:23:57,896 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,896 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,896 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:23:57,899 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:57,897 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,899 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:23:57,904 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637904
2022-02-16T15:23:57,904 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992637904
2022-02-16T15:23:57,904 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:57,906 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,953 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:57,952 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:57,953 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:57,966 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:57,960 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:57,966 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:57,971 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:57,968 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:57,971 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:57,977 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:57,973 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:57,977 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:57,982 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:57,979 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:57,982 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:57,991 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:57,984 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:57,991 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:58,005 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:58,002 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:58,005 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:58,011 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-02-16T15:23:58,008 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:58,012 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:58,011 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-02-16T15:23:58,012 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:23:58,036 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:58,036 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:23:58,237 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:58,236 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:58,237 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:58,253 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:58,243 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:58,253 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:58,264 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:58,260 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:58,264 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:58,273 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:58,270 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:58,273 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:58,277 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:58,275 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:58,277 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:58,283 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:58,278 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:58,283 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:58,292 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:58,291 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:58,292 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:58,296 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-02-16T15:23:58,294 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:58,298 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:58,296 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-02-16T15:23:58,298 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:23:58,307 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:58,307 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:23:59,446 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:59,445 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:59,446 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:59,453 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:59,448 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:59,453 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:59,457 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:59,455 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:59,457 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:59,463 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:59,459 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:59,463 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:59,467 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:59,465 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:59,467 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:59,469 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:59,473 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:59,472 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:59,487 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:59,473 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:59,488 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:59,485 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:59,488 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:59,492 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-02-16T15:23:59,487 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:23:59,490 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:59,497 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:59,492 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-02-16T15:23:59,497 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:23:59,756 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:59,755 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:59,756 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:23:59,761 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:59,760 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:59,761 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:23:59,769 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:59,767 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:59,769 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:23:59,775 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:59,771 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:59,775 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:59,775 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:23:59,779 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:59,777 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:59,779 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:23:59,780 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:59,783 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:59,785 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:59,786 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:59,786 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:59,788 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:59,787 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:59,788 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:59,803 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-02-16T15:23:59,801 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:59,804 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:59,803 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-02-16T15:23:59,804 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:23:59,842 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:23:59,842 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:24:00,023 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,022 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,023 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,055 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,050 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,055 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,059 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,057 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,059 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,065 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,062 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,065 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,077 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,067 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,077 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,079 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,083 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:00,083 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,083 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:00,087 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:00,085 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,087 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:00,090 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-02-16T15:24:00,088 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:00,093 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:00,090 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-02-16T15:24:00,109 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,093 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:00,108 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,109 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,112 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,110 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,112 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,116 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,114 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,116 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,120 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,118 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,123 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:00,120 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,124 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,123 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:00,122 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,124 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,134 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:00,129 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,134 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:00,152 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:00,151 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,152 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:00,155 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-02-16T15:24:00,153 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,158 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:00,155 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-02-16T15:24:00,158 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:00,189 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:00,189 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:00,380 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,379 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,380 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:00,392 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,385 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,392 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:00,397 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,394 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,397 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:00,402 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,399 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,402 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:00,406 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,404 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,406 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:00,408 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,422 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:00,422 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,422 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:00,426 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:00,424 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,426 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:00,431 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-02-16T15:24:00,429 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:00,433 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:00,431 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-02-16T15:24:00,433 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:00,438 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:00,438 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:03,426 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:24:03,426 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:24:06,365 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:06,367 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32720
2022-02-16T15:24:06,371 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:06,370 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:06,371 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:06,375 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:24:06,372 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:06,375 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:24:06,380 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992646380
2022-02-16T15:24:06,380 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992646380
2022-02-16T15:24:06,380 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:24:06,383 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:07,676 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:07,675 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:07,676 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:07,687 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:07,676 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:07,687 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:07,698 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:07,693 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:07,698 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:07,703 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:07,700 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:07,703 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:07,706 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:07,704 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:07,706 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:07,710 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:07,707 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:07,710 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:07,717 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:07,717 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:07,717 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:07,720 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-02-16T15:24:07,722 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:07,718 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:07,726 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:07,722 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:07,720 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-02-16T15:24:07,726 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:19,014 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:24:19,014 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:24:19,300 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:24:19,300 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:24:20,498 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:24:20,498 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:24:20,820 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:24:20,820 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:24:21,099 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:24:21,099 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:24:21,180 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:24:21,180 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:24:21,456 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:24:21,456 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:24:24,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:24,324 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]2352
2022-02-16T15:24:24,326 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:24,325 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:24,326 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:24,331 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:24:24,326 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:24,329 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]15892
2022-02-16T15:24:24,334 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:24,331 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:24:24,332 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:24,338 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992664338
2022-02-16T15:24:24,338 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:24:24,334 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:24,342 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:24:24,333 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:24,338 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992664338
2022-02-16T15:24:24,342 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:24:24,344 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:24,368 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992664368
2022-02-16T15:24:24,362 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:24,368 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:24:24,368 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992664368
2022-02-16T15:24:24,374 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:25,756 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:25,761 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]28080
2022-02-16T15:24:25,765 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:25,765 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:25,765 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:25,769 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:24:25,767 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:25,769 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:24:25,775 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992665775
2022-02-16T15:24:25,775 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992665775
2022-02-16T15:24:25,775 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:24:25,778 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,226 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:26,237 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36968
2022-02-16T15:24:26,240 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:26,239 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:26,240 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:26,243 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:24:26,241 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:26,243 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:24:26,249 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992666249
2022-02-16T15:24:26,249 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992666249
2022-02-16T15:24:26,249 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:24:26,252 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:26,816 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]23340
2022-02-16T15:24:26,826 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:26,826 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:26,826 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:26,833 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:24:26,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:26,833 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:24:26,838 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992666838
2022-02-16T15:24:26,838 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992666838
2022-02-16T15:24:26,838 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:24:26,840 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,911 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:26,910 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:26,911 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:26,927 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:26,916 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:26,927 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:26,930 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:26,928 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:26,930 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:26,934 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:26,931 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:26,934 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:26,937 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:26,935 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:26,937 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:26,946 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:26,949 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:24:26,949 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:26,951 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:26,950 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:26,949 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:24:26,956 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:24:26,951 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:26,957 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:26,957 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:24:26,951 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:26,956 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:24:26,960 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-02-16T15:24:26,953 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:26,959 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:26,964 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:24:26,957 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:24:26,957 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:26,967 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:26,964 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:24:26,962 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:26,960 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-02-16T15:24:26,967 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:26,997 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:26,974 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:26,997 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:27,000 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:26,998 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:27,000 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:27,002 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:27,005 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:24:27,005 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:27,005 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:24:27,009 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:24:27,007 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:27,009 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:24:27,012 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-02-16T15:24:27,011 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:27,014 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:24:27,012 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-02-16T15:24:27,015 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:24:27,014 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:24:27,015 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:24:27,329 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:27,342 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]36048
2022-02-16T15:24:27,346 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:27,346 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:27,346 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:27,350 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:24:27,348 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:27,350 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:24:27,358 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992667358
2022-02-16T15:24:27,357 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:24:27,358 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992667358
2022-02-16T15:24:27,364 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:27,472 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:27,475 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]9860
2022-02-16T15:24:27,479 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:27,479 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:27,479 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:27,483 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:24:27,481 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:27,483 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:24:27,490 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:24:27,490 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992667490
2022-02-16T15:24:27,490 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992667490
2022-02-16T15:24:27,493 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:28,343 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:28,342 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:28,343 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:28,365 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:28,359 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:28,365 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:28,368 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:28,366 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:28,368 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:28,374 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:28,370 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:28,374 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:28,386 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:28,383 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:28,386 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:28,388 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:28,392 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:24:28,392 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:28,392 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:24:28,396 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:24:28,395 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:28,396 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:24:28,400 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-02-16T15:24:28,398 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:28,402 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:24:28,400 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-02-16T15:24:28,402 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:24:28,441 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:24:28,441 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:24:28,567 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:28,565 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:28,567 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:28,582 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:28,577 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:28,582 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:28,585 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:28,583 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:28,585 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:28,591 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:28,587 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:28,591 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:28,602 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:28,600 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:28,602 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:28,603 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:28,608 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:24:28,607 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:28,608 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:24:28,611 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:24:28,608 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:28,611 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:24:28,615 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-02-16T15:24:28,613 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:28,617 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:24:28,615 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-02-16T15:24:28,617 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:24:28,643 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:24:28,643 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:24:29,072 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,072 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,072 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,080 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,074 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,080 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,084 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,082 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,084 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,089 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,086 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,089 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,102 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,092 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,102 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,105 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,110 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:29,109 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,110 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:29,113 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:29,111 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,113 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:29,117 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-02-16T15:24:29,115 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,118 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:29,117 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-02-16T15:24:29,118 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:24:29,127 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:29,127 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:24:29,262 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,261 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,262 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,273 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,265 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,273 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,277 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,275 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,277 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,282 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,279 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,282 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,286 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,284 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,286 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,288 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,293 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:29,293 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,293 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:29,297 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:29,305 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:29,295 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,305 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:24:29,297 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:29,316 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-02-16T15:24:29,314 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,318 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:29,316 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-02-16T15:24:29,318 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:24:29,397 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,397 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,397 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:29,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,398 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,404 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:29,408 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,405 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,408 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:29,413 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,410 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,413 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:29,416 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,414 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,416 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:29,417 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,431 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:29,431 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,431 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:29,437 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:29,434 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,437 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:29,440 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-02-16T15:24:29,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,442 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:29,440 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-02-16T15:24:29,445 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:29,442 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:24:29,445 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:24:41,724 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:24:41,724 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:24:44,560 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:44,561 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]20792
2022-02-16T15:24:44,565 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:44,565 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:44,565 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:24:44,568 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:24:44,567 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:44,568 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:24:44,573 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992684573
2022-02-16T15:24:44,573 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992684573
2022-02-16T15:24:44,574 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:24:44,576 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:45,818 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:45,817 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:45,818 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:24:45,823 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:45,818 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:45,823 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:24:45,826 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:45,825 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:45,826 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:24:45,831 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:45,828 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:45,831 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:24:45,834 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:45,832 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:45,834 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:24:45,836 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:45,849 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:45,848 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:45,849 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:45,852 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:45,850 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:45,852 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:45,856 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 55 seconds.
2022-02-16T15:24:45,858 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:45,854 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:45,862 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:24:45,858 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:24:45,856 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 55 seconds.
2022-02-16T15:24:45,862 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:25:00,973 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:25:00,973 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:25:01,019 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:25:01,019 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:25:02,415 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:25:02,415 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:25:02,636 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:25:02,636 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:25:03,123 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:25:03,123 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:25:03,326 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:25:03,326 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:25:03,470 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:25:03,470 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:25:05,848 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:05,881 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]34716
2022-02-16T15:25:05,886 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:05,886 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:05,886 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:05,889 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:25:05,887 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:05,889 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:25:05,895 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992705895
2022-02-16T15:25:05,895 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992705895
2022-02-16T15:25:05,895 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:25:05,898 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:06,352 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:06,358 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]18372
2022-02-16T15:25:06,360 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:06,359 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:06,360 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:06,366 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:25:06,364 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:06,366 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:25:06,372 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992706372
2022-02-16T15:25:06,372 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992706372
2022-02-16T15:25:06,372 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:25:06,374 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:08,154 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:08,161 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]23428
2022-02-16T15:25:08,166 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:08,166 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:08,166 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:08,170 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:25:08,168 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:08,170 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:25:08,181 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992708181
2022-02-16T15:25:08,181 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992708181
2022-02-16T15:25:08,181 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:25:08,191 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:08,465 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:08,464 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:08,471 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:08,465 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:08,479 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:08,472 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:08,477 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]33508
2022-02-16T15:25:08,482 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:08,479 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:08,483 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:08,480 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:08,482 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:08,483 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:08,490 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:08,485 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:08,482 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:08,492 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:25:08,490 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:08,494 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:08,487 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:08,492 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:08,494 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:08,492 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:25:08,497 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:08,501 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:25:08,502 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992708502
2022-02-16T15:25:08,501 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:08,502 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:25:08,501 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:25:08,506 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:25:08,503 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:08,502 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992708502
2022-02-16T15:25:08,506 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:25:08,524 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-02-16T15:25:08,509 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:08,527 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:25:08,508 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:08,531 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:25:08,531 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:25:08,527 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:25:08,524 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2022-02-16T15:25:09,080 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,084 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]35024
2022-02-16T15:25:09,088 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,088 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,088 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,091 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:25:09,089 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,091 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:25:09,096 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709096
2022-02-16T15:25:09,096 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:25:09,096 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709096
2022-02-16T15:25:09,102 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:09,131 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:09,138 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:09,132 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:09,138 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:09,148 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:09,146 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:09,148 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:09,151 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:09,149 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:09,151 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:09,154 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:09,152 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:09,154 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:09,157 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:09,156 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:09,157 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:09,172 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:25:09,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:09,172 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:25:09,176 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:25:09,173 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:09,186 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:25:09,176 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:25:09,189 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-02-16T15:25:09,186 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:25:09,182 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:09,202 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:25:09,189 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2022-02-16T15:25:09,202 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:25:09,222 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,227 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]21572
2022-02-16T15:25:09,229 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,229 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,229 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,231 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:25:09,231 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,231 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:25:09,237 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709237
2022-02-16T15:25:09,237 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709237
2022-02-16T15:25:09,237 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:25:09,244 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:09,263 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,264 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]30768
2022-02-16T15:25:09,273 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,273 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,273 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:09,279 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:25:09,277 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,279 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:25:09,284 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709284
2022-02-16T15:25:09,283 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:25:09,284 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992709284
2022-02-16T15:25:09,286 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:10,755 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:10,754 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:10,755 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:10,777 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:10,770 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:10,777 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:10,781 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:10,779 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:10,781 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:10,786 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:10,783 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:10,786 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:10,790 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:10,788 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:10,790 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:10,792 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:10,797 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:25:10,797 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:10,797 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:25:10,811 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:25:10,799 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:10,811 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:25:10,816 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-02-16T15:25:10,819 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:25:10,813 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:10,821 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:25:10,819 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:25:10,816 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2022-02-16T15:25:10,821 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:25:10,945 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:10,945 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:10,945 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:10,951 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:10,947 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:10,951 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:10,954 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:10,952 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:10,954 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:10,958 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:10,955 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:10,958 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:10,961 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:10,959 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:10,961 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:10,967 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:25:10,974 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:25:10,963 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:10,974 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:25:10,967 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:25:10,979 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:25:10,976 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:10,979 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:25:10,983 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2022-02-16T15:25:10,981 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:10,985 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:25:10,983 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 55 seconds.
2022-02-16T15:25:10,985 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:25:11,172 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,171 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,172 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,187 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,177 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,187 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,191 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,189 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,191 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,196 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,192 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,196 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,200 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,198 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,200 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,211 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,215 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:25:11,214 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,215 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:25:11,218 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:25:11,216 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,218 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:25:11,222 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 55 seconds.
2022-02-16T15:25:11,220 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:11,224 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:25:11,222 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 55 seconds.
2022-02-16T15:25:11,224 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:25:11,252 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:25:11,252 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:25:11,294 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,293 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,294 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,311 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,295 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,311 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,318 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,316 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,318 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,323 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,319 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,323 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,336 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,325 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,336 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,339 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,343 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:25:11,345 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,343 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,345 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:11,347 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,344 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,349 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:25:11,343 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:25:11,355 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:25:11,347 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:11,365 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,355 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:25:11,372 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2022-02-16T15:25:11,349 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:25:11,348 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,372 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 55 seconds.
2022-02-16T15:25:11,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:11,379 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:25:11,365 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:11,382 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,375 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,379 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:25:11,382 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:11,387 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,384 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,387 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:11,389 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,407 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:25:11,407 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,407 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:25:11,410 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:25:11,409 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,410 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:25:11,414 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-02-16T15:25:11,415 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:25:11,412 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,416 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:25:11,415 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:25:11,414 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2022-02-16T15:25:11,416 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:25:40,863 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:25:40,863 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:25:43,974 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:43,975 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]10476
2022-02-16T15:25:43,980 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:43,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:43,980 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:25:43,983 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:25:43,981 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:43,983 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:25:43,989 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992743989
2022-02-16T15:25:43,989 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992743989
2022-02-16T15:25:43,989 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:25:43,992 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:45,395 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:45,394 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:45,395 [INFO ] nioEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:25:45,402 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:45,395 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:45,402 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:25:45,405 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:45,403 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:45,405 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:25:45,410 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:45,407 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:45,410 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:25:45,413 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:45,411 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:45,413 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:25:45,414 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:45,416 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:25:45,416 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:45,416 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:25:45,420 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:25:45,418 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:45,422 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:25:45,420 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:25:45,435 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 89 seconds.
2022-02-16T15:25:45,422 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:25:45,422 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:45,439 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:25:45,435 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 89 seconds.
2022-02-16T15:25:45,439 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:26:03,535 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:26:03,535 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:26:04,197 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:26:04,197 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:26:05,820 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:26:05,820 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:26:06,002 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:26:06,002 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:26:06,230 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:26:06,230 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:26:06,391 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:26:06,391 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:26:06,431 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:26:06,431 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:26:07,990 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:07,997 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]37304
2022-02-16T15:26:08,001 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:08,001 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:08,001 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:08,004 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:26:08,002 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:08,004 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:26:08,009 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992768009
2022-02-16T15:26:08,009 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992768009
2022-02-16T15:26:08,009 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:26:08,014 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:09,599 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:09,609 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]43540
2022-02-16T15:26:09,614 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:09,614 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:09,614 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:09,618 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:26:09,615 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:09,618 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:26:09,625 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992769625
2022-02-16T15:26:09,625 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992769625
2022-02-16T15:26:09,625 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:26:09,628 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:11,013 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:11,012 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:11,013 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:11,035 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:11,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:11,035 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:11,039 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:11,037 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:11,039 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:11,044 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:11,041 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:11,044 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:11,047 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:11,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:11,047 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:11,049 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:11,053 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:26:11,052 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:11,053 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:26:11,067 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:26:11,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:11,067 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:26:11,071 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2022-02-16T15:26:11,069 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:11,072 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:26:11,071 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2022-02-16T15:26:11,072 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:26:11,080 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:26:11,080 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:26:11,660 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:11,662 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]24764
2022-02-16T15:26:11,667 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:11,667 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:11,667 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:11,669 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:11,674 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:26:11,674 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:26:11,678 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992771678
2022-02-16T15:26:11,678 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992771678
2022-02-16T15:26:11,679 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:26:11,681 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:11,883 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:11,885 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]22824
2022-02-16T15:26:11,890 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:11,889 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:11,890 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:11,893 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:26:11,891 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:11,893 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:26:11,898 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992771898
2022-02-16T15:26:11,898 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992771898
2022-02-16T15:26:11,898 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:26:11,901 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,002 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,006 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]27136
2022-02-16T15:26:12,011 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,011 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,011 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,014 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:26:12,012 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,014 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:26:12,020 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772020
2022-02-16T15:26:12,020 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772020
2022-02-16T15:26:12,020 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:26:12,023 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,028 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,029 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]51440
2022-02-16T15:26:12,038 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,038 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,038 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,041 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:26:12,039 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,041 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:26:12,047 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772047
2022-02-16T15:26:12,047 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772047
2022-02-16T15:26:12,047 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:26:12,050 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,360 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]25656
2022-02-16T15:26:12,381 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,381 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,381 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:26:12,384 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:26:12,383 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,384 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:26:12,390 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772390
2022-02-16T15:26:12,390 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:26:12,390 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992772390
2022-02-16T15:26:12,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,496 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:12,495 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:12,496 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:12,505 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:12,499 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:12,505 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:12,508 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:12,506 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:12,508 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:12,512 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:12,509 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:12,512 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:12,522 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:12,513 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:12,522 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:12,523 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:12,526 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:26:12,526 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:12,526 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:26:12,530 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:26:12,528 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:12,530 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:26:12,540 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2022-02-16T15:26:12,537 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:12,541 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:26:12,542 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:26:12,540 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2022-02-16T15:26:12,542 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:26:12,541 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:26:13,814 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:13,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:13,814 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:13,824 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:13,817 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:13,824 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:13,830 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:13,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:13,830 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:13,835 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:13,832 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:13,835 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:13,839 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:13,837 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:13,839 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:13,841 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:13,845 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:26:13,853 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:26:13,844 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:13,853 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:26:13,845 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:26:13,863 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:26:13,858 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:13,863 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:26:13,871 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 89 seconds.
2022-02-16T15:26:13,869 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:13,872 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:26:13,871 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 89 seconds.
2022-02-16T15:26:13,872 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:26:14,057 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,056 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,057 [INFO ] nioEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,078 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,067 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,078 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,092 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,087 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,092 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,104 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,094 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,104 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,109 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,107 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,109 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,111 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,115 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:26:14,115 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,115 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:26:14,118 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:26:14,117 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,118 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:26:14,133 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-02-16T15:26:14,120 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,135 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:26:14,133 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2022-02-16T15:26:14,135 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:26:14,147 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:26:14,147 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:26:14,215 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,214 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,215 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,238 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,226 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,249 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,238 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,252 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,249 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,255 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,248 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,246 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,255 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,261 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,252 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,265 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,258 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,256 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,265 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,269 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,267 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,266 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,269 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,261 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,276 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,273 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,278 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:26:14,271 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,276 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,280 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,278 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:26:14,282 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:26:14,277 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,280 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,278 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,288 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:26:14,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,282 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:26:14,309 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2022-02-16T15:26:14,288 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:26:14,309 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:26:14,287 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,311 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:26:14,309 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 89 seconds.
2022-02-16T15:26:14,289 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,315 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:26:14,312 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,311 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:26:14,309 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:26:14,320 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2022-02-16T15:26:14,316 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,330 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:26:14,315 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:26:14,320 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2022-02-16T15:26:14,330 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:26:14,368 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:26:14,368 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:26:14,473 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,472 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,473 [INFO ] nioEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:26:14,495 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,490 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,495 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:26:14,499 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,497 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,499 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:26:14,505 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,501 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,505 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:26:14,508 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,506 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,508 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:26:14,519 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,523 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:26:14,523 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,523 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:26:14,528 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:26:14,525 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,528 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:26:14,532 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2022-02-16T15:26:14,533 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:26:14,530 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,534 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:26:14,533 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:26:14,532 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 89 seconds.
2022-02-16T15:26:14,534 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:27:14,443 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:27:14,443 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:27:17,518 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:17,519 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]12372
2022-02-16T15:27:17,523 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:17,523 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:17,523 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:17,525 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:27:17,524 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:17,525 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:27:17,529 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992837529
2022-02-16T15:27:17,529 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992837529
2022-02-16T15:27:17,529 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:27:17,531 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:18,761 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:18,760 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:18,761 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:18,766 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:18,762 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:18,766 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:18,770 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:18,768 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:18,770 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:18,778 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:18,776 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:18,778 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:18,787 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:18,783 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:18,787 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:18,797 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:18,801 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:27:18,801 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:18,801 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stderr
2022-02-16T15:27:18,805 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:27:18,803 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:18,805 [WARN ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-sentencemoji_1.0-stdout
2022-02-16T15:27:18,809 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 144 seconds.
2022-02-16T15:27:18,806 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:18,811 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:27:18,812 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:27:18,809 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 144 seconds.
2022-02-16T15:27:18,812 [INFO ] W-9006-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stderr
2022-02-16T15:27:18,811 [INFO ] W-9006-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-sentencemoji_1.0-stdout
2022-02-16T15:27:40,073 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:27:40,073 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:27:41,555 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:27:41,555 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:27:42,878 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:27:42,878 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:27:43,144 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:27:43,144 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:27:43,164 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:43,170 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21792
2022-02-16T15:27:43,172 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:43,172 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:43,172 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:43,179 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:27:43,177 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:43,179 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:27:43,186 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992863186
2022-02-16T15:27:43,186 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992863186
2022-02-16T15:27:43,186 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:27:43,190 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:43,346 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:27:43,351 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:27:43,346 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:27:43,351 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:27:43,563 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:27:43,563 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:27:45,701 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:45,701 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:45,701 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:45,716 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:45,711 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:45,716 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:45,721 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:45,718 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:45,721 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:45,726 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:45,723 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:45,726 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:45,729 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:45,728 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:45,729 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:45,731 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:45,735 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:27:45,735 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:45,735 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stderr
2022-02-16T15:27:45,749 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:27:45,747 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:45,749 [WARN ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-sentencemoji_1.0-stdout
2022-02-16T15:27:45,753 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 144 seconds.
2022-02-16T15:27:45,751 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:45,755 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:27:45,753 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 144 seconds.
2022-02-16T15:27:45,755 [INFO ] W-9001-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stdout
2022-02-16T15:27:45,828 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:27:45,828 [INFO ] W-9001-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-sentencemoji_1.0-stderr
2022-02-16T15:27:46,547 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:46,549 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]17192
2022-02-16T15:27:46,554 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:46,554 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:46,554 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:46,557 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:27:46,555 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:46,557 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:27:46,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992866562
2022-02-16T15:27:46,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992866562
2022-02-16T15:27:46,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:27:46,569 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,031 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,041 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]32684
2022-02-16T15:27:48,046 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,046 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,046 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,051 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:27:48,048 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,051 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:27:48,058 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868058
2022-02-16T15:27:48,058 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868058
2022-02-16T15:27:48,058 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:27:48,066 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,560 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]51508
2022-02-16T15:27:48,567 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,567 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,567 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,570 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:27:48,569 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,570 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:27:48,577 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868577
2022-02-16T15:27:48,577 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:27:48,577 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868577
2022-02-16T15:27:48,580 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,695 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,718 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]32772
2022-02-16T15:27:48,723 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,723 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,723 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,726 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:27:48,724 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,726 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:27:48,732 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868732
2022-02-16T15:27:48,732 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868732
2022-02-16T15:27:48,732 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:27:48,735 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,809 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]57288
2022-02-16T15:27:48,815 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,815 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,815 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:48,819 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:27:48,817 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,819 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:27:48,826 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868826
2022-02-16T15:27:48,826 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992868826
2022-02-16T15:27:48,826 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:27:48,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:49,388 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:49,387 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:49,388 [INFO ] nioEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:49,406 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:49,396 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:49,406 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:49,412 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:49,410 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:49,412 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:49,417 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:49,414 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:49,417 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:49,433 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:49,431 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:49,433 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:49,434 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:49,438 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:27:49,437 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:49,438 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stderr
2022-02-16T15:27:49,441 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:27:49,439 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:49,441 [WARN ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-sentencemoji_1.0-stdout
2022-02-16T15:27:49,444 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 144 seconds.
2022-02-16T15:27:49,443 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:49,446 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:27:49,450 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:27:49,446 [INFO ] W-9002-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stdout
2022-02-16T15:27:49,444 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 144 seconds.
2022-02-16T15:27:49,450 [INFO ] W-9002-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-sentencemoji_1.0-stderr
2022-02-16T15:27:50,264 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:50,263 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:50,264 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:50,285 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:50,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:50,285 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:50,299 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:50,293 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:50,299 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:50,304 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:50,301 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:50,304 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:50,308 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:50,306 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:50,308 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:50,310 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:50,314 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:27:50,313 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:50,314 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stderr
2022-02-16T15:27:50,317 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:27:50,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:50,317 [WARN ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-sentencemoji_1.0-stdout
2022-02-16T15:27:50,322 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 144 seconds.
2022-02-16T15:27:50,319 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:50,322 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:27:50,322 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 144 seconds.
2022-02-16T15:27:50,322 [INFO ] W-9007-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stdout
2022-02-16T15:27:50,380 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:27:50,380 [INFO ] W-9007-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-sentencemoji_1.0-stderr
2022-02-16T15:27:50,900 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:50,896 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:50,900 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:50,904 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:50,899 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:50,900 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]28532
2022-02-16T15:27:50,906 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:50,904 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:50,908 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:50,905 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:50,906 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-02-16T15:27:50,911 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:27:50,906 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:50,910 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:50,908 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:50,923 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:50,913 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:50,911 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:27:50,923 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:50,929 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:50,931 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992870931
2022-02-16T15:27:50,914 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:50,931 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:27:50,931 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644992870931
2022-02-16T15:27:50,929 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:50,938 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:50,944 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:27:50,942 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:50,944 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:50,944 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stderr
2022-02-16T15:27:50,955 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:27:50,955 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:50,957 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:27:50,955 [WARN ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-sentencemoji_1.0-stdout
2022-02-16T15:27:50,962 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 144 seconds.
2022-02-16T15:27:50,957 [INFO ] W-9003-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stderr
2022-02-16T15:27:50,956 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:50,966 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:27:50,962 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 144 seconds.
2022-02-16T15:27:50,966 [INFO ] W-9003-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-sentencemoji_1.0-stdout
2022-02-16T15:27:51,094 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:51,093 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:51,094 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:51,103 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:51,096 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:51,103 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:51,108 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:51,105 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:51,108 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:51,114 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:51,110 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:51,114 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:51,128 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:51,116 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:51,128 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:51,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:51,134 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:51,134 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:27:51,133 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:51,134 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stderr
2022-02-16T15:27:51,138 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:27:51,134 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:51,134 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:51,142 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:51,138 [WARN ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-sentencemoji_1.0-stdout
2022-02-16T15:27:51,145 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-02-16T15:27:51,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:51,142 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:51,160 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:51,140 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:51,162 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:27:51,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:51,145 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2022-02-16T15:27:51,162 [INFO ] W-9000-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stdout
2022-02-16T15:27:51,160 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:51,170 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:51,163 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:51,170 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:51,173 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:51,172 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:51,173 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:51,179 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:27:51,188 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:27:51,175 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:51,179 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stderr
2022-02-16T15:27:51,192 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:27:51,189 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:51,195 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:27:51,188 [INFO ] W-9000-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-sentencemoji_1.0-stderr
2022-02-16T15:27:51,192 [WARN ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-sentencemoji_1.0-stdout
2022-02-16T15:27:51,199 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 144 seconds.
2022-02-16T15:27:51,195 [INFO ] W-9005-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stderr
2022-02-16T15:27:51,194 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:51,202 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:27:51,199 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 144 seconds.
2022-02-16T15:27:51,202 [INFO ] W-9005-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-sentencemoji_1.0-stdout
2022-02-16T15:27:52,887 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:52,890 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:52,888 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:52,890 [INFO ] nioEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-02-16T15:27:52,899 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:52,897 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:52,899 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-02-16T15:27:52,902 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:52,901 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:52,902 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-02-16T15:27:52,907 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:52,904 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:52,907 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: sentencemoji, error: Worker died.
2022-02-16T15:27:52,910 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:52,908 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:52,910 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-02-16T15:27:52,913 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:52,949 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:52,950 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:52,953 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:27:52,954 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:27:52,955 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:27:52,957 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:27:52,959 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:27:52,961 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:27:52,962 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:27:52,970 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 123, in handle
2022-02-16T15:27:52,972 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T15:27:52,973 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 112, in handle
2022-02-16T15:27:52,975 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T15:27:52,977 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 37, in initialize
2022-02-16T15:27:52,980 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:27:52,980 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stderr
2022-02-16T15:27:52,981 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:27:52,981 [WARN ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-sentencemoji_1.0-stdout
2022-02-16T15:27:52,982 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 144 seconds.
2022-02-16T15:27:52,981 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T15:27:52,984 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:27:52,982 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 144 seconds.
2022-02-16T15:27:52,984 [INFO ] W-9004-sentencemoji_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stdout
2022-02-16T15:27:53,035 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:27:53,035 [INFO ] W-9004-sentencemoji_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-sentencemoji_1.0-stderr
2022-02-16T15:46:04,599 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T15:46:04,599 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-02-16T15:46:04,706 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T15:46:04,706 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-02-16T15:46:05,468 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216152159336-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T15:46:05,468 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.2
TS Home: C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages
Current directory: C:\Users\enoch9\Desktop\개발\sentencEmoji
Temp directory: C:\Users\enoch9\AppData\Local\Temp
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 4046 M
Python executable: c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe
Config file: logs\config\20220216152159336-startup.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Initial Models: sentencemoji=sentencemoji.mar
Log dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Metrics dir: C:\Users\enoch9\Desktop\개발\sentencEmoji\logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: C:\Users\enoch9\Desktop\개발\sentencEmoji\model_store
Model config: N/A
2022-02-16T15:46:05,490 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216152159336-startup.cfg",
  "modelCount": 1,
  "created": 1644992519337,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T15:46:05,490 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20220216152159336-startup.cfg",
  "modelCount": 1,
  "created": 1644992519337,
  "models": {
    "sentencemoji": {
      "1.0": {
        "defaultVersion": true,
        "marName": "sentencemoji.mar",
        "minWorkers": 8,
        "maxWorkers": 8,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2022-02-16T15:46:05,507 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216152159336-startup.cfg
2022-02-16T15:46:05,507 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20220216152159336-startup.cfg
2022-02-16T15:46:05,512 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216152159336-startup.cfg validated successfully
2022-02-16T15:46:05,512 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20220216152159336-startup.cfg validated successfully
2022-02-16T15:46:44,843 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T15:46:44,843 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model sentencemoji
2022-02-16T15:46:44,845 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:46:44,845 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:46:44,846 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:46:44,846 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model sentencemoji
2022-02-16T15:46:44,848 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T15:46:44,848 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model sentencemoji loaded.
2022-02-16T15:46:44,848 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T15:46:44,848 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: sentencemoji, count: 8
2022-02-16T15:46:44,877 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:46:44,877 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:46:44,877 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9001]
2022-02-16T15:46:44,879 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:46:44,879 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:46:44,880 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:46:44,877 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9000]
2022-02-16T15:46:44,881 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:46:44,880 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9003]
2022-02-16T15:46:44,882 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:46:44,879 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9002]
2022-02-16T15:46:44,879 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9004]
2022-02-16T15:46:44,885 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:46:44,882 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9006]
2022-02-16T15:46:44,881 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9005]
2022-02-16T15:46:44,890 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T15:46:44,885 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [c:\users\enoch9\appdata\local\continuum\anaconda3\python.exe, C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py, --sock-type, tcp, --port, 9007]
2022-02-16T15:46:44,890 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2022-02-16T15:46:45,567 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T15:46:45,567 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-02-16T15:46:45,569 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T15:46:45,569 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2022-02-16T15:46:45,576 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T15:46:45,576 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-02-16T15:46:45,577 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T15:46:45,577 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2022-02-16T15:46:45,580 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T15:46:45,580 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-02-16T15:46:46,546 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T15:46:46,546 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-02-16T15:46:48,548 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,550 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.35219955444336|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,554 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.49252319335938|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,556 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,557 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5235.75|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,559 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:10942.34765625|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:48,561 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:67.6|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994008
2022-02-16T15:46:51,724 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:51,726 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21808
2022-02-16T15:46:51,731 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:51,730 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:51,731 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:51,733 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:51,744 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:46:51,744 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2022-02-16T15:46:51,772 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:46:51,780 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994011780
2022-02-16T15:46:51,780 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994011780
2022-02-16T15:46:51,854 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,147 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,151 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]36704
2022-02-16T15:46:52,154 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,154 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,154 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,158 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:46:52,155 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,158 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2022-02-16T15:46:52,166 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012166
2022-02-16T15:46:52,166 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012166
2022-02-16T15:46:52,166 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:46:52,191 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,356 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,358 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]10244
2022-02-16T15:46:52,362 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,361 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,362 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,368 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:46:52,362 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,367 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]33268
2022-02-16T15:46:52,371 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,368 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2022-02-16T15:46:52,370 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,371 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,376 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:46:52,376 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012376
2022-02-16T15:46:52,371 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,376 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:46:52,376 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2022-02-16T15:46:52,376 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012376
2022-02-16T15:46:52,377 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,390 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012390
2022-02-16T15:46:52,390 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012390
2022-02-16T15:46:52,390 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:46:52,411 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,422 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,442 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,444 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]33324
2022-02-16T15:46:52,447 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,447 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,447 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,450 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:46:52,448 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,450 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2022-02-16T15:46:52,457 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012457
2022-02-16T15:46:52,457 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:46:52,457 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012457
2022-02-16T15:46:52,484 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,598 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,602 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]11868
2022-02-16T15:46:52,604 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,604 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,604 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,608 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:46:52,605 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,608 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2022-02-16T15:46:52,618 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012618
2022-02-16T15:46:52,618 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012618
2022-02-16T15:46:52,618 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:46:52,646 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,851 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,853 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]31480
2022-02-16T15:46:52,868 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,868 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,868 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:52,871 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:46:52,869 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,871 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2022-02-16T15:46:52,879 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012879
2022-02-16T15:46:52,879 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:46:52,879 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994012879
2022-02-16T15:46:52,916 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:53,280 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:53,281 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]34048
2022-02-16T15:46:53,284 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:53,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:53,284 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change null -> WORKER_STARTED
2022-02-16T15:46:53,287 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:46:53,287 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:53,287 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2022-02-16T15:46:53,293 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994013293
2022-02-16T15:46:53,293 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:46:53,293 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994013293
2022-02-16T15:46:53,322 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:47:16,144 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']
2022-02-16T15:47:16,147 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,159 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,258 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:16,332 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23417
2022-02-16T15:47:16,332 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23417
2022-02-16T15:47:16,334 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,334 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,338 [INFO ] W-9003-sentencemoji_1.0 TS_METRICS - W-9003-sentencemoji_1.0.ms:31467|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994036
2022-02-16T15:47:16,339 [INFO ] W-9003-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:43|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:16,459 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']
2022-02-16T15:47:16,461 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,465 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,528 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:16,596 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24185
2022-02-16T15:47:16,596 [INFO ] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24185
2022-02-16T15:47:16,597 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,641 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:16,597 [DEBUG] W-9000-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,662 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,668 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,665 [INFO ] W-9000-sentencemoji_1.0 TS_METRICS - W-9000-sentencemoji_1.0.ms:31800|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994036
2022-02-16T15:47:16,729 [INFO ] W-9000-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:168|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:16,745 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:16,776 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24354
2022-02-16T15:47:16,776 [INFO ] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24354
2022-02-16T15:47:16,777 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,777 [DEBUG] W-9007-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:16,781 [INFO ] W-9007-sentencemoji_1.0 TS_METRICS - W-9007-sentencemoji_1.0.ms:31910|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994036
2022-02-16T15:47:16,783 [INFO ] W-9007-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:39|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:17,016 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']
2022-02-16T15:47:17,018 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,109 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,103 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,174 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23852
2022-02-16T15:47:17,174 [INFO ] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 23852
2022-02-16T15:47:17,175 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,175 [DEBUG] W-9005-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,177 [INFO ] W-9005-sentencemoji_1.0 TS_METRICS - W-9005-sentencemoji_1.0.ms:32306|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994037
2022-02-16T15:47:17,179 [INFO ] W-9005-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:34|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:17,342 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:17,344 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,349 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,438 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,446 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24800
2022-02-16T15:47:17,446 [INFO ] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 24800
2022-02-16T15:47:17,448 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,448 [DEBUG] W-9006-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,450 [INFO ] W-9006-sentencemoji_1.0 TS_METRICS - W-9006-sentencemoji_1.0.ms:32578|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994037
2022-02-16T15:47:17,452 [INFO ] W-9006-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:33|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:17,501 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']
2022-02-16T15:47:17,504 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,509 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,532 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25371
2022-02-16T15:47:17,562 [INFO ] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25371
2022-02-16T15:47:17,563 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,563 [DEBUG] W-9002-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:17,567 [INFO ] W-9002-sentencemoji_1.0 TS_METRICS - W-9002-sentencemoji_1.0.ms:32697|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994037
2022-02-16T15:47:17,569 [INFO ] W-9002-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:32|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:18,012 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:18,014 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:18,018 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:18,034 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:18,035 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25551
2022-02-16T15:47:18,035 [INFO ] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 25551
2022-02-16T15:47:18,037 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:18,037 [DEBUG] W-9004-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:18,039 [INFO ] W-9004-sentencemoji_1.0 TS_METRICS - W-9004-sentencemoji_1.0.ms:33168|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994038
2022-02-16T15:47:18,041 [INFO ] W-9004-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:33|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:18,354 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']
2022-02-16T15:47:18,356 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:18,361 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:18,375 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26521
2022-02-16T15:47:18,374 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:18,375 [INFO ] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 26521
2022-02-16T15:47:18,383 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:18,383 [DEBUG] W-9001-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-sentencemoji_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-02-16T15:47:18,387 [INFO ] W-9001-sentencemoji_1.0 TS_METRICS - W-9001-sentencemoji_1.0.ms:33517|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994038
2022-02-16T15:47:18,393 [INFO ] W-9001-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:92|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:47:47,306 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,308 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.353618621826172|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,312 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.49110412597656|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,313 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,315 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1299.6328125|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,317 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:14878.3984375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:47:47,318 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:92.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994067
2022-02-16T15:48:47,229 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,230 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.356266021728516|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,231 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.48845672607422|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,232 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,232 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1272.90234375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,233 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:14905.12890625|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:48:47,235 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:92.1|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994127
2022-02-16T15:49:47,228 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,713 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:12.355602264404297|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,721 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:220.48912048339844|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,721 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,722 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1266.96875|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,724 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14910.76953125|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:20,726 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:92.2|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994187
2022-02-16T15:51:21,503 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,504 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:12.366111755371094|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,508 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:220.47861099243164|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,510 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,512 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1263.6484375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,514 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:14914.3828125|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:51:21,515 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:92.2|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994281
2022-02-16T15:53:12,630 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994392629
2022-02-16T15:51:47,243 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:12,630 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1644994392629
2022-02-16T15:53:35,143 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.36606216430664|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,153 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.4786605834961|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,158 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend received inference at: 1644994415
2022-02-16T15:53:35,159 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,160 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Received text: '???? ??? ??????'
2022-02-16T15:53:35,167 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1235.9296875|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:14942.1015625|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,173 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:92.4|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994307
2022-02-16T15:53:35,582 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Model predicted: '4772'
2022-02-16T15:53:35,583 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 429
2022-02-16T15:53:35,583 [INFO ] W-9003-sentencemoji_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 429
2022-02-16T15:53:35,583 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:422.87|#ModelName:sentencemoji,Level:Model|#hostname:DESKTOP-AOFSBVV,requestID:69106a43-713f-4ba9-9d3a-8bb98aa0d9ac,timestamp:1644994415
2022-02-16T15:53:35,589 [INFO ] W-9003-sentencemoji_1.0 ACCESS_LOG - /127.0.0.1:50888 "PUT /predictions/sentencemoji HTTP/1.1" 200 22988
2022-02-16T15:53:35,613 [INFO ] W-9003-sentencemoji_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:53:35,619 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.job.Job - Waiting time ns: 586100, Backend time ns: 22989727300
2022-02-16T15:53:35,619 [DEBUG] W-9003-sentencemoji_1.0 org.pytorch.serve.job.Job - Waiting time ns: 586100, Backend time ns: 22989727300
2022-02-16T15:53:35,620 [INFO ] W-9003-sentencemoji_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:53:35,622 [INFO ] W-9003-sentencemoji_1.0 TS_METRICS - WorkerThreadTime.ms:22564|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:null
2022-02-16T15:53:36,051 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,052 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:12.366790771484375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,057 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:220.47793197631836|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:94.7|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,062 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:885.1875|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,063 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:15292.84375|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
2022-02-16T15:53:36,070 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:94.5|#Level:Host|#hostname:DESKTOP-AOFSBVV,timestamp:1644994416
