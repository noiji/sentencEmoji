2022-02-09T20:20:08,828 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:08,825 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:08,840 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:08,844 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:08,902 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:09,071 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:09,089 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:09,108 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:16,330 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]45372
2022-02-09T20:20:16,336 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]43448
2022-02-09T20:20:16,337 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]20856
2022-02-09T20:20:16,339 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]41900
2022-02-09T20:20:16,339 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34108
2022-02-09T20:20:16,341 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]28124
2022-02-09T20:20:16,343 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,343 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,345 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,346 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,346 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]46812
2022-02-09T20:20:16,346 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,373 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,378 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,379 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,379 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,379 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]42572
2022-02-09T20:20:16,402 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:20:16,423 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,429 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,431 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:20:16,433 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,434 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,439 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:16,440 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,467 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:16,469 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:20:16,480 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:20:16,482 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,492 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:20:16,510 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,563 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:20:16,566 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,568 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:20:16,601 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:20:16,627 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,667 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,686 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,707 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:16,750 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:18,053 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,059 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,109 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,114 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,114 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,116 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,117 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,119 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,120 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,137 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,140 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,140 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,141 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,141 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,143 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:18,148 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,152 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:18,200 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:18,202 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,212 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,257 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:18,257 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,260 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,261 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,262 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:18,266 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,266 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,267 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:18,269 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,272 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,275 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,275 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:18,278 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,302 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,309 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,341 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,359 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,361 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,363 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,369 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,379 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:18,396 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,403 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,424 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:18,424 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,425 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,443 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,448 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,453 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,455 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,457 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,462 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,473 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:18,478 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,479 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,481 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:18,489 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,490 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:18,492 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,493 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,503 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:18,559 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:18,563 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,566 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:18,568 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,570 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:18,585 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:18,587 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,591 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:18,594 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:18,597 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:18,599 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:18,601 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:18,602 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:28,268 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,269 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]42156
2022-02-09T20:20:28,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,275 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,283 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:20:28,326 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,417 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,421 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]44508
2022-02-09T20:20:28,425 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,426 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,433 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:20:28,462 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,471 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,473 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]40256
2022-02-09T20:20:28,474 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,475 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,483 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:20:28,518 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,574 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,576 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]29680
2022-02-09T20:20:28,580 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,581 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,589 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:20:28,589 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,592 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]42832
2022-02-09T20:20:28,595 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,597 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,631 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:20:28,631 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,632 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,638 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]47796
2022-02-09T20:20:28,644 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,644 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,653 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,666 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:20:28,686 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,867 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,874 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]41356
2022-02-09T20:20:28,885 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,888 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,895 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:20:28,931 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:28,943 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:28,951 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]45612
2022-02-09T20:20:28,952 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:28,953 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:28,962 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:20:29,008 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:29,873 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:29,877 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:29,884 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:29,885 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:29,889 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:29,892 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:29,895 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:29,898 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:29,911 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:29,913 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:29,917 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:30,056 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,062 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,068 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,069 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,072 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,074 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,076 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,079 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,081 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,082 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:30,085 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:30,086 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:30,088 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:20:30,089 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:20:30,106 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:20:30,107 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-09T20:20:30,108 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 97, in handle
2022-02-09T20:20:30,109 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-09T20:20:30,111 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 31, in initialize
2022-02-09T20:20:30,112 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-09T20:20:30,114 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-09T20:20:30,142 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,143 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,145 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,147 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,148 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,150 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,152 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,153 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,154 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,156 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,159 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,161 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:30,165 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:30,184 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:30,186 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,189 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:20:30,191 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,195 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:20:30,197 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,210 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:20:30,213 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,219 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,220 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,221 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,249 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:30,266 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,268 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,271 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,272 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,283 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,286 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,289 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,295 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,314 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,381 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,382 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,386 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,389 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,391 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,395 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,398 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,408 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,413 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,415 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,418 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,419 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,423 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,425 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:30,429 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,447 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,450 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,452 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,453 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:30,455 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:30,458 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:30,465 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:30,471 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:30,478 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:30,481 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:30,484 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:30,486 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:30,488 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:30,490 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:30,492 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:34,124 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,301 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,595 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,661 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,661 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,754 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,801 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:34,854 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:46,473 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19020
2022-02-09T20:20:46,491 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]42428
2022-02-09T20:20:46,494 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]3408
2022-02-09T20:20:46,494 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]34044
2022-02-09T20:20:46,497 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27076
2022-02-09T20:20:46,499 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]33476
2022-02-09T20:20:46,505 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]36852
2022-02-09T20:20:46,513 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]16072
2022-02-09T20:20:46,514 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,515 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,517 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,520 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,525 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,528 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,534 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,549 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,551 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,553 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,554 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,555 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:46,559 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:20:46,563 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:20:46,566 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:20:46,568 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:20:46,578 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,580 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,584 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:20:46,585 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,588 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,591 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,594 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,628 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:20:46,629 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:46,629 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,645 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,657 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,666 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:20:46,668 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:20:46,670 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:46,675 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:47,851 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:47,851 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:47,857 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:47,860 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:47,860 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:47,862 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:47,865 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:47,867 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:47,871 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:47,874 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:47,874 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:47,876 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:47,878 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:47,893 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:47,896 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:47,901 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:47,902 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:47,903 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:47,910 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:47,921 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:47,927 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:47,953 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:47,956 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:47,958 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:47,964 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:47,966 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:47,970 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:47,993 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:47,995 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:47,996 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:48,015 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:48,017 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:48,030 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:48,030 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:48,058 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:48,059 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:48,062 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:48,072 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:48,077 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:48,085 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:48,088 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:48,090 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:48,091 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:48,094 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:48,108 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:48,116 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:48,122 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:48,131 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:48,132 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:48,134 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:48,137 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:48,138 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:48,141 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:48,151 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:48,159 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:48,162 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:48,165 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:48,166 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:48,169 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:48,172 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:48,174 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:48,190 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:48,192 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:48,195 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:48,199 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:48,200 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:48,203 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:48,214 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:53,429 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,431 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]38556
2022-02-09T20:20:53,441 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,442 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,448 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:20:53,452 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,493 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,501 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]11720
2022-02-09T20:20:53,502 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,503 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,509 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:20:53,510 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,524 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,525 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]39252
2022-02-09T20:20:53,526 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,527 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,527 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,529 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]39032
2022-02-09T20:20:53,533 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,536 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:20:53,537 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,539 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,543 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:20:53,556 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,651 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,652 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]8272
2022-02-09T20:20:53,656 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,657 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,667 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:20:53,681 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,717 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,718 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]37344
2022-02-09T20:20:53,724 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,725 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,731 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:20:53,734 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,744 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,746 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34864
2022-02-09T20:20:53,747 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,749 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,762 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:20:53,764 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:53,854 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:20:53,856 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]9372
2022-02-09T20:20:53,860 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:20:53,861 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:20:53,868 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:20:53,871 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:20:54,807 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:54,808 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:54,822 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:54,826 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:54,829 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:54,842 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:54,843 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:54,845 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:54,846 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:54,848 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:54,853 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:54,875 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:54,875 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:54,877 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:54,880 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:54,884 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:54,888 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:54,891 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:54,893 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:54,914 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:54,915 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:54,930 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:54,933 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:54,937 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:54,942 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:54,944 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:54,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:54,950 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:54,971 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:54,978 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:54,981 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:54,985 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:54,988 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:55,012 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:55,015 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:55,019 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:55,032 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:55,036 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:55,037 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:55,038 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:55,041 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:55,042 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:20:55,044 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:20:55,045 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:20:55,049 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:20:55,097 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:55,097 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:55,102 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:55,105 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:55,107 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:55,109 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:55,110 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:55,129 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:55,132 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:55,134 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:20:55,138 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:20:55,139 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:55,143 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:55,161 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:55,165 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:55,168 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:55,179 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:55,203 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:55,234 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:55,235 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:55,236 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:55,239 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:20:55,240 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:55,246 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:20:55,249 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:55,254 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:20:55,268 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:55,269 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:20:55,271 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:55,276 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:20:55,278 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:55,280 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:20:55,281 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:20:55,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:20:55,312 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:20:55,328 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:01,209 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,210 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]38840
2022-02-09T20:21:01,210 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,214 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,216 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]35320
2022-02-09T20:21:01,217 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,219 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,225 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,226 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:21:01,237 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,238 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:21:01,243 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,482 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,483 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]14096
2022-02-09T20:21:01,487 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,495 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,501 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:21:01,510 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,626 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,628 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]34424
2022-02-09T20:21:01,632 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,633 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,640 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:21:01,642 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,648 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,652 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]33888
2022-02-09T20:21:01,653 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,654 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,661 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:21:01,673 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,786 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,787 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]37644
2022-02-09T20:21:01,792 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,793 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,812 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:21:01,818 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:01,957 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:01,959 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]35192
2022-02-09T20:21:01,963 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:01,964 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:01,970 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:21:01,973 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:02,053 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:02,054 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]27340
2022-02-09T20:21:02,060 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:02,061 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:02,067 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:21:02,069 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:02,612 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:02,612 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:02,613 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:02,617 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:02,621 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:02,622 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:02,623 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:02,625 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:02,626 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:02,628 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:02,630 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:02,631 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:02,642 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:02,644 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:02,645 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:02,646 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:02,648 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:02,657 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:02,658 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:02,684 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:02,684 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:02,692 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:02,694 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:02,696 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:02,704 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:02,716 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:21:02,857 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:02,858 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:02,863 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:02,865 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:02,867 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:02,870 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:02,873 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:02,875 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:02,876 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:02,878 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:02,883 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:02,898 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:02,899 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:02,901 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:21:02,903 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:21:02,904 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-09T20:21:02,905 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 97, in handle
2022-02-09T20:21:02,906 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-09T20:21:03,021 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:03,021 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:03,026 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:03,029 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:03,032 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:03,033 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:03,034 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:03,036 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:03,037 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:03,050 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:03,055 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:03,055 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:03,057 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:03,060 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:21:03,061 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:03,064 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:03,068 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:03,093 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:03,112 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:03,115 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:03,117 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:03,119 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:03,122 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:03,196 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:03,197 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:03,201 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:03,204 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:03,206 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:03,210 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:03,222 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:03,224 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:03,226 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:03,228 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:03,279 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:03,280 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:03,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:03,287 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:03,289 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:03,297 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:03,304 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:03,320 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:03,324 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:03,375 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:03,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:03,380 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:03,382 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:03,384 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:03,387 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:03,390 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:03,392 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:03,393 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:03,395 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:11,007 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,008 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]36568
2022-02-09T20:21:11,013 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:11,014 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:11,021 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:21:11,025 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:11,141 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,142 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]28648
2022-02-09T20:21:11,147 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:11,148 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:11,154 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:21:11,157 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:11,526 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,527 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]41116
2022-02-09T20:21:11,532 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:11,538 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:11,545 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:21:11,549 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:11,596 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,597 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]35888
2022-02-09T20:21:11,604 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:11,616 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:11,622 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:21:11,627 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:11,839 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,840 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]32080
2022-02-09T20:21:11,845 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:11,846 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:11,853 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:21:11,858 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:11,994 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:11,995 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]38196
2022-02-09T20:21:11,998 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:12,000 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:12,006 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]17472
2022-02-09T20:21:12,008 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:12,009 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:12,012 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:21:12,014 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:12,026 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:12,029 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:21:12,034 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:12,289 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:12,290 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]43904
2022-02-09T20:21:12,294 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:12,296 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:12,312 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:21:12,325 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:12,436 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:12,437 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:12,442 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:12,445 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:12,447 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:12,452 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:12,466 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:12,469 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:12,471 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:12,474 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:12,589 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:12,589 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:12,595 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:12,598 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:12,599 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:12,602 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:12,606 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:12,609 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:12,624 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:12,626 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:12,629 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:12,994 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:12,995 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:13,006 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:13,009 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:13,014 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:13,015 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:13,016 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:13,018 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:13,021 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:13,030 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:13,032 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:13,033 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:13,035 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:13,048 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:13,056 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:13,058 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:13,059 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:13,060 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:13,090 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:13,091 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:21:13,095 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:13,097 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:21:13,114 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:13,122 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:13,123 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:13,125 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:13,126 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:13,127 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:13,129 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:21:13,140 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\faf60ff7e0554ef6a5ebe8069c408960\handler.py", line 108, in handle
2022-02-09T20:21:13,291 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:13,291 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:13,296 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:13,312 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:13,313 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:13,313 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:13,428 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:13,452 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:13,674 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:14,631 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:14,640 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:14,651 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:14,652 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:14,654 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:14,658 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:14,659 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:14,667 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:14,683 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:14,685 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:14,688 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:14,691 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:14,697 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:14,713 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:14,715 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:14,716 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:14,718 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:14,720 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:14,724 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:14,728 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:14,747 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:14,752 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:14,755 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:14,757 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:22,377 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:22,378 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]47320
2022-02-09T20:21:22,381 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:22,382 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:22,387 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:21:22,388 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:22,607 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:22,608 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]42588
2022-02-09T20:21:22,611 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:22,612 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:22,617 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:21:22,619 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:23,756 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:23,762 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]47388
2022-02-09T20:21:23,762 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:23,764 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:23,765 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]48076
2022-02-09T20:21:23,768 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:23,769 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:23,773 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:21:23,774 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:23,787 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:23,792 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:21:23,797 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:23,881 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:23,881 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:23,886 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:23,890 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:23,893 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:23,898 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:23,901 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:23,917 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:23,918 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:23,921 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:23,922 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:21:23,924 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:21:23,927 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:21:24,173 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:24,173 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:24,179 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:24,185 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:24,189 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:24,194 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:24,197 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:24,201 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:24,219 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:25,104 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:25,110 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:25,114 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:25,120 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:25,123 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:25,129 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:25,131 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:25,138 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:25,159 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:25,165 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:25,167 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:25,170 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:25,188 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:25,190 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:25,190 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:25,196 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:25,216 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:25,990 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:25,991 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]47836
2022-02-09T20:21:25,995 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:25,996 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:26,002 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:21:26,004 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:26,164 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:26,168 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]47900
2022-02-09T20:21:26,175 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:26,200 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:26,208 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:21:26,209 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:26,376 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:26,378 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]39228
2022-02-09T20:21:26,382 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:26,384 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:26,389 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:21:26,391 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:26,418 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:26,419 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]244
2022-02-09T20:21:26,421 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:26,422 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:26,426 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:21:26,433 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:27,019 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:27,019 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:27,024 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:27,027 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:27,030 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:27,033 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:27,036 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:27,038 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:27,040 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:27,042 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:27,156 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:27,156 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:27,161 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:27,163 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:27,166 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:27,170 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:27,184 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:27,187 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:27,188 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:27,190 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:27,273 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:27,274 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:27,288 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:27,291 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:27,293 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:27,309 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:27,309 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:27,314 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:27,321 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:27,323 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:27,324 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:27,334 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:27,335 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:27,336 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:27,349 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:27,353 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:27,372 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:38,604 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:38,605 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]46860
2022-02-09T20:21:38,610 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:38,611 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:38,617 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:21:38,619 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:39,054 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:39,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]47092
2022-02-09T20:21:39,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:39,056 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:39,058 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:21:39,060 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:39,371 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:39,371 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:39,372 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:39,373 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:39,375 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:39,378 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:39,381 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:39,383 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:39,385 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:39,387 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:39,795 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:39,796 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:39,800 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:39,804 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:39,811 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:39,830 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:39,833 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:39,835 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:39,837 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:39,839 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:40,096 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:40,180 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:40,770 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]41560
2022-02-09T20:21:40,772 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]3792
2022-02-09T20:21:40,775 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:40,775 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:40,777 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:40,789 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:40,794 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:21:40,798 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:21:40,805 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:40,816 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:41,889 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:41,889 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:41,893 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:41,894 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:41,901 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:41,905 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:41,908 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:41,909 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:41,911 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:41,925 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:41,928 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:41,929 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:41,932 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:41,935 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:41,937 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:41,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:41,941 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:41,976 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:43,036 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:43,037 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]38772
2022-02-09T20:21:43,041 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:43,042 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:43,046 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:21:43,048 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:43,063 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:43,066 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:43,067 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]35668
2022-02-09T20:21:43,067 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]22120
2022-02-09T20:21:43,068 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:43,068 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:43,070 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:43,070 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:43,074 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:21:43,075 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:21:43,075 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:43,088 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:43,120 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:21:43,121 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]43524
2022-02-09T20:21:43,122 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:21:43,123 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:21:43,134 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:21:43,148 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:21:43,954 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:43,954 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:43,959 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:43,961 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:43,962 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:43,963 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:43,968 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:43,971 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:43,984 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:43,987 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:43,989 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:43,990 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:43,993 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:43,995 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:43,999 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:44,001 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:44,002 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:44,025 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:44,031 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:44,050 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:44,109 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:21:44,721 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:44,744 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:44,754 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:21:44,755 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:21:44,769 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:21:44,774 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:44,777 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:44,780 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:21:44,783 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:44,788 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:21:44,815 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:44,823 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:21:44,830 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:21:44,835 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:21:44,836 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:21:44,843 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:51:45,727 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:45,825 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,107 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,124 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,209 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,327 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,327 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:51:46,471 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:52:53,858 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]45476
2022-02-09T20:52:53,890 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]42376
2022-02-09T20:52:53,916 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]11164
2022-02-09T20:52:53,935 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:52:54,010 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]43956
2022-02-09T20:52:54,013 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]39580
2022-02-09T20:52:54,042 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]36972
2022-02-09T20:52:54,070 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:52:54,103 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:52:54,103 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]37848
2022-02-09T20:52:54,103 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:52:54,104 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker did not receive connection in: 30
2022-02-09T20:52:54,179 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]17200
2022-02-09T20:56:21,818 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:21,821 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]43604
2022-02-09T20:56:21,828 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:21,830 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:21,897 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:56:22,017 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,074 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,076 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]35648
2022-02-09T20:56:22,082 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,097 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,153 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:56:22,183 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,246 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,264 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]32376
2022-02-09T20:56:22,265 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,271 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,302 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:56:22,356 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,379 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,381 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]39712
2022-02-09T20:56:22,394 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,419 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,471 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:56:22,494 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,497 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]2932
2022-02-09T20:56:22,498 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,524 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,532 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,618 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:56:22,729 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,820 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,822 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]34836
2022-02-09T20:56:22,831 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,847 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,885 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:56:22,923 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:22,948 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,951 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]28956
2022-02-09T20:56:22,961 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:22,968 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:22,969 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:22,989 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]46132
2022-02-09T20:56:22,998 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:23,001 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:56:23,017 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:23,063 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:23,084 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:56:23,121 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:25,535 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:25,537 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:25,551 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:25,589 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:25,599 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:25,618 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:25,626 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:25,661 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:25,673 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:25,702 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:25,724 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:56:25,728 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:56:25,731 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:56:25,761 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:25,790 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:25,823 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:25,842 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:25,862 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:25,941 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:25,943 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:25,958 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,039 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:26,056 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:26,066 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:26,087 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:26,117 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:26,160 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,176 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:26,204 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:26,204 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:26,251 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:26,286 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:26,301 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:26,389 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,395 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:26,396 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:26,429 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:26,509 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:26,512 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:26,525 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:26,592 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:26,693 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,697 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:26,739 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:26,739 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:26,762 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:26,805 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,830 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:26,885 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:26,901 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:26,934 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:26,964 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:26,991 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:27,021 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:27,037 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:27,042 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:27,077 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:27,091 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:27,130 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:27,132 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:27,182 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:27,207 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:27,208 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:27,239 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:56:27,242 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:27,320 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:33,605 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:33,607 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]35104
2022-02-09T20:56:33,629 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:33,631 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:33,674 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:56:33,726 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:34,410 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:34,412 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]36060
2022-02-09T20:56:34,430 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:34,432 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:34,453 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:56:34,502 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:34,532 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:34,534 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]32624
2022-02-09T20:56:34,542 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:34,548 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:34,601 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:56:34,642 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:34,701 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:34,703 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]43476
2022-02-09T20:56:34,711 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:34,728 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:34,784 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:56:34,846 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:34,898 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:34,900 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]44244
2022-02-09T20:56:34,906 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:34,907 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:34,923 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:34,932 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]27764
2022-02-09T20:56:34,950 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:34,967 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:56:34,980 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:35,003 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:35,004 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:56:35,065 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:35,674 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:35,799 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:56:36,605 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]22580
2022-02-09T20:56:36,644 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:36,644 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]44040
2022-02-09T20:56:36,647 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:36,650 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:56:36,672 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:56:36,676 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:56:36,741 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:36,742 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:56:36,815 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:56:37,075 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:37,076 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:37,099 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:37,109 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:37,134 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:37,168 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:37,192 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:37,211 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:37,235 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:37,926 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:37,927 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:37,937 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:37,956 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:37,969 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:37,977 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:38,005 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:38,020 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:38,060 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:38,062 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:38,071 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:38,104 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:38,117 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:38,126 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:38,142 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:38,211 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:38,270 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:38,280 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:38,344 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:38,361 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:38,375 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:38,395 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:38,426 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:38,442 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:38,488 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:38,525 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:38,577 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:38,608 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:38,640 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:38,658 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:38,661 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:38,689 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:38,788 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:38,790 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:38,804 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:38,831 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:38,871 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:38,876 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:38,933 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:38,937 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:38,939 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:38,971 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:39,583 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:39,640 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:39,659 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:39,676 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:39,681 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:39,736 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:39,752 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:39,767 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:39,782 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:39,873 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:40,352 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\190ca15d306c44e58fa9b9642fa4c902', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:56:40,353 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\190ca15d306c44e58fa9b9642fa4c902
2022-02-09T20:56:40,362 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:56:40,384 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:56:40,410 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:56:40,411 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:56:40,425 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:56:40,429 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:56:40,431 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:56:40,450 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:56:40,466 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:57:54,118 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:54,124 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]46580
2022-02-09T20:57:54,142 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:54,143 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:54,186 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:57:54,279 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:55,182 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:55,195 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]13288
2022-02-09T20:57:55,202 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:55,218 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:55,247 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:57:55,293 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:55,363 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:55,389 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:55,400 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]43684
2022-02-09T20:57:55,411 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]48060
2022-02-09T20:57:55,429 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:55,445 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:55,447 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:55,516 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:55,526 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:57:55,545 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:57:55,583 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:55,585 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:55,914 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:55,921 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]47532
2022-02-09T20:57:55,945 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:55,951 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:56,018 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:57:56,052 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:56,565 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:56,583 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]42600
2022-02-09T20:57:56,591 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:56,592 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:56,651 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:57:56,688 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:57,501 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:57,511 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]43224
2022-02-09T20:57:57,519 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:57,520 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:57,549 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:57:57,594 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:57,917 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:57:57,928 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:57:57,931 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:57:57,933 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:57:57,942 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:57:57,944 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:57:57,945 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:57:57,947 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:57:57,949 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:57:57,970 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:57:57,973 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:57:57,976 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:57:57,997 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:57:58,015 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:57:58,043 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:57:58,048 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:57:58,056 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]42336
2022-02-09T20:57:58,093 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:57:58,215 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:57:58,257 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:57:58,357 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:57:58,549 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:57:58,551 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:57:58,560 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:57:58,566 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:57:58,569 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:57:58,576 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:57:58,580 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:57:58,633 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:57:58,643 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:57:58,649 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:57:58,991 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:57:58,995 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:57:59,010 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:57:59,050 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:57:59,120 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:57:59,158 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:57:59,198 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:57:59,203 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:57:59,208 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:57:59,209 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:57:59,212 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:57:59,218 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:57:59,225 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:57:59,228 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:57:59,230 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:57:59,232 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:57:59,237 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:57:59,431 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:57:59,439 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:57:59,464 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:57:59,465 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:57:59,467 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:57:59,479 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:57:59,497 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:57:59,499 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:57:59,501 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:57:59,511 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:57:59,541 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:57:59,543 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:57:59,545 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:57:59,582 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:58:00,152 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:00,158 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:00,164 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:00,166 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:00,169 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:00,175 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:00,176 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:00,180 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:00,202 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:00,220 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:00,758 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:00,759 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:00,784 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:00,789 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:00,808 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:00,850 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:00,863 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:00,896 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:01,152 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:01,154 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:01,183 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:01,207 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:01,213 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:01,251 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:01,280 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:01,318 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:04,857 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:04,858 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]27712
2022-02-09T20:58:04,903 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:04,908 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:04,935 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:05,003 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:06,736 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:06,738 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]33476
2022-02-09T20:58:06,754 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:06,756 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:06,797 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:06,853 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:07,221 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:07,224 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]33772
2022-02-09T20:58:07,231 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:07,247 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:07,277 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:58:07,325 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:07,371 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:07,373 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]32948
2022-02-09T20:58:07,374 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:07,376 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:07,411 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:07,423 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:07,477 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:07,478 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]24724
2022-02-09T20:58:07,479 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:58:07,483 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:07,529 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:07,561 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:07,566 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:07,571 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:07,579 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:07,610 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:58:07,634 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:07,662 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:07,676 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:07,729 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:07,732 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]33640
2022-02-09T20:58:07,813 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:07,896 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:07,940 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:58:08,001 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:08,476 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:08,495 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]19812
2022-02-09T20:58:08,502 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:08,518 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:08,547 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:58:08,593 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:08,969 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:08,971 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]19356
2022-02-09T20:58:08,980 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:08,992 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:09,041 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:58:09,084 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:09,887 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:09,891 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:09,902 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:09,919 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:09,944 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:09,966 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:09,979 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:09,993 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:09,995 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:10,016 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:10,021 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:10,502 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:10,503 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:10,515 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:10,540 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:10,569 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:10,570 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:10,628 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:10,630 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:10,633 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:10,637 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:10,641 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:10,680 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:10,688 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:10,724 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:10,755 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:10,780 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:10,783 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:10,802 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:10,804 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:10,825 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:10,828 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:10,830 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:10,832 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:10,889 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:10,896 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:10,900 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:10,941 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:10,991 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:11,000 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:11,003 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:11,149 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:11,150 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:11,158 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:11,193 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:11,196 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:11,201 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:11,204 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:11,208 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:11,211 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:11,233 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:11,335 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:11,344 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:11,373 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:11,389 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:11,432 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:11,439 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:11,473 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:11,491 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:11,494 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:11,763 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:11,771 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:11,795 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:11,799 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:11,836 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:11,864 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:11,874 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:11,909 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:11,938 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:13,791 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:13,820 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]17576
2022-02-09T20:58:13,840 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:13,868 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:13,882 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:13,894 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:15,936 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:15,939 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]38824
2022-02-09T20:58:15,965 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:15,967 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:15,981 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:16,065 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:16,083 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:16,114 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:16,178 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:16,178 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:16,200 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:16,244 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:16,271 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:17,650 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:17,652 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]46356
2022-02-09T20:58:17,658 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:17,673 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:17,681 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:58:17,702 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:17,852 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:17,861 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]12032
2022-02-09T20:58:17,867 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:17,882 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:17,904 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:58:17,907 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:18,053 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:18,055 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]16908
2022-02-09T20:58:18,062 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:18,076 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:18,083 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:58:18,096 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:18,135 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:18,141 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]22624
2022-02-09T20:58:18,143 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:18,144 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:18,174 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:58:18,179 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:18,221 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:18,224 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:18,240 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:18,243 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:18,245 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:18,247 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:18,248 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:18,267 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:18,281 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:18,286 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:18,307 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:18,347 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:58:18,619 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:18,630 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]25412
2022-02-09T20:58:18,638 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:18,655 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:18,684 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:58:18,705 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:19,251 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:19,260 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]43328
2022-02-09T20:58:19,267 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:19,269 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:19,291 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:58:19,293 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:19,695 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:19,706 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:19,730 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:19,753 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:19,758 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:19,786 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:19,802 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:19,812 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:19,834 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:19,854 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:19,932 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:19,951 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:20,038 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:20,042 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:20,045 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:20,048 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:20,338 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:20,344 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:20,405 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:20,443 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:20,461 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:20,476 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:20,480 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:20,512 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:20,514 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:20,518 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:20,524 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:20,570 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:20,626 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:20,868 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:20,869 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:20,897 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:20,924 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:20,925 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:20,927 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:20,944 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:20,991 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:21,003 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:21,022 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:21,063 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:21,480 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:21,486 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:21,512 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:21,574 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:21,616 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:21,652 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:21,686 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:21,721 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:23,707 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:23,709 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]38880
2022-02-09T20:58:23,717 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:23,733 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:23,768 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:23,798 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:25,914 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:25,920 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:25,943 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:25,947 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:25,966 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:25,990 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:26,018 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:26,062 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:26,076 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:26,079 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:26,084 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:26,087 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:58:26,206 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:26,208 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]28312
2022-02-09T20:58:26,215 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:26,230 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:26,258 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:26,276 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:27,399 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:27,403 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]30016
2022-02-09T20:58:27,410 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:27,426 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:27,459 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:58:27,482 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:27,659 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:27,665 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]34628
2022-02-09T20:58:27,671 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:27,687 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:27,810 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:58:27,813 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:28,183 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:28,188 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]44700
2022-02-09T20:58:28,209 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:28,211 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:28,220 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:58:28,248 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:28,267 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:28,279 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:28,312 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:28,319 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:28,330 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:28,339 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:28,370 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:28,856 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:28,858 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]30620
2022-02-09T20:58:28,881 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:28,883 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:28,889 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:58:28,891 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:29,034 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:29,036 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]36780
2022-02-09T20:58:29,043 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:29,059 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:29,094 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:58:29,103 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:29,662 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:29,675 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:29,684 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:29,702 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:29,706 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:29,710 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:29,713 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:29,714 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:29,718 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:29,863 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:29,867 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]47756
2022-02-09T20:58:29,875 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:29,876 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:29,922 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:58:29,960 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:30,328 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:30,333 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:30,359 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:30,386 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:30,424 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:30,454 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:30,484 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:30,518 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:30,540 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:30,588 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:30,705 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:30,743 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:30,766 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:30,794 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:30,809 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:30,827 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:31,053 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:31,054 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:31,079 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:31,088 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:31,108 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:31,156 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:31,188 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:31,225 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:31,251 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:31,424 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:31,425 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:31,430 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:31,435 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:31,471 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:31,501 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:31,529 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:31,559 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:31,851 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:31,852 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:31,883 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:31,911 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:31,953 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:31,959 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:31,993 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:32,030 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:32,645 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:32,649 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]12628
2022-02-09T20:58:32,664 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:32,666 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:32,698 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:32,710 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:33,879 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:33,890 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:33,893 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:33,895 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:33,896 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:33,898 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:33,901 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:33,930 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:33,943 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:33,946 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:33,946 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:33,948 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:58:33,950 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:58:33,952 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:58:33,964 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:58:33,994 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:58:34,019 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 123, in handle
2022-02-09T20:58:34,021 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     raise e
2022-02-09T20:58:34,024 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 112, in handle
2022-02-09T20:58:34,212 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:34,213 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]41100
2022-02-09T20:58:34,221 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:34,240 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:34,267 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:34,284 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:35,942 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:35,943 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:35,967 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:35,986 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:35,989 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:35,993 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:35,996 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:35,998 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:36,024 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:36,268 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:36,272 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]45088
2022-02-09T20:58:36,279 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:36,295 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:36,323 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:58:36,326 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:37,576 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:37,577 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]42996
2022-02-09T20:58:37,584 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:37,586 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:37,615 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:58:37,627 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:37,976 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:37,977 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:38,003 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:38,027 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:38,045 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:38,054 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:38,091 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:38,093 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:38,102 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:38,105 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:38,107 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:38,115 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:58:38,229 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:38,230 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]34108
2022-02-09T20:58:38,260 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:38,268 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:38,341 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:58:38,343 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:38,589 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:38,593 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]44964
2022-02-09T20:58:38,600 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:38,615 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:38,644 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:58:38,659 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:38,829 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:38,830 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]37416
2022-02-09T20:58:38,852 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:38,858 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:38,887 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:58:38,923 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:39,565 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:39,580 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:39,604 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:39,606 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:39,631 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:39,670 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:39,694 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:39,725 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:39,734 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:39,758 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:39,819 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:39,833 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]34812
2022-02-09T20:58:39,888 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:39,895 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:39,927 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:58:39,946 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:40,299 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:40,313 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:40,322 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:40,324 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:40,329 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:40,332 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:40,335 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:40,337 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:40,364 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:40,554 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:40,555 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:40,579 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:40,583 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:40,600 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:40,627 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:40,650 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:40,900 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:40,901 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:40,922 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:40,925 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:40,928 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:40,962 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:40,971 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:41,002 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:41,739 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:41,740 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:41,764 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:41,789 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:41,815 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:41,830 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:41,846 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:41,853 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:43,317 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:43,326 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]7760
2022-02-09T20:58:43,327 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:43,329 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:43,334 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:43,337 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:44,843 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:44,844 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]26788
2022-02-09T20:58:44,851 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:44,867 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:44,896 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:44,909 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:44,925 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:44,934 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:44,978 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:45,007 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:45,030 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:45,034 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:45,036 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:45,039 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:46,772 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:46,776 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:46,813 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:46,825 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:46,865 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:46,870 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:46,876 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:46,894 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:48,229 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:48,230 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]44764
2022-02-09T20:58:48,237 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:48,251 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:48,302 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:58:48,337 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:50,571 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:50,573 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]35668
2022-02-09T20:58:50,579 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:50,597 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:50,641 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:58:50,666 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:50,897 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:50,911 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:50,933 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:50,936 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:50,962 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:50,965 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:50,968 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:50,978 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:50,997 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:51,547 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:51,551 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]44708
2022-02-09T20:58:51,558 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:51,573 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:51,580 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:58:51,584 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:51,648 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:51,652 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]47244
2022-02-09T20:58:51,662 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:51,678 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:51,685 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:58:51,700 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:52,465 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:52,491 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:52,513 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]30820
2022-02-09T20:58:52,517 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]27652
2022-02-09T20:58:52,518 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:52,520 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:52,522 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:52,525 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:52,534 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:58:52,536 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:58:52,541 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:52,551 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:52,621 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:52,639 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:52,648 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:52,682 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:52,684 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:52,708 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:52,711 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:52,744 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:52,763 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:52,795 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:53,245 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:53,247 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:53,273 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:53,281 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:53,282 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:53,302 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:53,304 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:53,337 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:53,344 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:53,379 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:53,412 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:53,445 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:53,471 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:53,487 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:53,544 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:53,549 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:53,972 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:53,973 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:53,995 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:53,999 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:54,018 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:54,022 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:54,026 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:54,029 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:54,047 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:54,094 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:54,122 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:54,127 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:54,149 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:54,153 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:54,180 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:55,466 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:55,472 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]43204
2022-02-09T20:58:55,473 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:55,473 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:55,476 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:58:55,486 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:56,485 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:56,486 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:56,495 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:56,496 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:56,497 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:56,498 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:56,498 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:56,499 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:56,499 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:56,501 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:56,502 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:58:57,206 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:58:57,207 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]38500
2022-02-09T20:58:57,211 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:58:57,212 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:58:57,214 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:58:57,215 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:58:58,272 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:58:58,276 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:58:58,276 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:58:58,277 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:58:58,277 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:58:58,278 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:58:58,279 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:58:58,279 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:58:58,279 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:58:58,280 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:58:58,281 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:01,272 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:01,285 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]43912
2022-02-09T20:59:01,285 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:01,286 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:01,289 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:59:01,316 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:03,292 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:03,294 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:03,295 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:03,295 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:03,296 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:03,296 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:03,296 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:03,297 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:03,298 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:03,300 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:03,302 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:03,303 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:03,328 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:03,329 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:05,277 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:05,288 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]46876
2022-02-09T20:59:05,295 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:05,296 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:05,299 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:59:05,306 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:06,369 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:06,371 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]35484
2022-02-09T20:59:06,373 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:06,373 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:06,377 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:59:06,379 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:06,483 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:06,485 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]27216
2022-02-09T20:59:06,493 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:06,494 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:06,497 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:59:06,499 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:07,222 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:07,227 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:07,228 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:07,235 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]45540
2022-02-09T20:59:07,236 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:07,236 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:07,236 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:07,237 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:07,238 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:07,239 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:07,239 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:59:07,240 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:07,241 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:07,241 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:07,241 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:07,243 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:07,243 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:07,252 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:07,289 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]37896
2022-02-09T20:59:07,289 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:07,290 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:07,292 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:59:07,294 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:08,322 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:08,324 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:08,331 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:08,331 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:08,332 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:08,333 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:08,334 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:08,334 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:08,335 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:08,336 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:08,337 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:08,337 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:08,338 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:08,339 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:08,339 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:59:08,563 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:08,566 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:08,576 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:08,577 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:08,577 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:08,579 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:08,579 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:08,579 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:08,580 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:08,582 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:08,583 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:09,156 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:09,156 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:09,163 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:09,163 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:09,164 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:09,165 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:09,166 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:09,166 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:09,167 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:09,168 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:09,169 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:09,187 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:09,201 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:09,202 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:09,203 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:09,205 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:09,205 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:09,206 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:09,207 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:09,208 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:09,209 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:09,210 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:12,898 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:12,899 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]48020
2022-02-09T20:59:12,906 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:12,906 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:12,910 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:59:12,912 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:14,856 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:14,857 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:14,866 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:14,867 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:14,867 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:14,869 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:14,871 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:14,873 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:14,875 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:14,879 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:15,604 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:15,606 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]28064
2022-02-09T20:59:15,614 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:15,614 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:15,618 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:59:15,620 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:17,026 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:17,027 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:17,034 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:17,035 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:17,037 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:17,038 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:17,038 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:17,039 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:17,039 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:17,041 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:18,913 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:18,921 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]45036
2022-02-09T20:59:18,922 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:18,922 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:18,925 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:59:18,931 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:19,899 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:19,899 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:19,905 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:19,906 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:19,906 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:19,907 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:19,908 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:19,908 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:19,909 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:19,910 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:19,911 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:19,912 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:22,904 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:22,906 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]32968
2022-02-09T20:59:22,911 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:22,911 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:22,914 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:59:22,916 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:24,822 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:24,864 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:24,866 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:24,867 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:24,867 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:24,869 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:24,870 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:24,871 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:24,871 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:24,872 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:24,873 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:25,138 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:25,152 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]38832
2022-02-09T20:59:25,153 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:25,153 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:25,157 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:59:25,159 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:25,557 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:25,557 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]37496
2022-02-09T20:59:25,563 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:25,564 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:25,567 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:59:25,570 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:26,054 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:26,055 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]47808
2022-02-09T20:59:26,060 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:26,061 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:26,064 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:59:26,066 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:26,092 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:26,095 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]8692
2022-02-09T20:59:26,098 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:26,101 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:26,110 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:59:26,140 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:26,543 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:26,543 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:26,551 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:26,552 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:26,552 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:26,552 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:26,553 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:26,554 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:26,555 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:26,556 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:26,557 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:26,557 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:26,562 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:26,563 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:26,563 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:59:26,564 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:59:26,565 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 123, in handle
2022-02-09T20:59:26,565 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     raise e
2022-02-09T20:59:26,566 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 112, in handle
2022-02-09T20:59:26,591 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     _service.initialize(context)
2022-02-09T20:59:26,592 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 37, in initialize
2022-02-09T20:59:26,594 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-09T20:59:26,595 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-09T20:59:27,000 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:27,002 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:27,009 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:27,010 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:27,010 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:27,012 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:27,012 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:27,014 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:27,014 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:27,016 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:27,360 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:27,361 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:27,366 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:27,367 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:27,367 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:27,367 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:27,369 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:27,369 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:27,370 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:27,371 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:27,372 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:27,440 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:27,440 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:27,441 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:27,441 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:27,442 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:27,442 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:27,443 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:27,444 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:27,444 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:27,445 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:27,446 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:27,446 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:27,447 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:27,447 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:38,056 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:38,057 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]41552
2022-02-09T20:59:38,057 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:38,057 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:38,060 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T20:59:38,070 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:39,309 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:39,310 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:39,317 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:39,317 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:39,318 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:39,319 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:39,320 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:39,320 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:39,321 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:39,322 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:39,323 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:40,477 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:40,477 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]41280
2022-02-09T20:59:40,481 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:40,481 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:40,483 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T20:59:40,484 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:42,065 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:42,071 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:42,085 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:42,085 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:42,085 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:42,086 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:42,087 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:42,088 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:42,088 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:42,090 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:42,091 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:42,092 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:44,783 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:44,784 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]44416
2022-02-09T20:59:44,789 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:44,789 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:44,792 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T20:59:44,794 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:46,484 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:46,485 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:46,492 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:46,492 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:46,492 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:46,494 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:46,494 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:46,495 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:46,495 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:46,496 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:46,496 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:46,496 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:46,497 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:48,578 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:48,579 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]40892
2022-02-09T20:59:48,579 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:48,580 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:48,583 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T20:59:48,591 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:50,542 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:50,544 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:50,551 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:50,552 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:50,553 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:50,556 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:50,556 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:50,556 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:50,557 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:50,558 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:50,559 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:50,560 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:50,561 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:50,561 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:51,341 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:51,342 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]36640
2022-02-09T20:59:51,342 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:51,342 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:51,346 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T20:59:51,396 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:51,768 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:51,769 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]34908
2022-02-09T20:59:51,774 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:51,774 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:51,777 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T20:59:51,779 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:52,186 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:52,187 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]45976
2022-02-09T20:59:52,191 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:52,191 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:52,193 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T20:59:52,194 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:52,301 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T20:59:52,301 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]40612
2022-02-09T20:59:52,306 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T20:59:52,306 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T20:59:52,308 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T20:59:52,309 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T20:59:52,659 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:52,660 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:52,667 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:52,668 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:52,668 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:52,668 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:52,670 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:52,670 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:52,671 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:52,672 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:52,672 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:52,672 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:52,673 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:52,674 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:52,674 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:59:53,136 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:53,136 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:53,143 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:53,143 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:53,144 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:53,147 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:53,148 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:53,149 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:53,149 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:53,150 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:53,151 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:53,468 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:53,477 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:53,477 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:53,478 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:53,478 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:53,479 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:53,481 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:53,481 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:53,482 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:53,482 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:53,483 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:53,483 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:53,484 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T20:59:53,484 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T20:59:53,485 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T20:59:53,485 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T20:59:53,591 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T20:59:53,591 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T20:59:53,596 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T20:59:53,596 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T20:59:53,598 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T20:59:53,598 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T20:59:53,598 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T20:59:53,599 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T20:59:53,599 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T20:59:53,599 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T20:59:53,600 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T20:59:53,600 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T20:59:53,601 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:00:15,337 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:15,337 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]39524
2022-02-09T21:00:15,342 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:15,342 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:15,344 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T21:00:15,344 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:16,202 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:16,202 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:16,213 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:16,213 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:16,214 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:16,215 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:16,216 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:16,216 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:16,216 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:16,218 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:16,218 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:18,219 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:18,220 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]42600
2022-02-09T21:00:18,223 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:18,223 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:18,225 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T21:00:18,226 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:20,196 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:20,208 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:20,209 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:20,210 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:20,210 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:20,211 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:20,213 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:20,213 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:20,213 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:20,214 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:20,214 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:20,214 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:00:20,215 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:00:20,215 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:00:20,216 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:00:20,216 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T21:00:20,218 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57\handler.py", line 123, in handle
2022-02-09T21:00:20,243 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     raise e
2022-02-09T21:00:22,775 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:22,775 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]44684
2022-02-09T21:00:22,779 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:22,779 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:22,782 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T21:00:22,783 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:23,604 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:23,605 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:23,614 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:23,614 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:23,614 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:23,615 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:23,616 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:23,617 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:23,617 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:23,619 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:23,619 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:27,296 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:27,297 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]46652
2022-02-09T21:00:27,301 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:27,302 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:27,305 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T21:00:27,306 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:28,734 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:28,736 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:28,743 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:28,743 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:28,744 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:28,745 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:28,745 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:28,746 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:28,746 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:28,747 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:28,747 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:28,748 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:00:28,748 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:00:28,749 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:00:28,749 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:00:28,750 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T21:00:29,758 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:29,759 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]47624
2022-02-09T21:00:29,764 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:29,765 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:29,767 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T21:00:29,768 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:30,228 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:30,233 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]43904
2022-02-09T21:00:30,233 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:30,233 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:30,237 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T21:00:30,238 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:30,597 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:30,598 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]31116
2022-02-09T21:00:30,604 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:30,604 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:30,607 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T21:00:30,609 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:30,651 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:00:30,654 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]28564
2022-02-09T21:00:30,660 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:00:30,660 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:00:30,663 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T21:00:30,664 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:00:31,032 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:31,035 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:31,035 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:31,036 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:31,036 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:31,038 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:31,038 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:31,039 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:31,039 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:31,077 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:31,078 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:31,476 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:31,477 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:31,483 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:31,484 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:31,484 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:31,486 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:31,486 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:31,487 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:31,487 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:31,487 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:31,488 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:31,488 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:00:31,489 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:00:31,772 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:31,773 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:31,779 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:31,779 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:31,780 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:31,781 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:31,781 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:31,782 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:31,782 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:31,782 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:31,782 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:00:31,783 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:00:31,783 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:00:31,784 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:00:31,812 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:00:31,820 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:00:31,821 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:00:31,821 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:00:31,822 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:00:31,823 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:00:31,827 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:00:31,830 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:00:31,831 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:00:31,832 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:00:31,833 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:13,231 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:13,231 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]34552
2022-02-09T21:01:13,235 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:13,235 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:13,237 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T21:01:13,237 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:13,988 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:13,988 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:13,995 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:13,996 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:13,996 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:13,997 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:13,998 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:13,999 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:14,000 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:14,000 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:14,000 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:14,001 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:14,001 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:14,001 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:01:14,002 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:01:14,002 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T21:01:17,143 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:17,149 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]34388
2022-02-09T21:01:17,149 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:17,150 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:17,152 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T21:01:17,153 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:17,996 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:17,997 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:17,998 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:17,998 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:17,998 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:18,000 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:18,000 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:18,001 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:18,001 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:18,002 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:18,004 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:18,005 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:20,655 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:20,656 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]17572
2022-02-09T21:01:20,656 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:20,656 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:20,659 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T21:01:20,664 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:21,433 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:21,433 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:21,438 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:21,439 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:21,439 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:21,440 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:21,441 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:21,441 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:21,441 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:21,442 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:21,442 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:21,443 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:21,443 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:25,716 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:25,717 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]45900
2022-02-09T21:01:25,721 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:25,721 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:25,724 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T21:01:25,724 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:26,631 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:26,639 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:26,640 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:26,641 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:26,641 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:26,642 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:26,643 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:26,643 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:26,667 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:26,668 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:26,668 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:26,669 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:26,670 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:26,695 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:01:26,696 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:01:28,934 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:28,935 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]22832
2022-02-09T21:01:28,940 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:28,940 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:28,943 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T21:01:28,946 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:29,498 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:29,499 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]35652
2022-02-09T21:01:29,504 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:29,504 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:29,507 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T21:01:29,509 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:29,765 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:29,766 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]44672
2022-02-09T21:01:29,766 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:29,766 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:01:29,766 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:29,767 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]38916
2022-02-09T21:01:29,767 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:01:29,768 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:01:29,769 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T21:01:29,770 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T21:01:29,771 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:29,772 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:01:30,233 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:30,234 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:30,241 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:30,241 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:30,242 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:30,242 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:30,243 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:30,244 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:30,245 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:30,245 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:30,246 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:30,246 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:30,246 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:30,247 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:01:30,706 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:30,707 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:30,715 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:30,715 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:30,716 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:30,716 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:30,717 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:30,718 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:30,719 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:30,720 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:30,720 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:30,721 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:30,721 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:30,721 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:01:30,722 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:01:30,912 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:30,913 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:30,918 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:30,918 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:30,919 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:30,919 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:30,920 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:30,921 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:30,921 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:30,922 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:30,922 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:30,922 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:30,923 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:01:30,923 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:01:30,924 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:01:30,935 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:01:30,962 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:01:30,962 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:01:30,962 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:01:30,964 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:01:30,964 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:01:30,964 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:01:30,965 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:01:30,965 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:01:30,965 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:01:30,966 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:01:30,966 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:01:30,966 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:02:45,431 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:02:45,431 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]42932
2022-02-09T21:02:45,435 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:02:45,435 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:02:45,437 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T21:02:45,438 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:02:46,253 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\75f0adf03c4e42548284a6611c731b57', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:02:46,265 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\75f0adf03c4e42548284a6611c731b57
2022-02-09T21:02:46,266 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:02:46,266 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:02:46,268 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:02:46,269 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:02:46,269 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:02:46,269 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:02:46,306 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:02:46,307 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:08,602 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,602 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,604 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]6832
2022-02-09T21:59:08,605 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]30020
2022-02-09T21:59:08,605 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,605 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,605 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,606 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,624 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,627 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]47768
2022-02-09T21:59:08,627 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,628 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,644 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T21:59:08,644 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T21:59:08,644 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T21:59:08,647 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,648 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]39120
2022-02-09T21:59:08,648 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,649 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,658 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T21:59:08,720 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,721 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,721 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,721 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,722 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]45108
2022-02-09T21:59:08,722 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,726 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,737 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,760 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T21:59:08,786 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,808 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,810 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]40608
2022-02-09T21:59:08,812 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,813 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,821 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T21:59:08,847 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,878 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,880 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]34852
2022-02-09T21:59:08,880 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,881 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,887 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T21:59:08,938 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:08,948 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:08,950 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]35540
2022-02-09T21:59:08,950 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:08,952 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:08,962 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T21:59:09,002 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:10,233 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,233 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,237 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,237 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,238 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,239 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,242 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,246 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,246 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,254 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,262 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,271 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,274 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,276 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,279 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,280 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,286 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,287 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,289 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,290 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,291 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,292 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,303 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,313 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,313 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,314 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,315 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,316 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,317 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,320 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,321 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,322 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,349 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:10,375 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,379 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:10,387 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,415 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,415 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,416 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,417 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,418 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,419 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:10,460 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:10,473 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:10,475 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,477 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:10,498 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:10,503 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:10,548 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:10,549 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:10,570 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:10,573 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:10,587 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,589 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:10,591 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:10,612 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:10,613 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:10,614 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:10,617 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:59:10,620 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:10,636 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:10,643 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:10,648 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:14,647 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,649 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - [PID]19552
2022-02-09T21:59:14,652 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,653 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,662 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-09T21:59:14,699 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,708 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,709 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]41108
2022-02-09T21:59:14,710 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,711 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,718 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-09T21:59:14,758 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,799 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,799 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]29480
2022-02-09T21:59:14,803 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,805 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,812 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-09T21:59:14,849 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,850 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,883 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]1408
2022-02-09T21:59:14,888 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,890 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,894 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-09T21:59:14,899 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,902 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,906 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]39416
2022-02-09T21:59:14,912 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - [PID]45060
2022-02-09T21:59:14,912 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,914 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,914 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,921 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,943 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-09T21:59:14,944 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,958 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-09T21:59:14,977 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:14,978 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,978 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]16904
2022-02-09T21:59:14,981 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:14,982 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:14,990 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:14,991 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-09T21:59:15,030 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:15,080 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:15,081 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]41876
2022-02-09T21:59:15,085 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T21:59:15,086 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T21:59:15,093 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T21:59:15,118 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T21:59:16,000 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,000 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,004 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,007 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,010 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,011 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,012 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,014 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,020 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,028 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:16,040 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:59:16,041 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-09T21:59:16,050 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-09T21:59:16,079 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-09T21:59:16,083 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-09T21:59:16,084 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-09T21:59:16,085 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414\handler.py", line 123, in handle
2022-02-09T21:59:16,087 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     raise e
2022-02-09T21:59:16,097 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414\handler.py", line 112, in handle
2022-02-09T21:59:16,097 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     _service.initialize(context)
2022-02-09T21:59:16,098 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414\handler.py", line 37, in initialize
2022-02-09T21:59:16,101 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-09T21:59:16,143 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,144 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,148 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,151 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,154 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,157 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,159 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,162 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,163 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,167 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:16,182 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,183 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,185 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,187 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,190 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,191 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,214 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,217 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,220 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,222 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:16,224 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-09T21:59:16,249 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,250 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,251 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,252 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,255 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,259 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,260 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,264 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,276 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,280 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,281 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,284 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,286 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,289 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,290 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,292 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,339 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,343 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,346 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,348 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,351 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,354 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,356 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,358 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,369 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,385 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,386 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,387 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,389 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,401 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,404 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:16,411 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T21:59:16,411 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T21:59:16,413 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T21:59:16,414 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T21:59:16,417 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T21:59:16,418 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T21:59:16,426 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T21:59:16,430 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T21:59:16,446 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T21:59:16,457 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T21:59:19,883 [INFO ] W-9004-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:19,989 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:20,023 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:20,063 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:20,101 [INFO ] W-9007-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:20,123 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T21:59:20,131 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T23:39:26,447 [INFO ] W-9005-sentencemoji_1.1-stdout MODEL_LOG - [PID]37272
2022-02-09T23:39:26,449 [INFO ] W-9000-sentencemoji_1.1-stdout MODEL_LOG - [PID]38936
2022-02-09T23:39:26,459 [INFO ] W-9002-sentencemoji_1.1-stdout MODEL_LOG - [PID]38916
2022-02-09T23:39:26,460 [INFO ] W-9003-sentencemoji_1.1-stdout MODEL_LOG - [PID]244
2022-02-09T23:39:26,498 [INFO ] W-9006-sentencemoji_1.1-stdout MODEL_LOG - [PID]30208
2022-02-09T23:39:28,005 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Listening on port: None
2022-02-09T23:39:28,006 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - [PID]22360
2022-02-09T23:39:28,008 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Torch worker started.
2022-02-09T23:39:28,009 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-09T23:39:28,022 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-09T23:39:28,027 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-09T23:39:28,743 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\5c86bc825e4e4867a27e97d281f9f414', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-09T23:39:28,744 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\5c86bc825e4e4867a27e97d281f9f414
2022-02-09T23:39:28,748 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Backend worker process died.
2022-02-09T23:39:28,750 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-09T23:39:28,751 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-09T23:39:28,753 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     worker.run_server()
2022-02-09T23:39:28,754 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-09T23:39:28,758 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-09T23:39:28,758 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-09T23:39:28,760 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-09T23:39:28,761 [INFO ] W-9001-sentencemoji_1.1-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
