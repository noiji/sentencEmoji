2022-02-16T14:16:30,182 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,190 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]5372
2022-02-16T14:16:30,194 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,202 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,241 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:30,327 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,520 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,524 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]20900
2022-02-16T14:16:30,528 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,536 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,550 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:30,587 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,703 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,705 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]14688
2022-02-16T14:16:30,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,718 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,727 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:30,751 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:30,754 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32528
2022-02-16T14:16:30,756 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:30,760 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:30,763 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:30,769 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:30,808 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,222 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,224 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]31604
2022-02-16T14:16:31,225 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,225 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,232 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:31,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,359 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,361 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]29732
2022-02-16T14:16:31,366 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,374 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,404 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:31,439 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,617 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,619 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19916
2022-02-16T14:16:31,623 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,631 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,639 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:31,683 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:31,789 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:31,791 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]53036
2022-02-16T14:16:31,795 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:31,802 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:31,812 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:31,843 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:33,785 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:33,786 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:33,792 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:33,802 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:33,806 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:33,807 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:33,809 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:33,811 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:33,813 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:33,827 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:33,828 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:33,830 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:16:33,832 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:16:33,834 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T14:16:33,836 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T14:16:33,841 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T14:16:33,859 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 123, in handle
2022-02-16T14:16:33,890 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T14:16:33,892 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 112, in handle
2022-02-16T14:16:33,897 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T14:16:33,898 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85\handler.py", line 37, in initialize
2022-02-16T14:16:33,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T14:16:33,912 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-16T14:16:33,913 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     pretrained_model_name_or_path, return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs
2022-02-16T14:16:33,939 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 582, in from_pretrained
2022-02-16T14:16:33,944 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-02-16T14:16:34,182 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,184 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,188 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,204 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,215 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,224 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,237 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,246 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,252 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,258 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,260 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:34,264 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:16:34,266 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,277 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,296 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,304 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,313 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,326 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,329 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,331 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,336 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,412 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,413 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,427 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,432 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,436 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,451 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,461 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,465 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,467 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,471 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,483 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,500 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,521 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,524 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,528 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,541 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,557 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,664 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,665 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,672 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,681 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,686 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,710 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,717 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,723 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,733 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,869 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,869 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:34,870 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,877 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:34,890 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,901 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:34,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,912 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:34,919 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,922 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:34,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,941 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:34,947 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:34,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:34,952 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:34,952 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:34,969 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:16:34,996 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:40,772 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:40,773 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]26936
2022-02-16T14:16:40,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:40,785 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:40,794 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:40,852 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,035 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,042 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]15352
2022-02-16T14:16:42,043 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,050 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,060 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:42,123 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,226 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,228 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]40788
2022-02-16T14:16:42,233 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,241 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,251 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:42,278 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:42,280 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]3380
2022-02-16T14:16:42,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:42,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:42,299 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:42,319 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:42,376 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,159 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,161 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]26428
2022-02-16T14:16:43,165 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,173 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,189 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:43,214 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,238 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,239 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]57660
2022-02-16T14:16:43,241 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,246 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,278 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:43,302 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,553 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,554 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]34200
2022-02-16T14:16:43,559 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,567 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,610 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:43,648 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:43,686 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:43,690 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29072
2022-02-16T14:16:43,693 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:43,703 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:43,734 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:43,776 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:44,520 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:44,521 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:44,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:44,537 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:44,546 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:44,556 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:44,571 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:44,583 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:44,586 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,491 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,492 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,495 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,495 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,505 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,512 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,529 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,538 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,546 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,555 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,560 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,572 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,577 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,583 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,585 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,587 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,591 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,611 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:45,754 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:45,755 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:45,762 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:45,771 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:45,776 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:45,788 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:45,797 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:45,801 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:45,805 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,143 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,144 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,149 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,162 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,167 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,180 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,193 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,210 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,386 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,387 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,392 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,402 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,411 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,428 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,442 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,443 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,449 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:46,612 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,613 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,615 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,620 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,630 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,639 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,654 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,672 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,687 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:46,733 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:46,735 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:46,747 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:46,774 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:46,789 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:46,794 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:46,796 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:46,808 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:46,809 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:46,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:51,783 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:51,788 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]38124
2022-02-16T14:16:51,789 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:51,796 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:51,806 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:16:51,813 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:52,995 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:52,999 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:53,001 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]26048
2022-02-16T14:16:53,009 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,011 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,013 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]18052
2022-02-16T14:16:53,016 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,021 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:16:53,033 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,046 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:53,079 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:16:53,082 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:53,281 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:53,283 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32012
2022-02-16T14:16:53,288 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:53,296 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:53,316 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:16:53,327 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,074 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,076 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]39268
2022-02-16T14:16:54,080 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,096 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:16:54,102 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,354 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,356 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]24516
2022-02-16T14:16:54,360 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,368 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,389 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:16:54,396 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,399 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,405 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]16072
2022-02-16T14:16:54,412 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,419 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:54,427 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:16:54,437 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:54,986 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:16:54,987 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]21272
2022-02-16T14:16:54,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:16:54,999 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:16:55,017 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:16:55,021 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:16:55,486 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:55,487 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:55,501 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:55,515 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:55,535 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:55,542 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:55,560 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:55,570 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:55,572 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:55,578 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:56,128 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,129 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,143 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,146 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,151 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,152 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,169 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,170 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,172 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,174 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,197 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:56,197 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,219 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,222 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:16:56,229 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,266 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,312 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,329 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,626 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:56,627 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:56,641 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:56,645 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:56,648 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:56,661 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:56,668 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:56,670 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:56,672 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,044 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,046 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,060 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,064 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,067 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,083 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,086 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,091 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,229 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,230 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,243 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,256 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,259 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,278 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,279 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,283 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,313 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,318 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,322 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,331 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,345 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,347 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,351 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:16:57,486 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:16:57,487 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:16:57,501 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:16:57,505 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:16:57,520 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:16:57,529 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:16:57,532 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:16:57,534 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:16:57,539 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:03,572 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:03,574 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]21500
2022-02-16T14:17:03,579 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:03,586 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:03,594 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:03,597 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,379 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,380 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]56900
2022-02-16T14:17:04,389 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,391 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,410 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:04,423 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,619 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,621 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]23820
2022-02-16T14:17:04,625 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,629 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:04,633 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,636 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]42004
2022-02-16T14:17:04,641 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:04,650 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:04,658 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:04,675 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:04,684 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:04,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:05,849 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:05,851 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]18040
2022-02-16T14:17:05,856 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:05,864 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:05,872 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:05,875 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,120 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,121 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]24632
2022-02-16T14:17:06,125 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,133 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,140 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:06,150 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,240 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]51028
2022-02-16T14:17:06,245 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,253 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,259 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:06,263 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:06,688 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:06,689 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]31220
2022-02-16T14:17:06,700 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:06,707 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:06,729 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:06,740 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:07,097 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,098 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,112 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,117 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,121 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,123 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,137 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,142 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:07,508 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,509 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,523 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,527 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,530 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,533 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,550 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,554 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:07,926 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:07,927 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:07,940 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:07,944 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:07,949 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:07,952 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:07,967 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:07,971 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,031 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,061 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,071 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,080 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,083 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,087 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,649 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,650 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,660 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,664 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,666 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,670 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,684 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,695 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,700 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,715 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,729 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:08,734 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,737 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:08,758 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,780 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,796 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,798 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,803 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,930 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:08,932 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:08,944 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:08,948 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:08,952 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:08,967 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:08,975 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:08,978 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:08,982 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:09,031 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:09,032 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:09,041 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:09,062 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:09,075 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:09,083 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:09,088 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:09,093 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:16,083 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:16,084 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]16696
2022-02-16T14:17:16,089 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:16,097 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:16,126 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:16,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:16,733 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:16,735 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]51912
2022-02-16T14:17:16,740 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:16,748 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:16,754 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:16,757 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:17,103 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:17,110 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]33356
2022-02-16T14:17:17,110 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:17,116 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:17,123 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:17,136 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:17,238 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:17,239 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]14956
2022-02-16T14:17:17,243 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:17,251 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:17,258 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:17,262 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,300 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,301 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]15996
2022-02-16T14:17:18,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,316 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,325 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:18,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,605 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,607 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]55844
2022-02-16T14:17:18,612 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,620 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,629 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:18,632 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,676 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,677 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]48524
2022-02-16T14:17:18,682 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,690 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,700 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:18,718 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:18,897 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:18,899 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]38064
2022-02-16T14:17:18,903 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:18,911 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:18,920 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:18,934 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:19,114 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:19,115 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:19,128 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:19,133 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:19,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:19,155 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:19,159 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:19,162 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:19,976 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:19,977 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:19,991 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:19,995 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:20,009 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,018 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,022 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,025 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,029 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:20,041 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:20,265 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:20,266 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:20,280 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:20,284 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:20,290 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,304 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,308 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,311 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,314 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:20,545 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:20,546 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:20,552 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:20,562 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:20,567 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:20,573 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:20,590 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:20,593 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:20,598 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,178 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,179 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,184 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,188 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,196 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,204 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,209 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,213 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,244 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,246 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,252 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,253 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,281 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,284 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,336 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:21,341 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,346 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,352 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,382 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,405 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,408 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,412 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:21,517 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:21,518 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:21,531 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:21,536 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:21,549 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:21,557 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:21,560 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:21,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:21,564 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:28,283 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:28,964 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:29,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:30,726 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]50192
2022-02-16T14:17:30,726 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]24420
2022-02-16T14:17:30,729 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]35316
2022-02-16T14:17:30,896 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,897 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,897 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:30,900 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,902 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,904 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:30,911 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:30,940 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:30,945 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:30,948 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:30,952 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:30,956 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:33,499 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,501 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,509 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,510 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,516 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,523 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,528 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,533 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,544 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,551 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:33,552 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,557 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:33,557 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,560 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,563 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,582 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,585 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:33,590 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:33,615 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:33,616 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:33,620 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:33,622 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:33,625 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:33,701 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:33,710 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:33,719 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:36,054 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]43848
2022-02-16T14:17:36,075 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,077 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,085 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:36,088 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,258 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,259 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]15712
2022-02-16T14:17:36,264 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,264 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,276 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:36,279 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,363 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,364 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]31200
2022-02-16T14:17:36,368 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,376 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,392 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:36,398 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:36,465 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:36,467 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]55000
2022-02-16T14:17:36,471 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:36,479 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:36,485 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:36,489 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:37,174 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:37,176 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19328
2022-02-16T14:17:37,180 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:37,188 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:37,196 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:37,199 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:38,316 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,317 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,330 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,339 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,350 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,366 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,373 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,375 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,377 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:38,392 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:38,493 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,494 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,499 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,508 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,512 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,516 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,528 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,533 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,535 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,537 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,541 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:38,546 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,572 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,576 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,580 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,601 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:38,726 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:38,727 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:38,742 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:38,746 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:38,752 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:38,756 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:38,775 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:38,779 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:39,129 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:39,131 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:39,144 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:39,148 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:39,159 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:39,167 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:39,171 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:39,173 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:39,177 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:45,285 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,286 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]15348
2022-02-16T14:17:45,296 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,298 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,306 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:17:45,309 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:45,338 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,340 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]45496
2022-02-16T14:17:45,344 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,352 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,363 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:17:45,368 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:45,697 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:45,699 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]45980
2022-02-16T14:17:45,704 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:45,713 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:45,734 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:17:45,742 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:47,206 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:47,209 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:47,221 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:47,236 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:47,246 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:47,250 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:47,266 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:47,270 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:47,619 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:47,620 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:47,635 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:47,639 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:47,653 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:47,657 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:47,669 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:47,672 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:47,675 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:48,302 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:48,303 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:48,316 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:48,331 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:48,344 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:48,348 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:48,366 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:48,369 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:52,175 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,179 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]16636
2022-02-16T14:17:52,184 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,192 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,201 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:17:52,221 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,292 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,308 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]23708
2022-02-16T14:17:52,313 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,321 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,343 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:17:52,354 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,573 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,576 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]2312
2022-02-16T14:17:52,580 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,588 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,596 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:17:52,600 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:52,646 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:52,667 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]21828
2022-02-16T14:17:52,671 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:52,680 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:52,689 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:17:52,692 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:53,838 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:17:53,848 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]17948
2022-02-16T14:17:53,857 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:17:53,861 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:17:53,893 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:17:53,906 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:17:54,983 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:54,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,003 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,007 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,012 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,015 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,032 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,036 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,176 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,190 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,203 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,216 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,240 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,244 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,246 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,254 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,273 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,274 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,282 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:55,286 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,288 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:55,290 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,297 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,302 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,309 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,312 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,320 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:55,333 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,342 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:55,352 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:55,359 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,363 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:55,363 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:55,365 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:55,367 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:55,372 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:55,395 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:55,400 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:55,412 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:55,422 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:56,295 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:17:56,297 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:17:56,312 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:17:56,320 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:17:56,341 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:17:56,344 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:17:56,346 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:17:56,350 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:17:56,352 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:17:56,356 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:17:56,358 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:17:56,369 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:17:56,387 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:18:04,823 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:04,829 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]13328
2022-02-16T14:18:04,833 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:04,841 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:04,849 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:18:04,855 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:05,262 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:05,264 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]35136
2022-02-16T14:18:05,269 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:05,277 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:05,284 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:18:05,290 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:06,060 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:06,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]38240
2022-02-16T14:18:06,066 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:06,074 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:06,084 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:18:06,096 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:06,722 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:06,723 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:06,739 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:06,741 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:06,758 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:06,767 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:06,771 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:06,773 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:06,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:07,193 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:07,199 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:07,220 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:07,227 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:07,235 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:07,256 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:07,260 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:07,262 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:07,266 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:07,890 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:07,891 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:07,909 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:07,912 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:07,917 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:07,921 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:07,924 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:07,927 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:07,931 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:13,074 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,076 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27408
2022-02-16T14:18:13,080 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,091 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,101 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:18:13,113 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,195 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,200 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]49452
2022-02-16T14:18:13,201 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,209 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,233 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:18:13,241 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,303 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,304 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]45672
2022-02-16T14:18:13,308 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,336 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:18:13,340 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:13,343 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:13,344 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]13764
2022-02-16T14:18:13,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:13,362 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:13,367 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:18:13,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:15,023 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:15,024 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]3000
2022-02-16T14:18:15,029 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:15,037 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:15,045 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:18:15,049 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:15,359 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,362 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,376 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,379 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,381 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,425 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,434 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,445 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,450 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:15,478 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:18:15,625 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,633 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,646 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,650 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,657 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,672 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,680 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,680 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,682 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,687 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,703 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,710 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:15,718 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,749 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,757 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,773 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,784 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:15,793 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:15,808 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:15,864 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:15,873 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:15,893 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:15,897 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:15,899 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:15,902 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:17,012 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:17,015 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:17,030 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:17,036 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:17,046 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:17,064 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:17,067 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:17,068 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:17,072 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:32,106 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:32,107 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]7492
2022-02-16T14:18:32,112 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:32,120 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:32,129 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:18:32,132 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:32,594 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:32,597 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]41624
2022-02-16T14:18:32,602 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:32,612 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:32,630 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:18:32,637 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:33,115 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:33,116 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]37288
2022-02-16T14:18:33,121 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:33,129 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:33,142 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:18:33,151 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:34,032 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:34,048 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:34,061 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:34,065 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:34,069 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:34,074 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:34,084 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:34,086 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:34,101 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:34,653 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:34,662 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:34,679 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:34,683 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:34,686 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:34,699 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:34,715 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:34,736 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:35,182 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:35,183 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:35,196 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:35,199 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:35,218 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:35,224 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:35,232 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:35,233 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:35,254 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:35,261 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:18:41,495 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,496 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,498 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]23468
2022-02-16T14:18:41,502 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]28696
2022-02-16T14:18:41,510 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,514 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,522 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,525 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,536 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:18:41,545 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:18:41,557 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,565 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,786 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:41,802 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]33684
2022-02-16T14:18:41,818 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:41,820 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:41,829 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:18:41,832 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:41,980 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:42,000 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]43296
2022-02-16T14:18:42,005 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:42,013 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:42,029 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:18:42,036 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:42,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:18:42,942 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]17228
2022-02-16T14:18:42,954 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:18:42,957 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:18:42,965 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:18:42,968 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:18:43,757 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:43,760 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:43,774 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:43,778 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:43,793 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:43,798 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:43,804 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:43,806 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:43,811 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:43,823 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:43,830 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:43,834 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:43,836 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:43,839 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:43,850 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:43,871 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:44,107 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:44,113 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:44,125 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:44,130 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:44,134 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:44,138 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:44,141 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:44,155 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:44,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:18:44,284 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:44,285 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:44,299 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:44,302 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:44,306 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:44,308 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:44,322 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:44,334 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:18:45,063 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:18:45,071 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:18:45,087 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:18:45,092 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:18:45,097 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:18:45,109 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:18:45,118 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:18:45,123 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:13,412 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:13,416 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41828
2022-02-16T14:19:13,421 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:13,422 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:13,432 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:19:13,435 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:13,851 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:13,853 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]19884
2022-02-16T14:19:13,858 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:13,866 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:13,874 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:19:13,876 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:14,763 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:14,770 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]39232
2022-02-16T14:19:14,777 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:14,788 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:14,809 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:19:14,841 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:15,725 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:15,730 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:15,745 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:15,750 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:15,771 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:15,775 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:15,779 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:15,796 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:16,111 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:16,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:16,145 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:16,150 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:16,170 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:16,194 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:16,211 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:16,230 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:16,245 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:17,018 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:17,020 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:17,034 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:17,038 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:17,044 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:17,061 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:17,064 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:17,073 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:17,075 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:17,081 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:24,429 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,431 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]52600
2022-02-16T14:19:24,436 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,444 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,452 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:19:24,455 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,559 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,563 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]50876
2022-02-16T14:19:24,567 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,575 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,589 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:19:24,615 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,638 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,656 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]52244
2022-02-16T14:19:24,670 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,673 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,687 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:24,689 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:19:24,689 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]21348
2022-02-16T14:19:24,693 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:24,712 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:24,729 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:24,746 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:19:24,750 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:27,055 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,070 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,083 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,088 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,101 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,115 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,123 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,125 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,130 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,285 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,297 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,310 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,314 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,317 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,321 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,325 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,329 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,349 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,353 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:27,455 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,457 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,462 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,466 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,480 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,488 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,492 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,495 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,505 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,622 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:27,624 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:27,640 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:27,644 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:27,647 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:27,652 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:27,655 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:27,658 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:27,675 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:27,764 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:19:27,766 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29660
2022-02-16T14:19:27,771 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:19:27,779 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:19:27,801 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:19:27,821 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:19:29,911 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:19:29,916 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:19:29,932 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:19:29,935 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:19:29,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:19:29,956 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:19:29,959 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:19:29,961 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:19:29,964 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:19:29,973 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:19:29,995 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:19:29,998 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:19:30,000 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T14:19:30,006 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T14:19:30,008 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T14:20:15,103 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:15,103 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]36652
2022-02-16T14:20:15,115 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:15,117 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:15,130 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T14:20:15,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:15,486 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:15,487 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]22132
2022-02-16T14:20:15,492 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:15,499 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:15,509 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T14:20:15,514 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:16,502 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:16,505 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]39104
2022-02-16T14:20:16,518 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:16,521 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:16,530 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T14:20:16,548 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:17,318 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:17,324 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:17,341 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:17,347 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:17,387 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:17,390 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:17,398 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:17,402 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:17,406 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:17,410 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:20:17,431 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:20:17,713 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:17,715 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:17,728 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:17,732 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:17,745 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:17,755 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:17,757 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:17,761 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:17,764 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:17,769 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T14:20:17,797 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T14:20:17,803 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T14:20:18,814 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:18,821 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:18,834 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:18,839 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:18,868 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:18,878 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:18,884 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:18,890 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:29,512 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,515 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]33272
2022-02-16T14:20:29,523 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,533 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,541 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T14:20:29,544 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,547 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]54724
2022-02-16T14:20:29,564 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,568 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,582 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T14:20:29,595 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,879 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,881 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]11404
2022-02-16T14:20:29,884 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,895 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:29,903 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T14:20:29,906 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:29,975 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:29,984 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]14172
2022-02-16T14:20:29,986 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:29,992 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:30,006 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T14:20:30,010 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:31,821 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T14:20:31,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]43764
2022-02-16T14:20:31,833 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T14:20:31,840 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T14:20:31,849 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T14:20:31,852 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T14:20:31,987 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,000 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,004 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,017 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,034 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,043 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,050 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,073 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,078 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,079 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,083 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,087 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,102 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,104 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:32,112 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T14:20:32,220 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,224 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,248 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,266 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,275 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,291 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,307 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:32,493 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:32,497 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:32,510 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:32,513 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:32,517 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:32,521 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:32,537 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:32,542 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:33,642 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\dc23f979f8894a1eae12594c5b347b85', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T14:20:33,643 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\dc23f979f8894a1eae12594c5b347b85
2022-02-16T14:20:33,657 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T14:20:33,663 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T14:20:33,677 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T14:20:33,685 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T14:20:33,696 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T14:20:33,698 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T14:20:33,702 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:08,996 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:08,998 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]43104
2022-02-16T15:22:08,999 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:09,000 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:09,036 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:09,115 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,272 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,280 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40196
2022-02-16T15:22:10,282 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,284 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,299 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:10,335 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,457 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,459 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]572
2022-02-16T15:22:10,463 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,465 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,476 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:10,518 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,730 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,733 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26972
2022-02-16T15:22:10,737 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,738 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,749 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:10,779 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,830 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]32868
2022-02-16T15:22:10,834 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,836 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,844 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:10,872 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:10,928 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:10,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]45768
2022-02-16T15:22:10,937 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:10,938 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:10,952 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:10,983 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:11,090 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:11,092 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36052
2022-02-16T15:22:11,096 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:11,097 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:11,105 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:11,139 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:11,609 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:11,611 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:11,616 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:11,620 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:11,622 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:11,623 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:11,626 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:11,627 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:11,629 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:11,632 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:11,639 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:11,641 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:11,643 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:11,645 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:11,647 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:22:11,648 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:22:11,650 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 123, in handle
2022-02-16T15:22:11,652 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T15:22:11,654 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 112, in handle
2022-02-16T15:22:11,655 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T15:22:11,657 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 37, in initialize
2022-02-16T15:22:11,660 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T15:22:11,662 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:11,670 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\auto_factory.py", line 419, in from_pretrained
2022-02-16T15:22:11,676 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]22448
2022-02-16T15:22:11,681 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     pretrained_model_name_or_path, return_unused_kwargs=True, trust_remote_code=trust_remote_code, **kwargs
2022-02-16T15:22:11,681 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:11,683 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\models\auto\configuration_auto.py", line 582, in from_pretrained
2022-02-16T15:22:11,685 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:11,687 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
2022-02-16T15:22:11,713 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\configuration_utils.py", line 576, in get_config_dict
2022-02-16T15:22:11,718 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:11,741 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     user_agent=user_agent,
2022-02-16T15:22:11,749 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\transformers\file_utils.py", line 1794, in cached_path
2022-02-16T15:22:11,751 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     raise ValueError(f"unable to parse {url_or_filename} as a URL or as a local path")
2022-02-16T15:22:11,754 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - ValueError: unable to parse C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\config.json as a URL or as a local path
2022-02-16T15:22:11,777 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:13,731 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,733 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,740 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,743 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,758 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,762 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,766 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,768 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:13,771 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:13,920 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,921 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,925 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:13,927 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,929 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:13,934 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,937 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,938 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:13,945 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:13,946 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,968 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,969 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:13,971 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:13,976 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:13,978 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:13,992 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:13,998 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:13,999 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,210 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,211 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,216 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,220 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,224 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,229 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,241 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,244 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,246 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,250 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,315 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,316 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,337 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,349 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,353 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,365 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,368 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,374 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,403 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,405 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,411 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,414 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,428 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,431 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,435 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,436 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,438 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,443 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:14,530 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:14,531 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:14,537 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:14,540 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:14,544 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:14,549 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:14,552 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:14,569 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:14,571 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:14,577 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:19,943 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:19,945 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]28460
2022-02-16T15:22:19,950 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:19,952 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:19,962 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:20,020 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:21,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:21,317 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]12332
2022-02-16T15:22:21,320 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:21,321 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:21,343 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:21,391 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,363 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,364 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]18332
2022-02-16T15:22:22,369 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,371 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,380 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:22,415 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,485 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,489 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]28888
2022-02-16T15:22:22,490 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,493 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,505 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,512 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27096
2022-02-16T15:22:22,514 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,515 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,515 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:22,567 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,573 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:22,593 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,688 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,690 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]57896
2022-02-16T15:22:22,694 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,696 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,703 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:22,721 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:22,961 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:22,963 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]33692
2022-02-16T15:22:22,967 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:22,969 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:22,978 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:23,028 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:23,643 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:23,644 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:23,652 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:23,656 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:23,665 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:23,683 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:23,687 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:23,689 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:23,692 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:23,926 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:23,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]25288
2022-02-16T15:22:23,936 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:23,938 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:23,946 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:23,984 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:24,907 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:24,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:24,912 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:24,916 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:24,920 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:24,938 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:24,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:24,941 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:24,942 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:24,953 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:24,956 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:24,959 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:25,836 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:25,837 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:25,843 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:25,847 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:25,851 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:25,856 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:25,872 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:25,874 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:25,876 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:25,880 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:25,883 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:26,042 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,043 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,048 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,051 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,053 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,057 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,059 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,062 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,066 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,080 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,082 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:26,113 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,114 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,116 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,119 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,123 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,127 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,142 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,144 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,148 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,218 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,220 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,226 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,231 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,236 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,248 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,252 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,255 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,258 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,267 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,290 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,296 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,306 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,311 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,333 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,342 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,346 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,809 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:26,811 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:26,817 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:26,821 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:26,825 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:26,826 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:26,830 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:26,832 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:26,834 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:26,839 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:26,853 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:26,856 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:26,859 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:29,985 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:29,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]25416
2022-02-16T15:22:29,990 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:29,991 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:29,999 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:30,014 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:32,268 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:32,273 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]34392
2022-02-16T15:22:32,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:32,276 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:32,302 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:32,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,180 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:33,181 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:33,184 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,188 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40772
2022-02-16T15:22:33,190 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:33,192 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,193 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:33,196 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,203 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:33,204 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:33,215 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:33,220 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,222 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:33,225 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:33,227 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:33,232 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:33,665 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,667 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36660
2022-02-16T15:22:33,672 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,673 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,682 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:33,684 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,695 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,697 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]26420
2022-02-16T15:22:33,698 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,700 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,712 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:33,720 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:33,855 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:33,860 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]15072
2022-02-16T15:22:33,862 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:33,865 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:33,872 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:33,875 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:34,053 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:34,055 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]40084
2022-02-16T15:22:34,059 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:34,060 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:34,073 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:34,078 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:34,371 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:34,372 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34360
2022-02-16T15:22:34,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:34,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:34,386 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:34,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:35,494 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:35,495 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:35,503 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:35,520 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:35,522 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:35,524 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:35,529 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:35,531 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:35,533 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:35,540 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:35,552 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:35,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:35,558 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:35,562 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:36,323 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,324 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,331 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,334 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,346 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,354 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,357 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,359 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,361 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:36,441 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,442 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,446 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,451 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,456 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,459 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,472 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,475 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,679 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,680 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,688 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,694 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,699 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,703 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,707 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,722 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,726 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:36,817 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:36,818 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:36,827 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:36,831 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:36,836 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:36,849 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:36,853 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:36,855 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:36,858 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:37,029 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:37,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:37,038 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:37,042 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:37,046 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:37,049 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:37,060 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:37,064 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:37,426 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:37,427 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:37,433 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:37,436 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:37,440 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:37,456 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:37,460 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:37,464 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:37,466 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:37,471 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:40,291 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:40,293 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]12600
2022-02-16T15:22:40,296 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:40,298 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:40,306 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:40,311 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:43,384 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:43,385 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:43,393 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:43,397 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:43,402 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:43,406 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:43,410 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:43,422 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:43,426 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:43,614 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:43,616 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]29064
2022-02-16T15:22:43,620 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:43,622 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:43,650 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:43,653 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,430 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,431 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]34768
2022-02-16T15:22:44,435 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,436 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,444 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:44,446 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,725 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,727 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]12728
2022-02-16T15:22:44,732 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,734 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,748 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:44,748 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,806 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,807 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]27060
2022-02-16T15:22:44,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,813 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:44,823 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:44,901 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:44,905 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]19648
2022-02-16T15:22:44,907 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:44,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:44,918 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:44,921 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:45,180 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:45,184 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]41620
2022-02-16T15:22:45,187 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:45,189 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:45,196 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:45,199 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:46,790 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:46,791 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:46,799 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:46,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:46,833 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:46,835 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:46,861 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:46,863 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:46,865 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:46,868 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:46,870 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:46,872 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:22:46,876 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:22:46,906 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:22:46,908 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:22:46,939 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:22:47,139 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:47,140 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]16508
2022-02-16T15:22:47,145 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:47,147 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:47,155 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:47,158 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:47,214 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,215 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,229 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,233 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,238 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,242 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,256 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,258 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,262 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,692 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,693 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,699 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,703 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,714 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,718 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,721 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,723 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,727 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,812 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,824 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,841 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,844 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,846 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,849 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,907 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:47,908 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:47,913 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:47,917 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:47,922 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:47,936 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:47,939 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:47,941 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:47,945 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:47,948 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:47,951 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:22:48,152 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:48,153 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:48,173 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:48,181 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:48,188 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:48,200 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:48,204 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:48,206 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:48,210 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:48,997 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:48,998 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:49,004 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:49,008 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:49,012 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:49,017 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:49,031 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:49,035 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:49,037 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:49,042 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:22:50,412 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:50,413 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]30452
2022-02-16T15:22:50,416 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:50,418 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:50,426 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:22:50,431 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:54,579 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:22:54,581 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:22:54,587 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:22:54,592 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:22:54,597 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:22:54,609 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:22:54,613 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:22:54,615 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:22:54,619 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:22:57,231 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,232 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]19000
2022-02-16T15:22:57,236 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,238 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,249 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:22:57,255 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,274 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,275 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40024
2022-02-16T15:22:57,277 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,279 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,289 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:22:57,295 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,312 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,327 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26228
2022-02-16T15:22:57,344 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,348 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,355 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:22:57,356 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,531 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41180
2022-02-16T15:22:57,533 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,534 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,541 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:22:57,543 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,663 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,665 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]40100
2022-02-16T15:22:57,673 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,678 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,707 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:22:57,710 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:57,890 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:57,891 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]25596
2022-02-16T15:22:57,903 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:57,905 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:57,913 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:22:57,919 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:22:58,371 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:22:58,372 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]56988
2022-02-16T15:22:58,376 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:22:58,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:22:58,385 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:22:58,388 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:00,281 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,282 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,289 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,293 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,297 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,301 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,304 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,306 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,320 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,393 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,396 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,400 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,405 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,410 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,413 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,428 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,433 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,557 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,565 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,570 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,575 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,579 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,582 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,584 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,597 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,604 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:00,782 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,783 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,789 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,791 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,794 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,796 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,796 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,798 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,800 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:00,803 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:00,811 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:00,813 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:00,815 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:00,816 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:23:00,819 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:23:00,942 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,943 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,949 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:00,953 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:00,963 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:00,967 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:00,984 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:00,991 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:00,992 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:00,999 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:00,999 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:01,025 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:01,049 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:01,053 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:01,220 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:01,221 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:01,229 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:01,233 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:01,238 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:01,241 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:01,245 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:01,257 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:01,261 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:04,654 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:04,655 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]35352
2022-02-16T15:23:04,658 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:04,660 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:04,669 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:04,672 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:06,963 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:06,964 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:06,971 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:06,973 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:06,977 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:06,978 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:06,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:06,982 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:06,983 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:06,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:06,989 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:07,003 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:07,007 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:07,009 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:23:07,012 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:23:11,449 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:11,679 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:11,947 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,096 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,101 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,268 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:12,322 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:13,433 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]41300
2022-02-16T15:23:13,447 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]40016
2022-02-16T15:23:13,452 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21672
2022-02-16T15:23:13,453 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]27240
2022-02-16T15:23:13,455 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]29572
2022-02-16T15:23:13,456 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]34088
2022-02-16T15:23:13,458 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]47660
2022-02-16T15:23:13,459 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,461 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,463 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,465 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,466 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,477 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,483 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,486 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,493 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:13,499 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:13,501 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,510 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,511 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:13,514 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,520 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,530 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:13,530 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,540 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,542 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:13,556 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:13,558 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:13,566 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:13,568 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,574 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,577 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:13,593 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:13,599 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:16,237 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,238 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,245 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,249 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,254 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,257 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,268 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,270 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,273 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,300 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,301 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,305 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,313 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,315 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,317 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,322 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,332 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,334 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,339 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:16,397 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,400 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,405 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,409 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,412 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,417 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,430 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,434 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,436 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,439 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,445 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,448 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,468 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,475 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,478 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,480 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,499 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,558 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,559 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,566 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,569 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,580 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,593 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,598 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,602 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,606 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:16,611 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:16,626 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,630 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:16,634 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,640 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:16,646 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,650 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:16,651 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,667 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:16,685 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,694 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:16,696 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,700 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:16,704 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,708 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:16,711 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,713 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:16,727 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:18,833 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:18,834 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]41548
2022-02-16T15:23:18,838 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:18,840 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:18,849 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:18,852 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:20,104 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:20,105 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:20,111 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:20,114 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:20,119 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:20,128 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:20,132 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:20,134 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:20,137 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:30,500 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,517 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]40732
2022-02-16T15:23:30,522 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,524 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,531 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:30,535 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:30,628 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,633 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:30,635 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]19260
2022-02-16T15:23:30,639 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]45436
2022-02-16T15:23:30,640 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,641 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:30,644 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,648 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:30,658 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:30,658 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:30,664 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:30,664 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,142 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]18692
2022-02-16T15:23:31,152 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,154 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,165 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:31,175 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,583 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,591 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]34508
2022-02-16T15:23:31,621 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,625 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,640 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:31,649 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:31,782 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:31,802 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]20424
2022-02-16T15:23:31,809 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:31,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:31,820 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:31,823 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:32,110 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:32,121 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]43736
2022-02-16T15:23:32,125 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:32,127 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:32,141 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:32,148 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:33,713 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:33,726 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:33,736 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:33,740 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:33,746 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:33,759 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:33,764 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:33,768 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:33,774 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:34,270 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,276 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,284 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,288 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,294 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,298 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,312 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,316 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:34,415 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,425 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,448 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,457 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,467 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,483 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,488 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,491 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,494 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:34,500 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,502 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:34,515 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,520 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:34,525 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:34,527 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:34,532 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:34,553 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:34,908 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,909 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:34,911 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,932 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:34,935 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:34,994 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:35,013 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:35,023 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:35,027 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,033 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:35,050 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,052 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,053 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:35,055 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:35,056 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:35,061 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:35,084 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,086 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:35,160 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:35,165 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:35,171 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:35,176 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:35,206 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:35,220 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:35,231 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:23:35,247 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:23:35,251 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:23:39,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:39,981 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]57036
2022-02-16T15:23:39,986 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:39,988 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:39,992 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:23:39,996 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:42,354 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:42,370 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:42,382 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:42,386 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:42,400 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:42,405 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:42,409 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:42,417 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:53,028 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:53,038 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]49552
2022-02-16T15:23:53,042 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:53,044 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:53,051 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:23:53,056 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:53,721 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:53,738 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]26800
2022-02-16T15:23:53,753 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:53,763 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:53,775 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:23:53,780 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:56,589 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:56,591 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]41272
2022-02-16T15:23:56,596 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:56,598 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:56,607 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:23:56,609 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,137 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,143 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]16780
2022-02-16T15:23:57,149 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,150 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,158 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:23:57,162 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,276 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,282 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]41372
2022-02-16T15:23:57,284 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,289 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,302 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:23:57,307 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,418 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,422 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]35408
2022-02-16T15:23:57,427 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,428 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,436 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:23:57,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,884 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:23:57,886 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]14376
2022-02-16T15:23:57,896 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:23:57,897 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:23:57,904 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:23:57,906 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:23:57,952 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:57,960 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:57,968 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:57,973 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:57,979 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:57,984 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:58,002 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:58,008 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:58,236 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:58,243 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:58,260 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:58,270 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:58,275 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:58,278 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:58,291 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:58,294 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:59,445 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:59,448 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:59,455 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:59,459 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:59,465 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:59,469 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:59,472 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:59,485 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:59,490 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:59,755 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:23:59,760 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:23:59,767 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:23:59,771 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:23:59,775 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:23:59,777 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:23:59,780 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:23:59,783 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:23:59,785 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:23:59,787 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:23:59,801 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:24:00,022 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,050 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,057 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,062 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,067 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,079 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,083 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,085 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,088 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:00,108 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,110 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,114 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,118 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,122 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,129 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,151 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,153 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,379 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:00,385 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:00,394 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:00,399 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:00,404 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:00,408 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:00,422 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:00,424 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:00,429 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:06,365 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:06,367 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]32720
2022-02-16T15:24:06,370 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:06,372 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:06,380 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:24:06,383 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:07,675 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:07,676 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:07,693 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:07,700 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:07,704 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:07,707 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:07,717 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:07,718 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:24,315 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:24,324 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]2352
2022-02-16T15:24:24,325 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:24,326 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:24,329 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]15892
2022-02-16T15:24:24,332 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:24,333 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:24,338 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:24:24,344 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:24,362 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:24,368 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:24:24,374 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:25,756 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:25,761 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]28080
2022-02-16T15:24:25,765 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:25,767 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:25,775 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:24:25,778 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,226 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:26,237 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]36968
2022-02-16T15:24:26,239 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:26,241 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:26,249 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:24:26,252 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:26,816 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]23340
2022-02-16T15:24:26,826 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:26,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:26,838 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:24:26,840 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:26,910 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:26,916 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:26,928 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:26,931 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:26,935 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:26,946 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:26,949 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:26,950 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:26,951 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:26,953 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:26,959 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:26,962 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:26,974 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:26,998 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:27,002 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:27,005 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:27,007 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:27,011 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:27,329 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:27,342 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]36048
2022-02-16T15:24:27,346 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:27,348 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:27,357 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:24:27,364 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:27,472 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:27,475 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]9860
2022-02-16T15:24:27,479 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:27,481 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:27,490 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:24:27,493 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:28,342 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:28,359 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:28,366 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:28,370 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:28,383 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:28,388 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:28,392 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:28,395 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:28,398 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:28,565 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:28,577 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:28,583 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:28,587 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:28,600 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:28,603 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:28,607 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:28,608 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:28,613 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,072 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,074 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,082 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,086 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,092 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,105 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,109 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,111 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,115 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,261 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,265 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,275 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,279 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,284 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,288 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,293 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,295 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,314 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:29,397 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:29,398 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:29,405 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:29,410 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:29,414 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:29,417 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:29,431 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:29,434 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:29,438 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:24:44,560 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:24:44,561 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]20792
2022-02-16T15:24:44,565 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:24:44,567 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:24:44,574 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:24:44,576 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:24:45,817 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:24:45,818 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:24:45,825 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:24:45,828 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:24:45,832 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:24:45,836 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:24:45,848 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:24:45,850 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:24:45,854 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:05,848 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:05,881 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]34716
2022-02-16T15:25:05,886 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:05,887 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:05,895 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:25:05,898 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:06,352 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:06,358 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]18372
2022-02-16T15:25:06,359 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:06,364 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:06,372 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:25:06,374 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:08,154 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:08,161 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]23428
2022-02-16T15:25:08,166 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:08,168 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:08,181 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:25:08,191 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:08,464 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:08,471 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:08,472 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:08,477 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]33508
2022-02-16T15:25:08,480 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:08,482 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:08,485 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:08,487 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:08,492 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:08,497 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:08,501 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:08,502 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:25:08,503 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:08,508 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:08,509 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:09,080 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,084 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]35024
2022-02-16T15:25:09,088 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,089 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,096 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:25:09,102 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:09,131 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:09,132 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:09,146 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:09,149 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:09,152 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:09,156 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:09,159 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:09,173 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:09,182 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:09,222 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,227 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]21572
2022-02-16T15:25:09,229 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,231 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,237 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:25:09,244 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:09,263 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:09,264 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]30768
2022-02-16T15:25:09,273 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:09,277 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:09,283 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:25:09,286 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:10,754 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:10,770 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:10,779 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:10,783 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:10,788 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:10,792 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:10,797 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:10,799 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:10,813 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:10,945 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:10,947 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:10,952 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:10,955 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:10,959 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:10,963 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:10,976 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:10,981 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,171 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,177 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,189 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,192 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,198 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,211 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,214 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,216 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,220 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:11,293 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,295 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,316 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,319 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,325 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,339 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,343 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,344 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:11,345 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:11,348 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:11,370 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:25:11,375 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:11,384 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:11,389 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:11,407 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:11,409 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:11,412 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:43,974 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:25:43,975 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]10476
2022-02-16T15:25:43,980 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:25:43,981 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:25:43,989 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:25:43,992 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:25:45,394 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:25:45,395 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:25:45,403 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:25:45,407 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:25:45,411 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:25:45,414 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:25:45,416 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:25:45,418 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:25:45,422 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:07,990 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:07,997 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]37304
2022-02-16T15:26:08,001 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:08,002 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:08,009 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:26:08,014 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:09,599 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:09,609 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]43540
2022-02-16T15:26:09,614 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:09,615 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:09,625 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:26:09,628 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:11,012 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:11,030 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:11,037 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:11,041 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:11,045 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:11,049 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:11,052 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:11,055 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:11,069 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:11,660 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:11,662 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]24764
2022-02-16T15:26:11,667 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:11,669 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:11,679 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:26:11,681 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:11,883 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:11,885 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]22824
2022-02-16T15:26:11,889 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:11,891 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:11,898 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:26:11,901 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,002 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,006 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]27136
2022-02-16T15:26:12,011 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,012 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,020 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:26:12,023 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,028 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,029 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]51440
2022-02-16T15:26:12,038 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,039 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,047 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:26:12,050 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,360 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:26:12,378 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]25656
2022-02-16T15:26:12,381 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:26:12,383 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:26:12,390 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:26:12,394 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:26:12,495 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:12,499 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:12,506 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:12,509 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:12,513 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:12,523 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:12,526 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:12,528 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:12,537 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:13,813 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:13,817 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:13,828 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:13,832 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:13,837 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:13,841 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:13,844 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:13,858 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:13,869 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,056 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,067 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,087 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,094 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,107 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,111 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,115 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,117 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,120 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,214 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,226 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,246 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,248 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,256 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,258 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,266 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,267 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,271 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,273 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,277 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,278 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,287 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,289 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:26:14,312 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,316 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,472 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:26:14,490 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:26:14,497 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:26:14,501 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:26:14,506 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:26:14,519 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:26:14,523 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:26:14,525 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:26:14,530 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:17,518 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:17,519 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]12372
2022-02-16T15:27:17,523 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:17,524 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:17,529 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:27:17,531 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:18,760 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:18,762 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:18,768 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:18,776 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:18,783 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:18,797 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:18,801 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:18,803 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:18,806 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:43,164 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:43,170 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21792
2022-02-16T15:27:43,172 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:43,177 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:43,186 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:27:43,190 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:45,701 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:45,711 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:45,718 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:45,723 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:45,728 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:45,731 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:45,735 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:45,747 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:45,751 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:46,547 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:46,549 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]17192
2022-02-16T15:27:46,554 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:46,555 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:46,562 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:27:46,569 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,031 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,041 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]32684
2022-02-16T15:27:48,046 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,048 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,058 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:27:48,066 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,560 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,562 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]51508
2022-02-16T15:27:48,567 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,569 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,577 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:27:48,580 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,695 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,718 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]32772
2022-02-16T15:27:48,723 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,724 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,732 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:27:48,735 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:48,809 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:48,811 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]57288
2022-02-16T15:27:48,815 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:48,817 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:48,826 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:27:48,829 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:49,387 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:49,396 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:49,410 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:49,414 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:49,431 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:49,434 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:49,437 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:49,439 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:49,443 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:50,263 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:50,274 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:50,293 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:50,301 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:50,306 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:50,310 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:50,313 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:50,315 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:50,319 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:50,896 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:27:50,899 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:50,900 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]28532
2022-02-16T15:27:50,905 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:50,906 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:27:50,910 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:50,913 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:27:50,914 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:50,931 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:27:50,938 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:50,942 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:27:50,944 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:50,955 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:50,956 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:51,093 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:51,096 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:51,105 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:51,110 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:51,116 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:51,130 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:51,133 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:51,134 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:51,136 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:51,140 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:51,147 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:51,163 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:51,172 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:51,175 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:51,189 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:51,194 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:52,887 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - {'model_dir': 'C:\\Users\\enoch9\\AppData\\Local\\Temp\\models\\a7d22755b88d47bb8f011e96977a4208', 'gpu_id': None, 'batch_size': 1, 'server_name': 'MMS', 'server_version': '0.5.2', 'limit_max_image_pixels': True}
2022-02-16T15:27:52,888 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208
2022-02-16T15:27:52,897 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Backend worker process died.
2022-02-16T15:27:52,901 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-02-16T15:27:52,904 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 189, in <module>
2022-02-16T15:27:52,908 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     worker.run_server()
2022-02-16T15:27:52,913 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 161, in run_server
2022-02-16T15:27:52,949 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-02-16T15:27:52,950 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 123, in handle_connection
2022-02-16T15:27:52,953 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-02-16T15:27:52,954 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Continuum\anaconda3\Lib\site-packages\ts\model_service_worker.py", line 96, in load_model
2022-02-16T15:27:52,955 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     batch_size, envelope, limit_max_image_pixels)
2022-02-16T15:27:52,957 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 112, in load
2022-02-16T15:27:52,959 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-02-16T15:27:52,961 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "c:\users\enoch9\appdata\local\continuum\anaconda3\lib\site-packages\ts\model_loader.py", line 139, in <lambda>
2022-02-16T15:27:52,962 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     initialize_fn = lambda ctx: entry_point(None, ctx)
2022-02-16T15:27:52,970 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 123, in handle
2022-02-16T15:27:52,972 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     raise e
2022-02-16T15:27:52,973 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 112, in handle
2022-02-16T15:27:52,975 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     _service.initialize(context)
2022-02-16T15:27:52,977 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -   File "C:\Users\enoch9\AppData\Local\Temp\models\a7d22755b88d47bb8f011e96977a4208\handler.py", line 37, in initialize
2022-02-16T15:27:52,981 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG -     self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
2022-02-16T15:46:51,724 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:51,726 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - [PID]21808
2022-02-16T15:46:51,730 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:51,733 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:51,772 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2022-02-16T15:46:51,854 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,147 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,151 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - [PID]36704
2022-02-16T15:46:52,154 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,155 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,166 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2022-02-16T15:46:52,191 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,356 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,358 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - [PID]10244
2022-02-16T15:46:52,361 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,362 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,367 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - [PID]33268
2022-02-16T15:46:52,370 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,371 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,376 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2022-02-16T15:46:52,377 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,390 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2022-02-16T15:46:52,411 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,422 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,442 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,444 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - [PID]33324
2022-02-16T15:46:52,447 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,448 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,457 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2022-02-16T15:46:52,484 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,598 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,602 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - [PID]11868
2022-02-16T15:46:52,604 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,605 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,618 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2022-02-16T15:46:52,646 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:52,851 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:52,853 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - [PID]31480
2022-02-16T15:46:52,868 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:52,869 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:52,879 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2022-02-16T15:46:52,916 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:46:53,280 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Listening on port: None
2022-02-16T15:46:53,281 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - [PID]34048
2022-02-16T15:46:53,284 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Torch worker started.
2022-02-16T15:46:53,287 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Python runtime: 3.7.3
2022-02-16T15:46:53,293 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2022-02-16T15:46:53,322 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - model_name: sentencemoji, batchSize: 1
2022-02-16T15:47:16,144 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']
2022-02-16T15:47:16,147 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,159 [WARN ] W-9003-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,258 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:16,459 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']
2022-02-16T15:47:16,461 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,465 [WARN ] W-9000-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,528 [INFO ] W-9000-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:16,641 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:16,662 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:16,668 [WARN ] W-9007-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:16,745 [INFO ] W-9007-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,016 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']
2022-02-16T15:47:17,018 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,103 [WARN ] W-9005-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,109 [INFO ] W-9005-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,342 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:17,344 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,349 [WARN ] W-9006-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,438 [INFO ] W-9006-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:17,501 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']
2022-02-16T15:47:17,504 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:17,509 [WARN ] W-9002-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:17,532 [INFO ] W-9002-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:18,012 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']
2022-02-16T15:47:18,014 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:18,018 [WARN ] W-9004-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:18,034 [INFO ] W-9004-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:47:18,354 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']
2022-02-16T15:47:18,356 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - - This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-02-16T15:47:18,361 [WARN ] W-9001-sentencemoji_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-02-16T15:47:18,374 [INFO ] W-9001-sentencemoji_1.0-stdout MODEL_LOG - Missing the index_to_name.json file. Inference output will not include class name.
2022-02-16T15:53:35,158 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Backend received inference at: 1644994415
2022-02-16T15:53:35,160 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Received text: '???? ??? ??????'
2022-02-16T15:53:35,582 [INFO ] W-9003-sentencemoji_1.0-stdout MODEL_LOG - Model predicted: '4772'
